{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "#### Goal: Predict the number of nights granted to a request (not to an individual)\n",
    "\n",
    "\n",
    "#### Caracteristics of the model:\n",
    "Accuracy:\n",
    "- if used as a clearing tool removing overburden upfront, and thus only to get rid of obvious cases, the accuracy of such a tool could be its most important caracteristic.\n",
    "\n",
    "Interpretability:\n",
    "- could help families understand the decision (although not as important as in diseases predictions).\n",
    "- can also highlight and thus control biases (racial, sex, age).\n",
    "- since the tool would probably be used in combination with human selection, it could help save time by highlighting the main factors for each decision\n",
    "\n",
    "#### Conclusion:\n",
    "- a model easily interpretable could be prefered (tree).\n",
    "- or a highly accurate model (less interpretable) could also be used upfront (NN).\n",
    "\n",
    "\n",
    "#### Future improvements\n",
    "\n",
    "Imputations:\n",
    "- Build more robust, generalisable imputations (eg. impute future test samples with missing gender based on all easily interpretable categories group_composition_label and group_composition_id)\n",
    "\n",
    "- Automate NaNs imputation for future test samples\n",
    "\n",
    "- Reconstruct some NaNs by training models to predict the feature\n",
    "\n",
    "Feature engineering\n",
    "\n",
    "Datasets handling\n",
    "- I made the choice to keep the train and test sets split. This is to prevent gaining insight from the test set while doing pre-processing, analysis and while training the model. To prevent duplicate code, I thus placed most of the inner workings in the class Analysis, which makes the reading less fluent. To improve, see how to better combine the visual aspect of Jupyter Notebooks, while maintaining code standards like DRY philosophy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "I. Load\n",
    "\n",
    "1. Packages, classes, functions\n",
    "\n",
    "2. Databases (no join)\n",
    "\n",
    "II. Pre-process data 1:\n",
    "\n",
    "1. Impute NaNs\n",
    "\n",
    "2. Remove outliers\n",
    "\n",
    "III. Analyze\n",
    "\n",
    "1. Impact on target\n",
    "\n",
    "2. Correlated features\n",
    "\n",
    "IV. Pre-process data 2:\n",
    "\n",
    "1. Transform categorical features\n",
    "\n",
    "V. Build Model\n",
    "\n",
    "1. Benchmakrs\n",
    "\n",
    "2. Rush model using all data\n",
    "\n",
    "3. Simple using principal components\n",
    "\n",
    "4. More complex using specific features\n",
    "\n",
    "5. Ensemble\n",
    "\n",
    "VI. Predictions\n",
    "\n",
    "1. Train and Predict\n",
    "\n",
    "2. Hyperparameter tunning (split train set)\n",
    "\n",
    "VII. Evaluate methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes, Functions & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import tree\n",
    "\n",
    "#os.chdir('/Users/Pro/Desktop/Git_Contests/Predictions/Emergency_housing/')\n",
    "from cobratools import Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test scorer\n",
    "def competition_scorer(y_true, y_pred):\n",
    "    return log_loss(y_true, y_pred, sample_weight=10**y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General constants\n",
    "PRINT_ON = True\n",
    "PLOT_ON = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_train = pd.read_csv(filepath_or_buffer='data/requests_train.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "requests_test = pd.read_csv(filepath_or_buffer='data/requests_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "individuals_train = pd.read_csv(filepath_or_buffer='data/individuals_train.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "individuals_test = pd.read_csv(filepath_or_buffer='data/individuals_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index col as request id\n",
    "requests_train.set_index('request_id', inplace=True)\n",
    "requests_test.set_index('request_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join datasets\n",
    "\n",
    "Since there are multiple requests by individuals and multiple individuals by request, the straightfoward approach would be to create columns for each individual' informations. This way, no information would be lost, but the curse of dimensionality is very near and the number of samples might be too low to extract useful information.\n",
    "\n",
    "The chosen approach is rather to only keep the request dataset' columns, and feature engineer additional columns based on the individuals data, eg.:\n",
    "- nb of past requests made by the same individual\n",
    "- nb nights granted in past requests of the same individual(s)/group\n",
    "- gender diversity of the group\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate object analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate analysis object with request data\n",
    "analyze_train = Analysis(requests_train)\n",
    "analyze_test = Analysis(requests_test)\n",
    "\n",
    "# Define properties\n",
    "\n",
    "# - target\n",
    "target = 'granted_number_of_nights' \n",
    "analyze_test.target = target\n",
    "analyze_train.target = target\n",
    "# - shape\n",
    "analyze_train.m = analyze_train.df.shape[0]\n",
    "analyze_test.m = analyze_test.df.shape[0]\n",
    "analyze_train.n = analyze_train.df.shape[1]\n",
    "analyze_test.n = analyze_test.df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data 1\n",
    "\n",
    "Methodology:\n",
    "\n",
    "- Clean-up request dataset\n",
    "\n",
    "- Feature engineer using indiv dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaNs\n",
    "\n",
    "Methodology:\n",
    "- inspect NaNs on train set\n",
    "\n",
    "- if pattern detected, apply modifications on train and test sets\n",
    "\n",
    "Observations:\n",
    "- reverse engineering: the system seems to derive group_composition_id from group_composition_label, and both are then necessary linked/redondant => drop group_composition_label\n",
    "\n",
    "- there can be multiple individuals by request, and multiple requests by individual\n",
    "\n",
    "Further:\n",
    "- Impute 14 pregnancy NaNs from child_to_come (not useful for the current objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs train summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train: NaNs count by feature\n\n child_to_come                145947\nhousing_situation_label       16748\nlong_term_housing_request    165556\ntown                         159959\nvictim_of_violence_type      234175\ndtype: int64\n"
    }
   ],
   "source": [
    "# Get Na counts: by feature, by sample\n",
    "na_ft_train, na_sp_train = analyze_train.get_na_counts()\n",
    "na_ft_test, na_sp_test = analyze_test.get_na_counts()\n",
    "if PRINT_ON:\n",
    "    print('Train: NaNs count by feature\\n\\n', na_ft_train[na_ft_train!=0])\n",
    "    #print('\\n\\nTest: NaNs count by feature\\n\\n', na_ft_test[na_ft_test!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_to_come NaNs\n",
    "\n",
    "Observation\n",
    "- There are 145947 NaNs for child_to_come on the train set (in request)\n",
    "\n",
    "- There are only 14 NaNs for pregnancy in train set (in individuals)\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: child_to_come is True if any indiv of the group is pregnant\n",
    "\n",
    "Conclusion\n",
    "- => Impute child_to_come from the pregnancy in the group of indiv of the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes Â±3min\n",
    "if False:\n",
    "    analyze_train.impute_child_to_come(df_indiv=individuals_train)\n",
    "    analyze_test.impute_child_to_come(df_indiv=individuals_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute housing_situation_label NaNs\n",
    "\n",
    "Observation (train set)\n",
    "- There are 16748 NaNs for child_to_come (in request)\n",
    "- X NaNs for housing_situation_id (in request)\n",
    "\n",
    "- X NaNs for housing_situation_label_2 (in individuals)\n",
    "- X NaNs for housing_situation_id_2 (in individuals)\n",
    "\n",
    "- 21 housing_situation_label (request)\n",
    "- 22 housing_situation_id (request)\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: link with housing_situation_id (request), housing_situation_label_2 and housing_situation_id_2 (individuals)\n",
    "\n",
    "Conclusion\n",
    "- => Impute housing_situation_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([200,  10, 100, 170,  50, 120, 130, 160, 140,  80,  40, 220,  70,\n        30, 150, 110,  90,  60, 190,  20, 180, 210])"
     },
     "metadata": {},
     "execution_count": 171
    }
   ],
   "source": [
    "analyze_train.get_col_uniques('housing_situation_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore impact on target\n",
    "\n",
    "Results: there seems not to have a significative direct correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of target counts:\n",
    "# Â± half individuals granted >=1 night(s)\n",
    "# which means < 50% of requests\n",
    "# Rq: still nicely balanced dataset\n",
    "target_counts = analyze_train.df[target].value_counts()\n",
    "\n",
    "if PRINT_ON:\n",
    "    print('Absolute\\n', target_counts)\n",
    "    print('\\n\\nPercentage\\n', target_counts / n_samples * 100)\n",
    "\n",
    "# Filter pregnants\n",
    "mask_pregnant = analyze_train.df['pregnancy'] == True\n",
    "\n",
    "# Count pregnants: 11k+ pregnant\n",
    "n_pregnants = sum(mask_pregnant)\n",
    "\n",
    "# Percentage Â± 3%\n",
    "pct_pregnants = n_pregnants/ n_samples * 100\n",
    "\n",
    "\n",
    "# Correlation target & pregnancy: Â± -.1% (significant? not)\n",
    "analyze_train.df[[target, 'pregnancy']].corr()\n",
    "\n",
    "# Summary\n",
    "target_pregnancy_counts = analyze_train.df[target].groupby(analyze_train.df['pregnancy']).value_counts()\n",
    "\n",
    "if PRINT_ON:\n",
    "    # Pct pregnants by target\n",
    "    print('\\n\\nN of nights granted for pregnants', target_pregnancy_counts[1] / n_pregnants)\n",
    "    # Pct not pregnants by target\n",
    "    print('\\nN of nights granted for not pregnants', target_pregnancy_counts[0] / (n_samples - n_pregnants))\n",
    "\n",
    "# => Repartitions are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern for missing pregnancy?\n",
    "Search if missing is treated as pregnant through correlated variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_train.df['gender'].groupby(analyze_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern with child_situation\n",
    "analyze_train.df[target].groupby(analyze_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests granted (nb_nights > 0)\n",
    "granted = analyze_train.df[target] > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## child_to_come\n",
    "\n",
    "flag indicating whether the group is expecting a baby\n",
    "\n",
    "\n",
    "What does it represent?\n",
    "\n",
    "- hyp: it is the corresponding value of the individual \"pregnancy\"\n",
    "\n",
    "Then?\n",
    "\n",
    "- now that dataframes are joined, it is redondant\n",
    "\n",
    "Conclusion\n",
    "\n",
    "- use it to impute pregnancy NAs\n",
    "\n",
    "- then drop the feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender\n",
    "\n",
    "Only females are possibly pregnant, thus 30 males have made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_train.df['gender'].groupby(analyze_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the individual ids, and correct for male -> pregnancy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis (df_train)\n",
    "### General:\n",
    "- Number of requests: 238191\n",
    "- Number of individuals: 384133\n",
    "- Number of features: 39\n",
    "\n",
    "Requests are made for 1.6 pers on average.\n",
    "\n",
    "\n",
    "### Correlations with granted_number_of_nights\n",
    "- housing_situation_id: -0.458581. Strong negative impact. A high value must represent the good quality of the current housing situation.\n",
    "- housing_situation_2_id: 0.283840. Strong positive impact. A higher value must conversely represent a degraded quality.\n",
    "\n",
    "### Principal components\n",
    "- housing_situation_2_label: with value \"emergency accomodation\". High probability to get 1 or two nights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyze_df_train = Analysis(df_train)\n",
    "#Analyze_df_train.describe(investigation_level=3)\n",
    "#Analyze.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'granted_number_of_nights'\n",
    "feature = 'animal_presence'\n",
    "mask = df_train[feature] == 't'\n",
    "df_train[mask][[feature, target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA, inf\n",
    "columns_selected = ['animal_presence']\n",
    "df_train[columns_selected].isnull().sum()\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature: housing_situation_2_label\n",
    "- A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of feature on target\n",
    "join_key = 'request_id'\n",
    "target = 'granted_number_of_nights'\n",
    "feature = 'housing_situation_2_label'\n",
    "mask = df_train[feature] == 'emergency accomodation'\n",
    "\n",
    "# Hist: drop duplicate requests (due to indiv data merged)\n",
    "df_train[mask][[join_key, target]].drop_duplicates().hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical features\n",
    "Prepare data to feed models\n",
    "\n",
    "- booleans: replace by (1, 0)\n",
    "\n",
    "- 2 < cats < 11: one-hot encoding\n",
    "\n",
    "- No transform on features with more than 11 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process columns:\n",
    "# booleans: 't', 't' => True, False\n",
    "# Categorical with few classes => one-hot encoding\n",
    "bools_train, failed_train = analyze_train.transform_categories(target=analyze_train.target)\n",
    "bools_test, failed_test = analyze_test.transform_categories(target=analyze_test.target)\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "analyze_train.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "analyze_test.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Export data\n",
    "analyze_train.export_data('data/data_train_preprocessed.csv')\n",
    "analyze_test.export_data('data/data_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random uniform train/test\n",
    "random_preds_train = np.random.uniform(size=(requests_train.shape[0], 4))\n",
    "random_preds_test = np.random.uniform(size=(requests_test.shape[0], 4))\n",
    "\n",
    "# Dumb (always pred 3)\n",
    "dumb_preds_train = np.zeros((requests_train.shape[0], 4))\n",
    "dumb_preds_test = np.zeros((requests_test.shape[0], 4))\n",
    "# Set 10% pred everywhere (if not, log penalyzes hardly)\n",
    "dumb_preds_train[:,:] = .01\n",
    "dumb_preds_test[:,:] = .01\n",
    "# Set 20% pred on class 3\n",
    "dumb_preds_train[:,2] = .02\n",
    "dumb_preds_test[:,2] = .02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed a significant (negative) correlation of housing_situation_id with granted_number_of_nights, let's train a univariate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model' parameters\n",
    "clf = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=2,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=None,\n",
    "    class_weight=None)\n",
    "\n",
    "# Build train/test datasets with housing_situation_id only\n",
    "X_train = np.array(requests_train['housing_situation_id']).reshape(-1, 1)\n",
    "X_test = np.array(requests_test['housing_situation_id'].values).reshape(-1, 1)\n",
    "Y_train = requests_train.granted_number_of_nights.values\n",
    "Y_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Transform categorical target into a one-hot vector\n",
    "Y_train_onehot = to_onehot(Y_train)\n",
    "Y_test_onehot = to_onehot(Y_test)\n",
    "\n",
    "# Train the model\n",
    "clf = clf.fit(X_train, Y_train_onehot)\n",
    "\n",
    "# Yield train/test predictions\n",
    "preds_train_tree_univar = clf.predict(X_train)\n",
    "preds_test_tree_univar = clf.predict(X_test)\n",
    "\n",
    "# Fill predictions to .2 elsewhere\n",
    "preds_train_tree_univar[preds_train_tree_univar == 0] = .2\n",
    "preds_test_tree_univar[preds_test_tree_univar == 0] = .2\n",
    "\n",
    "# Evaluate train/test\n",
    "score_train = competition_scorer(Y_train, preds_train_tree_univar)\n",
    "score_test = competition_scorer(Y_test, preds_test_tree_univar)\n",
    "\n",
    "# Display results\n",
    "print(f'train score: {score_train:.2f}')\n",
    "print(f'test score: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = clf.predict_proba(X_train)\n",
    "v0 = probas[0].max(1)\n",
    "v1 = probas[1].max(1)\n",
    "v2 = probas[2].max(1)\n",
    "v3 = probas[3].max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_test = competition_scorer(y_true_test, random_preds_test)\n",
    "dumb_score_test = competition_scorer(y_true_test, dumb_preds_test)\n",
    "\n",
    "# Display results\n",
    "print(f'test score random: {random_score_test:.2f}')\n",
    "print(f'test score dumb: {dumb_score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_train = requests_train.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_train = competition_scorer(y_true_train, random_preds_train)\n",
    "dumb_score_train = competition_scorer(y_true_train, dumb_preds_train)\n",
    "\n",
    "# Display results\n",
    "print(f'train score random: {random_score_train:.2f}')\n",
    "print(f'train score dumb: {dumb_score_train:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree\n",
    "fn = ['housing_situation_id']\n",
    "cn = ['0', '1', '2', '3']\n",
    "\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True)\n",
    "\n",
    "requests_train['housing_situation_id'].hist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}