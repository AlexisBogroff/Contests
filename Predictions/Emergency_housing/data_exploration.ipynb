{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "#### Goal: Predict the number of nights granted to a request (not to an individual)\n",
    "\n",
    "\n",
    "#### Caracteristics of the model:\n",
    "Accuracy:\n",
    "- if used as a clearing tool removing overburden upfront, and thus only to get rid of obvious cases, the accuracy of such a tool could be its most important caracteristic.\n",
    "\n",
    "Interpretability:\n",
    "- could help families understand the decision (although not as important as in diseases predictions).\n",
    "- can also highlight and thus control biases (racial, sex, age).\n",
    "- since the tool would probably be used in combination with human selection, it could help save time by highlighting the main factors for each decision\n",
    "\n",
    "#### Conclusion:\n",
    "- a model easily interpretable could be prefered (tree).\n",
    "- or a highly accurate model (less interpretable) could also be used upfront (NN).\n",
    "\n",
    "\n",
    "#### Future improvements\n",
    "\n",
    "Imputations:\n",
    "- Build more robust, generalisable imputations (eg. impute future test samples with missing gender based on all easily interpretable categories group_composition_label and group_composition_id)\n",
    "\n",
    "- Automate NaNs imputation for future test samples\n",
    "\n",
    "- Reconstruct some NaNs by training models to predict the feature\n",
    "\n",
    "\n",
    "Datasets handling\n",
    "- I made the choice to keep the train and test sets split. This is to prevent gaining insight from the test set while doing pre-processing, analysis and while training the model. To prevent duplicate code, I thus placed most of the inner workings in the class Analysis, which makes the reading less fluent. To improve, see how to better combine the visual aspect of Jupyter Notebooks, while maintaining code standards like DRY philosophy.\n",
    "\n",
    "\n",
    "Pre-processing\n",
    "- impact historical data with the known global crises (financial crisis, immigration waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "I. Initialization\n",
    "\n",
    "1. Import packages, classes, functions\n",
    "\n",
    "2. Load databases (no join)\n",
    "\n",
    "3. Instantiate object Analysis\n",
    "\n",
    "\n",
    "II. Analyze I\n",
    "\n",
    "1. Overview\n",
    "\n",
    "2. Features: corr, dist, impact\n",
    "\n",
    "\n",
    "III. Pre-process data\n",
    "\n",
    "1. Impute NaNs\n",
    "\n",
    "2. Impute never seen before test set NaNs\n",
    "\n",
    "3. Remove outliers\n",
    "\n",
    "4. Transform categorical features\n",
    "\n",
    "5. Feature engineer\n",
    "\n",
    "\n",
    "\n",
    "IV. Analyze II\n",
    "\n",
    "1. Impact engineered features\n",
    "\n",
    "\n",
    "V. Build Model\n",
    "\n",
    "1. Benchmakrs\n",
    "\n",
    "2. Rush pytorch NN\n",
    "\n",
    "3. Simple model using principal components\n",
    "\n",
    "4. Ensemble\n",
    "\n",
    "\n",
    "VI. Predictions\n",
    "\n",
    "1. Train and Predict\n",
    "\n",
    "2. Hyperparameter tunning (split train set)\n",
    "\n",
    "\n",
    "VII. Evaluate methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "from sklearn import tree\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear, functional\n",
    "from torch import nn, optim\n",
    "\n",
    "# Utils\n",
    "import cobratools as cobra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set False to only apply data transformations\n",
    "ANALYZE_ON = False\n",
    "\n",
    "# False for the competition, True if predicting > year 2019 requests\n",
    "FUTURE_PRED = False\n",
    "\n",
    "# Takes ±4min\n",
    "IMPUTE_NANS = True\n",
    "EXPORT_DATA = False\n",
    "\n",
    "# Set to True to visualize\n",
    "PRINT_ON = False\n",
    "PLOT_ON = False\n",
    "\n",
    "# Debug\n",
    "RELOAD = False\n",
    "\n",
    "# Data specificities\n",
    "TARGET_VAR = 'granted_number_of_nights'\n",
    "N_TARGET_CLASS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug reload\n",
    "Without the need to re-perform data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELOAD:\n",
    "    # Backup data\n",
    "    backup_train = obj_train.df.copy()\n",
    "    backup_test = obj_test.df.copy()\n",
    "    \n",
    "    # Reload updated class and functions\n",
    "    importlib.reload(cobra)\n",
    "\n",
    "    # Re-instanciate obj_train and obj_test\n",
    "    obj_train = cobra.Analysis(backup_train)\n",
    "    obj_test = cobra.Analysis(backup_test)\n",
    "    \n",
    "    # Re-set target variable\n",
    "    obj_train.target = TARGET_VAR\n",
    "    obj_test.target = TARGET_VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_train = pd.read_csv(filepath_or_buffer='data/requests_train.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "requests_test = pd.read_csv(filepath_or_buffer='data/requests_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "individuals_train = pd.read_csv(filepath_or_buffer='data/individuals_train.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "individuals_test = pd.read_csv(filepath_or_buffer='data/individuals_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join datasets\n",
    "\n",
    "Since there are multiple requests by individuals and multiple individuals by request, the straightfoward approach would be to create columns for each individual' informations. This way, no information would be lost, but the curse of dimensionality is very near and the number of samples might be too low to extract useful information.\n",
    "\n",
    "The chosen approach is rather to only keep the request dataset' columns, and feature engineer additional columns based on the individuals data, eg.:\n",
    "- nb of past requests made by the same individual\n",
    "- nb nights granted in past requests of the same individual(s)/group\n",
    "- gender diversity of the group\n",
    "- etc.\n",
    "\n",
    "However, for analytics purpose, a dataframe with all the data is also created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge request and individuals datasets, for analytics purpose only\n",
    "df_full_train = pd.merge(requests_train, individuals_train, on='request_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index col as request id\n",
    "# (not for individuals data set, since there is no pkey currently)\n",
    "# (hence not for obj_full_train either)\n",
    "requests_train.set_index('request_id', inplace=True)\n",
    "requests_test.set_index('request_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate object analysis\n",
    "\n",
    "obj_train and obj_test will be the main dataframes, used for training and testing the model\n",
    "\n",
    "They are primilary built with the request data sets, then features engineered from individuals' data sets are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate analysis object with request data\n",
    "obj_train = cobra.Analysis(requests_train)\n",
    "obj_test = cobra.Analysis(requests_test)\n",
    "obj_full_train = cobra.Analysis(df_full_train)\n",
    "\n",
    "# Define properties\n",
    "\n",
    "# - set target\n",
    "obj_train.target = TARGET_VAR\n",
    "obj_full_train.target = TARGET_VAR\n",
    "\n",
    "# - set shape\n",
    "obj_train.m = obj_train.df.shape[0]\n",
    "obj_test.m = obj_test.df.shape[0]\n",
    "obj_train.n = obj_train.df.shape[1]\n",
    "obj_test.n = obj_test.df.shape[1]\n",
    "obj_full_train.m = obj_full_train.df.shape[0]\n",
    "obj_full_train.n = obj_full_train.df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "- Number of requests: 238191\n",
    "\n",
    "- Number of individuals: 384133\n",
    "\n",
    "- Number of features: 39\n",
    "\n",
    "- Requests are made for 1.6 pers on average.\n",
    "\n",
    "\n",
    "Principal components\n",
    "- housing_situation_label: with value \"emergency accomodation\". High probability to get 1 or two nights. Logical since the service treats emergency housing\n",
    "- housing_situation_2_label: with value \"emergency accomodation\". High probability to get 1 or two nights.\n",
    "\n",
    "--------------------\n",
    "\n",
    "\n",
    "Analysis by features\n",
    "\n",
    "\n",
    "A. housing_situation_id\n",
    "- correlation target-housing_situation_id: -0.458581. Strong negative impact. Although the linear numerical relation of the housing_situation_id categories is in my opinion flawed, the strong correlation is explainable as the category with the smallest value \"emergency accomodation\" might be correlated with higher granted_number_of_nights than the rest of the categories, which happen to have higher housing_situation_id values.\n",
    "\n",
    "- housing_situation_2_id: 0.283840. Strong positive impact. Same explanation as housing_situation_id.\n",
    "\n",
    "B. pregnancy\n",
    "- Pregnancy seems not to have a significant direct correlation with target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    obj_train.describe(investigation_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    obj_train.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### housing_situation_2_label\n",
    "\n",
    "- ±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "\n",
    "- ±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "\n",
    "- ±75% (289,870) individuals are \"on the street\"\n",
    "\n",
    "- A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # ±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "    obj_full_train.df[obj_full_train.df['housing_situation_label'] == 'street']\n",
    "\n",
    "    # ±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "    obj_full_train.df.query(\"housing_situation_label == 'street' and housing_situation_2_label == 'on the street'\")\n",
    "\n",
    "    # ±75% (289,870) individuals are \"on the street\"\n",
    "    print(obj_full_train.df['housing_situation_2_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Obs: A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights.\n",
    "\n",
    "    # Impact of feature on target\n",
    "    feature = 'housing_situation_2_label'\n",
    "    mask = obj_full_train.df[feature] == 'emergency accomodation'\n",
    "\n",
    "    # Hist: drop duplicate requests (due to multiple indivs by request)\n",
    "    obj_full_train.df[mask][['request_id', target]].drop_duplicates().hist()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### child_situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'child_situation'\n",
    "\n",
    "    # Display unique values\n",
    "    uniques = obj_train.get_col_uniques(feature)\n",
    "    uniques.sort()\n",
    "    print(\"child_situation possible values:\", *uniques)\n",
    "\n",
    "    # Display distribution\n",
    "    # Obs: Almost any request has child_situation == -1\n",
    "    # hyp: -1 means NaN\n",
    "    dist = obj_train.df[feature].value_counts()\n",
    "    \n",
    "    # Count all non NaNs values\n",
    "    dist_positive = sum(dist[dist.index != -1])\n",
    "    ratio_non_na = dist_positive / obj_train.m\n",
    "    \n",
    "    # Print distribution\n",
    "    print(\"\\nDistribution\\n\", dist)\n",
    "    \n",
    "    # Plot histogram\n",
    "    print(f\"\\n\\nChild_situation non NaN ratio: {round(ratio_non_na * 100, 2)}%\\n\\n\")\n",
    "\n",
    "    # Correlation with target (for non NaNs)\n",
    "    # The proportion of non NaNs is increasing with target values\n",
    "    # The probability of granting more nights is greater when non NaN\n",
    "    dist_grpby = obj_train.df[target].groupby(obj_train.df[feature])\n",
    "    if PLOT_ON:\n",
    "        dist_grpby.hist()\n",
    "        plt.show()\n",
    "\n",
    "    # Study only positive 'child_situation' samples\n",
    "    # TODO: produce a study\n",
    "    mask_pos = obj_train.df['child_situation'] != -1\n",
    "    dist_grpby_pos = obj_train.df[mask_pos][target].groupby(obj_train.df[feature])\n",
    "    if PLOT_ON:\n",
    "        dist_grpby_pos.hist()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### victime_of_violence_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'victim_of_violence_type'\n",
    "    feature_base = 'victim_of_violence'\n",
    "\n",
    "    # Inspect a specific group with violence type \"child\"\n",
    "    # ---------------------------------------------------\n",
    "    # TODO: go further this anecdotical impression\n",
    "    # Obs: \n",
    "    # - violence child can counter intuitively be applied on individuals without child, but awaiting a child.\n",
    "    # - requests seem more likely granted when multiple (non granted) requests have been made in the past\n",
    "    # - requests seem less likely granted when a recent request was granted\n",
    "    # => feature engineer measures to represent these observations\n",
    "\n",
    "    # Mask to filter on child violence only\n",
    "    mask_child_violence = obj_train.df[feature] == 'child'\n",
    "\n",
    "    # Mast to filter group1 entries only\n",
    "    mask_group1 = obj_train.df[mask_child_violence]['group_id'] == '8d79d2cd16e886a947158b5f6e2eff43'\n",
    "\n",
    "    # Sort entries by request_creation_date\n",
    "    grp1_sorted_rq_date = obj_train.df[mask_child][mask_group1].sort_values(by='request_creation_date')\n",
    "\n",
    "    # Get dates and housing values along with target\n",
    "    grp1_sorted_rq_date[[target, 'request_creation_date', 'answer_creation_date', 'housing_situation_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### animal_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'animal_presence'\n",
    "    mask = df_train[feature] == 't'\n",
    "    df_train[mask][[feature, target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requester_type along with group_main_requester_id\n",
    "if it is an urgentist, used to bring individuals to the service, its groups might have higher granted rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### request_backoffice_creator_id\n",
    "this might impact since each people has its own biases (as for the predictions of court decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data\n",
    "\n",
    "Methodology:\n",
    "\n",
    "- Clean-up obj_train.df (initially request dataset)\n",
    "\n",
    "- Feature engineer (using indiv dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaNs\n",
    "\n",
    "Methodology:\n",
    "- inspect NaNs on train set\n",
    "\n",
    "- if pattern detected, apply modifications on train and test sets\n",
    "\n",
    "Observations:\n",
    "- reverse engineering: the system seems to derive group_composition_id from group_composition_label, and both are then necessary linked/redondant => drop group_composition_label\n",
    "\n",
    "Further:\n",
    "- Impute 14 pregnancy NaNs from child_to_come (not useful for the current objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs train summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get Na counts: by feature, by sample\n",
    "    na_ft_train, na_sp_train = obj_train.get_na_counts()\n",
    "    na_ft_test, na_sp_test = obj_test.get_na_counts()\n",
    "    if PRINT_ON:\n",
    "        print('Train: NaNs count by feature\\n\\n', na_ft_train[na_ft_train!=0])\n",
    "        #print('\\n\\nTest: NaNs count by feature\\n\\n', na_ft_test[na_ft_test!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_to_come NaNs\n",
    "\n",
    "Observation\n",
    "- There are 145947 NaNs for child_to_come on the train set (in request)\n",
    "\n",
    "- There are only 14 NaNs for pregnancy in train set (in individuals)\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: child_to_come is True if any indiv of the group is pregnant\n",
    "\n",
    "Conclusion\n",
    "- => Impute child_to_come from the pregnancy in the group of indiv of the request\n",
    "\n",
    "Control\n",
    "- Verify that the imputation is not only setting to 'f':\n",
    "- -> successful: from the 145947 requests, 5375 are set to 't'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Capture the indexes where NaNs\n",
    "    df_train_raw_nas = obj_train.df[obj_train.df['child_to_come'].isna()]\n",
    "    idx_nas = df_train_raw_nas['child_to_come'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # TODO: refactor (this takes ±3min)\n",
    "    # Impute train set\n",
    "    obj_train.impute_child_to_come(df_indiv=individuals_train)\n",
    "    # Impute test set\n",
    "    obj_test.impute_child_to_come(df_indiv=individuals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get number of NaNs imputed as False and True\n",
    "    obj_train.df.loc[idx_nas]['child_to_come'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute housing_situation_label\n",
    "\n",
    "The following code cells are organized as follows for clarity:\n",
    "- Imputation steps\n",
    "\n",
    "- Analysis\n",
    "\n",
    "Observations\n",
    "\n",
    "A. Meta numbers\n",
    "- ±7% (16,748) NaNs for housing_situation_label (request)\n",
    "\n",
    "- 0 NaN for housing_situation_id (request)\n",
    "\n",
    "- 0 NaN for housing_situation_label_2 (individuals)\n",
    "\n",
    "- 0 NaN for housing_situation_id_2 (individuals)\n",
    "\n",
    "- 21 housing_situation_label (request)\n",
    "\n",
    "- 22 housing_situation_id (request)\n",
    "\n",
    "B. Specific ratios\n",
    "- ±10% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "\n",
    "- ±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "\n",
    "C. Analysis 1\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n",
    "\n",
    "D. Analysis 2\n",
    "- housing_situation_2_label can be very diverse when housing_situation_label is NaN (17 over 21 cat)\n",
    "\n",
    "- => housing_situation_label NaNs are not produced in a specific housing_situation_2_label situation\n",
    "\n",
    "E. Analysis 3\n",
    "- all individuals of a same request share the same housing_situation_2_label\n",
    "\n",
    "- => NaNs do not come from a problem of aggregating indiv data\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: the housing situation should logically have an impact on the result\n",
    "\n",
    "- Hyp: proba being on the street is significantly high to always impute NaN with 'street'\n",
    "\n",
    "- Hyp: housing_ids are not sorted in any specific order from which a logic could be derived. Thus, having numerical ids is dangereous and could lead to misinterpretations by the model.\n",
    "\n",
    "Conclusion\n",
    "- => Impute housing_situation_label NaNs as 'street'\n",
    "\n",
    "- => Drop housing_situation_id\n",
    "\n",
    "- => one-hot encode housing_situation_label\n",
    "\n",
    "\n",
    "Further improvements\n",
    "- derive more sub-groups: when a group is not housing_situation_label_2 'on the street', impute the request housing_situation_label with its most often matched value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute NaNs with the single value 'street'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # TODO: impute more properly \n",
    "    \n",
    "    # Impute housing_situation_label NaNs as 'street'\n",
    "    obj_train.df.loc[obj_train.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'\n",
    "    obj_test.df.loc[obj_test.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'\n",
    "\n",
    "    # Drop housing_situation_id\n",
    "    obj_train.df.drop('housing_situation_id', axis=1, inplace=True)\n",
    "    obj_test.df.drop('housing_situation_id', axis=1, inplace=True)\n",
    "\n",
    "    # One-hot encoding is applied later-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the mapping of housing_situation_id - housing_situation_label\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_id - housing_situation_label\n",
    "    map_housing_id_label = obj_train.df.loc[:, ['housing_situation_id', 'housing_situation_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index for clarity\n",
    "    map_housing_id_label = map_housing_id_label.sort_values(by='housing_situation_id')\n",
    "    map_housing_id_label.reset_index(drop=True, inplace=True)\n",
    "    map_housing_id_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze relation between housing_situation_label (request) and housing_situation_2_label (indiv)\n",
    "\n",
    "Make a temporary dataframe with columns:\n",
    "\n",
    "| request_id | gr_nb_nights | hous_id | hous_lab | indiv_id | hous_2id | hous2_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # request [gr_nb_nights, hous_id, hous_lab]\n",
    "    rq = obj_train.df.loc[:, ['granted_number_of_nights',\n",
    "                                'housing_situation_id',\n",
    "                                'housing_situation_label']]\n",
    "\n",
    "    # individuals [request_id, indiv_id, hous_2id, hous2_lab]\n",
    "    ind = individuals_train.loc[:, ['request_id',\n",
    "                                    'individual_id',\n",
    "                                    'housing_situation_2_id',\n",
    "                                    'housing_situation_2_label']]\n",
    "    ind.set_index('request_id', inplace=True)\n",
    "\n",
    "    # Merge request and individuals datasets\n",
    "    obj_full_train = pd.merge(rq, ind, on='request_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Nb of indivs (an indiv is considered a new indiv at each request)\n",
    "    nb_indivs = obj_full_train.shape[0]\n",
    "\n",
    "    # ±6% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "    obj_full_train[obj_full_train['housing_situation_label'].isna()]\n",
    "\n",
    "    # ±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "    df_temp = obj_full_train[obj_full_train[\"housing_situation_label\"].isna()]\n",
    "    df_temp['housing_situation_2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect individuals with housing_situation_2_label \"on the street\":\n",
    "\n",
    "- they can have a very diverse housing_situation (17 categories over a total of 21)\n",
    "\n",
    "- => no pattern to derive from this point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    q = obj_full_train.query(\"housing_situation_label.isna() and housing_situation_2_label != 'on the street'\")\n",
    "\n",
    "    # Count number of categories for housing_situation_2_label\n",
    "    n_cat_2 = len(q.loc[:, 'housing_situation_2_label'].unique())\n",
    "\n",
    "    # Total categories for the feature\n",
    "    n_cat_1 = len(obj_train.get_col_uniques('housing_situation_label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if housing_situation_label NA exist when indiv within a group have different housing_situation_2\n",
    "\n",
    "- no divergence\n",
    "\n",
    "- => when group, all indiv have the same housing_situation_2_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # takes ±1min\n",
    "    if False:\n",
    "        # Get request_id along with its group size\n",
    "        rq_id = obj_full_train.index.value_counts()\n",
    "        for i in range(70000):\n",
    "            # Get ith rq_id\n",
    "            rq_id_i = rq_id.index[0]\n",
    "\n",
    "            # Observe if housing_situation_label same for all the group members\n",
    "            n_uni_grp = len(obj_full_train.loc[rq_id_i]['housing_situation_label'].unique())\n",
    "            n_uni_indiv = len(obj_full_train.loc[rq_id_i]['housing_situation_2_label'].unique())\n",
    "\n",
    "            if n_uni_grp > 1 or n_uni_indiv > 1:\n",
    "                print(i)\n",
    "                print(n_uni_grp, n_uni_indiv)\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further improvements: derive the most probable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_label - housing_situation_2_label\n",
    "    obj_full_train_no_na = obj_full_train[~obj_full_train.housing_situation_label.isna()]\n",
    "    map_housing_labels = obj_full_train_no_na.loc[:, ['housing_situation_label', 'housing_situation_2_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index\n",
    "    map_housing_labels = map_housing_labels.sort_values(by='housing_situation_label')\n",
    "    map_housing_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute long_term_housing_request NaNs\n",
    "\n",
    "Nb NaNs: 165556\n",
    "\n",
    "Type: bool\n",
    "\n",
    "It seems to have no direct impact on target\n",
    "\n",
    "=> drop feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    ft = 'long_term_housing_request'\n",
    "    ma_na = obj_train.df[ft].isna()\n",
    "    ma_true = obj_train.df[ft] == 't'\n",
    "\n",
    "    # Is long_term_housing_request true when 'street' only?\n",
    "    # - No\n",
    "    obj_train.df[ma_true]['housing_situation_id'].value_counts()\n",
    "\n",
    "    # Does ft impact target?\n",
    "    # - Not directly\n",
    "    ct_true   = obj_train.df[ma_true][target].value_counts()\n",
    "    ct_false  = obj_train.df[~ma_true][target].value_counts()\n",
    "    ct_na     = obj_train.df[ma_na][target].value_counts()\n",
    "    ct_non_na = obj_train.df[~ma_na][target].value_counts()\n",
    "\n",
    "    if PRINT_ON:\n",
    "        print(\"ratios target when lt_housing true\")\n",
    "        for elem in ct_true:\n",
    "            print(f\"{round(elem/sum(ct_true)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing false\")\n",
    "        for elem in ct_false:\n",
    "            print(f\"{round(elem/sum(ct_false)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing NaN\")\n",
    "        for elem in ct_na:\n",
    "            print(f\"{round(elem/sum(ct_na)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing not NaN\")\n",
    "        for elem in ct_non_na:\n",
    "            print(f\"{round(elem/sum(ct_non_na)*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    obj_train.df.drop('long_term_housing_request', axis=1, inplace=True)\n",
    "    obj_test.df.drop('long_term_housing_request', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute town NaNs\n",
    "\n",
    "Nb NaNs: 159959\n",
    "\n",
    "categorical: cat_many\n",
    "\n",
    "Obs: The distribution is very uneven\n",
    "\n",
    "hyps:\n",
    "- very probable to live in a town, and ask housing in the district of our town\n",
    "\n",
    "- request_backoffice_creator_id: lives and makes requests in the same town, if the missing town is found in another request, all other NaNs with this backoffice_creator can be imputed properly\n",
    "\n",
    "- individual_id: might have missed town info in a request, but not in another (if requests are close, the probability to live in the same town is high)\n",
    "\n",
    "=> attribute the most probable town based on request district\n",
    "\n",
    "- 1 => build mapping of town-district pairs\n",
    "\n",
    "- 2 => attribute the corresponding pair for each NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Check that all values are available for district\n",
    "    # - Yes\n",
    "    sum(obj_full_train.df[ma_na]['district'].isna()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # Build mapping town-distric\n",
    "    mapping_town_district_train = obj_train.get_features_mapping('district', 'town')\n",
    "\n",
    "    # Fill 'town' NaNs with the most frequent occurence\n",
    "    # in the pair feature 'district'. Use the mapping\n",
    "    obj_train.fill_na_most_freq_pair('town', 'district', \n",
    "                                    mapping = mapping_town_district_train,\n",
    "                                    inplace = True)\n",
    "    obj_test.fill_na_most_freq_pair('town', 'district',\n",
    "                                    mapping = mapping_town_district_train,\n",
    "                                    inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute victim_of_violence_type NaNs\n",
    "\n",
    "Nb NaNs: 234175\n",
    "\n",
    "Hyp: is NaN if victim_of_violence is 'f'\n",
    "\n",
    "=> Set a specific value to NaNs where victim_of_violence is 'f', which will later be transformed into a boolean\n",
    "\n",
    "=> Set another specific value to NaNs where victim_of_violence is 't', IDEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Obs: the grand majority of victim_of_violence_type NaNs comes\n",
    "    # from the absence of violence (trivial)\n",
    "    print(\"victim bool distribution\\n\",\n",
    "            obj_train.df['victim_of_violence'].value_counts())\n",
    "    print(\"\\nvictim type NaNs\\n\",\n",
    "            obj_train.df['victim_of_violence_type'].isna().value_counts())\n",
    "\n",
    "    # For the remaining victim_of_violence_type NaNs\n",
    "    # only  half requests are not granted when victim_of_violence 't',\n",
    "    remaining_nans = obj_train.df[obj_train.df['victim_of_violence'] == 't']\\\n",
    "                                [obj_train.df['victim_of_violence_type'].isna()]\n",
    "    \n",
    "    print(\"\\nRemaining Nans\\n\", remaining_nans[target].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    feature = 'victim_of_violence_type'\n",
    "    feature_base = 'victim_of_violence'\n",
    "\n",
    "    # Impute NaNs corresponding to no violence signaled by 'no violence'\n",
    "    idx_na_no_violence_train = obj_train.df[obj_train.df[feature_base] == 'f'][obj_train.df[feature].isna()].index\n",
    "    idx_na_no_violence_test = obj_test.df[obj_test.df[feature_base] == 'f'][obj_test.df[feature].isna()].index\n",
    "    obj_train.df.loc[idx_na_no_violence_train, feature] = 'no violence'\n",
    "    obj_test.df.loc[idx_na_no_violence_test, feature] = 'no violence'\n",
    "\n",
    "    # Impute NaNs corresponding to a lack of specification, but with violence signaled by 'no detail'\n",
    "    idx_na_no_detail_train = obj_train.df[obj_train.df[feature_base] == 't'][obj_train.df[feature].isna()].index\n",
    "    idx_na_no_detail_test = obj_test.df[obj_test.df[feature_base] == 't'][obj_test.df[feature].isna()].index\n",
    "    obj_train.df.loc[idx_na_no_detail_train, feature] = 'no detail'\n",
    "    obj_test.df.loc[idx_na_no_detail_test, feature] = 'no detail'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_situation \n",
    "(hyp: -1 values are NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    ft_child = 'child_situation'\n",
    "    ft_violence = 'victim_of_violence_type'\n",
    "\n",
    "    # child_situation might be linked with:\n",
    "    # - group_composition_id: 58 combinations with ft\n",
    "    # - social_situation_id: no, it is redondant with group_id\n",
    "    # - victim_of_violence_type (if child): 34 combinations with ft (better)\n",
    "    obj_train.df[ft_child].value_counts()\n",
    "\n",
    "    # Get combinations for child_situation and victim_of_violence_type\n",
    "    df_temp = obj_train.df[[ft_child, ft_violence]]\\\n",
    "                            .sort_values(by = ft_violence)\n",
    "    df_temp.drop_duplicates(ignore_index=True)\\\n",
    "                            .sort_values(by = ft_violence)\n",
    "\n",
    "    # victim_of_violence_type\n",
    "    # Obs: only child_situation -1 and 10 (ie. only 10)\n",
    "    ma_child = df_temp[ft_violence] == 'child'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    ft_child = 'child_situation'\n",
    "    ft_violence = 'victim_of_violence_type'\n",
    "\n",
    "    # Hyp: -1 (NaNs) for child_situation should be 10 when victim_of_violence_type 'child'\n",
    "    # => replace child_situation by 10 when victim_of_violence_type 'child'\n",
    "    idx_child_train = obj_train.df[obj_train.df[ft_violence] == 'child'].index\n",
    "    idx_child_test = obj_test.df[obj_test.df[ft_violence] == 'child'].index\n",
    "    obj_train.df.loc[idx_child_train, ft_child] = 10\n",
    "    obj_test.df.loc[idx_child_test, ft_child] = 10\n",
    "\n",
    "    # Idem for 'family'\n",
    "    idx_family_train = obj_train.df[obj_train.df[ft_violence] == 'family'].index\n",
    "    idx_family_test = obj_test.df[obj_test.df[ft_violence] == 'family'].index\n",
    "    obj_train.df.loc[idx_family_train, ft_child] = 10\n",
    "    obj_test.df.loc[idx_family_test, ft_child] = 10\n",
    "\n",
    "    # TODO: impute the rest (majority :( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute remaining test set NaNs\n",
    "(that have no equivalent in train set, and thus can't be studied to build a clever imputation method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement method based on train set logic for any feature\n",
    "obj_train.set_default_na_vals()\n",
    "\n",
    "# Transfer default NaNs to test object\n",
    "obj_test.default_na_vals = obj_train.default_na_vals\n",
    "\n",
    "# Impute any remaining NaN based on its default value\n",
    "obj_test.impute_nans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop answer creation date\n",
    "hyp: the variable is not available at prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of the competition, is it expected to be used?\n",
    "if FUTURE_PRED:\n",
    "    obj_train.df.drop('answer_creation_date', axis=1, inplace=True)\n",
    "    obj_test.df.drop('answer_creation_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete old samples\n",
    "(if it was to predict future requests (> 2020))\n",
    "- Train/test split being done randomly (≠ historically), it is important for this competition to train the model on the whole train set (don't remove old samples)\n",
    "- Delete samples with group_creation_date < 2015, since it is very unlikely that current demands are treated like +5 years ago (social services evolve)\n",
    "- Threshold date: see if later is better, potential gains from domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FUTURE_PRED:\n",
    "    # Drop samples with year < 2015\n",
    "    old_samples = obj_train.df[obj_train.df.group_creation_date.dt.year < 2015]\n",
    "    obj_train.df.drop(old_samples.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender\n",
    "\n",
    "- => Only females are possibly pregnant, thus 30 males have made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Retrieve the individual ids, and correct for male -> pregnancy = 0\n",
    "#obj_train.df['gender'].groupby(obj_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterize large categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make clusters then transform using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dates\n",
    "- into linear numerical features (year, month)\n",
    "\n",
    "- and into categorical features (hot_season, col_season:T/F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features: Dates to year, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns of date type\n",
    "list_date_cols = [\n",
    "    'request_creation_date',\n",
    "    'group_creation_date'\n",
    "]\n",
    "\n",
    "# Don't use the feature if trying to build robust in-production model\n",
    "if not FUTURE_PRED:\n",
    "    list_date_cols.append('answer_creation_date')\n",
    "\n",
    "# Transform date type: string to timestamp\n",
    "for col in list_date_cols:\n",
    "    obj_train.df[col] = pd.to_datetime(obj_train.df[col])\n",
    "    obj_test.df[col] = pd.to_datetime(obj_test.df[col])\n",
    "\n",
    "# Create feature: 'year'\n",
    "for col in list_date_cols:\n",
    "    obj_train.df[col[:-4]+'year'] = obj_train.df[col].dt.year\n",
    "    obj_test.df[col[:-4]+'year'] = obj_test.df[col].dt.year\n",
    "\n",
    "# Create feature: 'month'\n",
    "for col in list_date_cols:\n",
    "    obj_train.df[col[:-4]+'month'] = obj_train.df[col].dt.month\n",
    "    obj_test.df[col[:-4]+'month'] = obj_test.df[col].dt.month\n",
    "\n",
    "# Drop raw features of type date\n",
    "for col in list_date_cols:\n",
    "    obj_train.df.drop(col, axis=1, inplace=True)\n",
    "    obj_test.df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feats: hot_season, cold_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create district_grant_ratio and town_grant_ratio\n",
    "\n",
    "Type:\n",
    "- num (float), can be linearly separable\n",
    "\n",
    "Obs:\n",
    "- district_grant_ratio: has a large impact, with districts granting more nights than there are requests and some refusing way more often\n",
    "\n",
    "- town_grant_ratio: has a large impact, with nights granted more for individuals from a specific towns (eg. Amiens is 4x)\n",
    "\n",
    "Hyp:\n",
    "- it is a sort of district emergency housing capacity measurement against the emergency housing demand\n",
    "\n",
    "- it should be very close, redondant? Yes in part, the correlation is very high (88%), but the discrepancies might come from valuable information\n",
    "\n",
    "- => create ratio of the distance between town and district of a request\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature district_grant_ratio\n",
    "obj_train.create_ft_grant_ratio('district')\n",
    "obj_test.create_ft_grant_ratio('district')\n",
    "\n",
    "# Create new feature town_grant_ratio\n",
    "obj_train.create_ft_grant_ratio('town')\n",
    "obj_test.create_ft_grant_ratio('town')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: distance between town and district\n",
    "or a simpler version: if town is from this district or another\n",
    "\n",
    "- if town in district: 0\n",
    "- else: 1\n",
    "\n",
    "Since there are 1116 towns, doing the mapping would take 3h if 10s by town\n",
    "\n",
    "=> another time, or say, let the model firgure it out <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create town_capacity_left\n",
    "This can be computed on the month or the year. It provides a guess of the number of nights that can be granted at time of request (using past request then)\n",
    "\n",
    "Hyp: it might be the most impactful feature, since the selectivity based on personal criteria is lowered or inexistant when there is a large emergency housing capacity left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Town and District to regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: group_age_max, group_age_min\n",
    "\n",
    "Based on individuals information birth_month, birth_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of indivs in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past requests by indivs forming the group of the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Single individual\n",
    "\n",
    "# Get number of ALL requests of indiv with max n_requests\n",
    "#ind_id = obj_full_train['individual_id'].value_counts().index[0]\n",
    "\n",
    "# Watch request made by the same indiv\n",
    "#obj_full_train[obj_full_train['individual_id'] == ind_id]\n",
    "\n",
    "# TODO: Past requests only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past granted request by indivs forming the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop numerical columns\n",
    "(that can't be used properly, or untill transformation methods are implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: transform before drop: request_backoffice_creator_id\n",
    "list_drop = [\n",
    "    'district',\n",
    "    'town',\n",
    "    'group_id',\n",
    "    'group_main_requester_id',\n",
    "    'request_backoffice_creator_id',\n",
    "    'social_situation_id'\n",
    "]\n",
    "\n",
    "for feature in list_drop:\n",
    "    obj_train.df.drop(feature, axis=1, inplace=True)\n",
    "    obj_test.df.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical features\n",
    "Prepare data to feed models\n",
    "\n",
    "- booleans: replace by (1, 0)\n",
    "\n",
    "- 2 < cats < 11: one-hot encoding\n",
    "\n",
    "- No transform on features with more than 11 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show standard data type: True\n",
    "# Show personalized (provide insight on information level)\n",
    "STANDARD = False\n",
    "\n",
    "if ANALYZE_ON:\n",
    "    if STANDARD:\n",
    "        # Display standard data types\n",
    "        print(obj_train.df.dtypes)\n",
    "    else:\n",
    "        # Display col name along its type (bool, cat, num, empty)\n",
    "        for col, col_type in zip(obj_train.df.columns, obj_train.get_cols_type()):\n",
    "            print(col_type, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform all categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traform categorical features:\n",
    "# - booleans: ('t', 't') into (1, 0)\n",
    "# - categorical with few/med classes: one-hot encoding\n",
    "bools_train, failed_train = obj_train.transform_categories(\n",
    "                                        target=obj_train.target)\n",
    "bools_test, failed_test = obj_test.transform_categories(\n",
    "                                        target=obj_test.target)\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "obj_train.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "obj_test.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Export data\n",
    "if EXPORT_DATA:\n",
    "    obj_train.export_data('data/data_train_preprocessed.csv')\n",
    "    obj_test.export_data('data/data_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data, tools, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between selecting or dropping columns\n",
    "SELECT = True\n",
    "\n",
    "# Drop only the following features, keep the others\n",
    "# -------------------------------------------------\n",
    "if not SELECT:\n",
    "    drop_features = [\n",
    "        'request_creation_year',\n",
    "        'group_creation_year',\n",
    "        'answer_creation_year'\n",
    "    ]\n",
    "    df_train.drop(*[drop_features], axis=1, inplace=True)\n",
    "    df_test.drop(*[drop_features], axis=1, inplace=True)\n",
    "\n",
    "else:\n",
    "    # Select and keep only the following features\n",
    "    # -------------------------------------------\n",
    "    use_features = [\n",
    "        'district_grant_ratio'\n",
    "    ]\n",
    "    # Append target col to the list of columns to keep\n",
    "    use_cols = use_features + [obj_train.target]\n",
    "    \n",
    "    # Create df with selected cols only\n",
    "    df_train = obj_train.df[use_cols]\n",
    "    df_test  = obj_test.df[use_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and tensorize data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train/cross-validation split:\n",
    "# .8 means 80% of samples in the train set,\n",
    "# and the remaining, 20%, in validation set\n",
    "TRAIN_VAL_SPLIT = .8\n",
    "\n",
    "# Reset the target feature\n",
    "# (in case it has been changed during debugging)\n",
    "target = obj_train.target\n",
    "\n",
    "# Mask - select all features columns but the target\n",
    "ma_ft = df_train.columns != target\n",
    "\n",
    "# Separate target and features\n",
    "X_train_full = df_train.loc[:,ma_ft]\n",
    "X_test       = df_test.loc[:,ma_ft]\n",
    "Y_train_full = df_train.loc[:,target]\n",
    "Y_test       = df_test.loc[:,target]\n",
    "\n",
    "# Split train into: train / cross-val sets\n",
    "n_train = round(X_train_full.shape[0] * TRAIN_VAL_SPLIT)\n",
    "X_train = X_train_full[:n_train]\n",
    "X_val   = X_train_full[n_train:]\n",
    "Y_train = Y_train_full[:n_train]\n",
    "Y_val   = Y_train_full[n_train:]\n",
    "\n",
    "# Transform pandas dataframes into torch tensors\n",
    "X_train = torch.from_numpy(X_train.values)\n",
    "X_val   = torch.from_numpy(X_val.values)\n",
    "X_test  = torch.from_numpy(X_test.values)\n",
    "Y_train = torch.from_numpy(Y_train.values)\n",
    "Y_val   = torch.from_numpy(Y_val.values)\n",
    "Y_test  = torch.from_numpy(Y_test.values)\n",
    "\n",
    "# Cast all to float type\n",
    "X_train = X_train.float()\n",
    "X_val   = X_val.float()\n",
    "X_test  = X_test.float()\n",
    "Y_train = Y_train.float()\n",
    "Y_val   = Y_val.float()\n",
    "Y_test  = Y_test.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate datasets\n",
    "dataset_train = cobra.Dataset(X=X_train, Y=Y_train)\n",
    "dataset_val   = cobra.Dataset(X=X_val,   Y=Y_val)\n",
    "dataset_test  = cobra.Dataset(X=X_test,  Y=Y_test)\n",
    "\n",
    "# Instantiate data loaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size = dataset_train.len)\n",
    "dataloader_val   = torch.utils.data.DataLoader(dataset_val,   batch_size = dataset_val.len)\n",
    "dataloader_test  = torch.utils.data.DataLoader(dataset_test,  batch_size = dataset_test.len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'train': {'accuracy': None, 'loss_model': None, 'loss_compet': None},\n 'eval': {'accuracy': None, 'loss_model': None, 'loss_compet': None},\n 'test': {'accuracy': None, 'loss_model': None, 'loss_compet': None}}"
     },
     "metadata": {},
     "execution_count": 206
    }
   ],
   "source": [
    "# Set evaluation weights, penalize higher values harder\n",
    "weights = [1, 10, 100, 1000]  # hard \n",
    "weights = [.23217, .16407, .7497, .517]  # smoother\n",
    "\n",
    "# Cast weights to tensor format\n",
    "class_weights = torch.FloatTensor(weights)\n",
    "\n",
    "# Set evaluation weighted criterion\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Set hidden layers number and size\n",
    "layers = [X_train.shape[1], 1, N_TARGET_CLASS]\n",
    "\n",
    "# Calculate the number of weights\n",
    "#n_weights = calculate_n_weights(layers)\n",
    "if PRINT_ON:\n",
    "    print(n_weights)\n",
    "\n",
    "# Reimport module\n",
    "importlib.reload(cobra)\n",
    "\n",
    "# Initialize model and weights\n",
    "model = cobra.NN(layers, p=0.3)\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                        lr=0.08,\n",
    "                        momentum=0.8,\n",
    "                        weight_decay=0)\n",
    "\n",
    "# Define sets\n",
    "sets_epochs = ['train', 'eval', 'test']\n",
    "sets_batchs = ['train', 'eval']\n",
    "\n",
    "# Define metrics (name and func)\n",
    "metrics = {'accuracy': cobra.compute_accuracy,\n",
    "           'loss_model': criterion,\n",
    "           'loss_compet': cobra.competition_scorer}\n",
    "\n",
    "# Reset performances history\n",
    "monitor_epochs = cobra.Monitoring(sets=sets_epochs, metrics=metrics)\n",
    "monitor_batchs = cobra.Monitoring(sets=sets_batchs, metrics=metrics)\n",
    "\n",
    "# Show storing format\n",
    "monitor_epochs.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0 - train acc: 14.4569 - eval acc: 14.4569 - train mod loss: 1.4512 - eval mod loss: 1.4512 - train comp loss: 13.2654 - eval comp loss: 13.2654\nEpoch 1 - train acc: 14.4569 - eval acc: 14.4569 - train mod loss: 1.4333 - eval mod loss: 1.4333 - train comp loss: 13.633 - eval comp loss: 13.633\nEpoch 2 - train acc: 14.4569 - eval acc: 14.4569 - train mod loss: 1.4103 - eval mod loss: 1.4103 - train comp loss: 13.8606 - eval comp loss: 13.8606\nEpoch 3 - train acc: 14.4569 - eval acc: 14.4569 - train mod loss: 1.3845 - eval mod loss: 1.3845 - train comp loss: 14.0242 - eval comp loss: 14.0242\nEpoch 4 - train acc: 15.221 - eval acc: 15.221 - train mod loss: 1.3569 - eval mod loss: 1.3569 - train comp loss: 14.1507 - eval comp loss: 14.1507\nEpoch 5 - train acc: 15.221 - eval acc: 15.221 - train mod loss: 1.3299 - eval mod loss: 1.3299 - train comp loss: 14.2529 - eval comp loss: 14.2529\nEpoch 6 - train acc: 15.2231 - eval acc: 15.2231 - train mod loss: 1.3049 - eval mod loss: 1.3049 - train comp loss: 14.3397 - eval comp loss: 14.3397\nEpoch 7 - train acc: 15.2567 - eval acc: 15.2567 - train mod loss: 1.2819 - eval mod loss: 1.2819 - train comp loss: 14.4783 - eval comp loss: 14.4783\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-207-5b7d5aae5347>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# --------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mn_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/shortcuts/virtualenvs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/shortcuts/virtualenvs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/shortcuts/virtualenvs/pytorch/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_index\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/shortcuts/virtualenvs/pytorch/lib/python3.6/site-packages/torch/utils/data/sampler.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "n_epochs = 10\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # Reset batchs performances\n",
    "    monitor_batchs.reset()\n",
    "\n",
    "    # Training\n",
    "    # --------\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_train):\n",
    "\n",
    "        # Predict\n",
    "        predictions = model(x)\n",
    "\n",
    "        # Evaluate model and compute metrics\n",
    "        monitor_batchs.evaluate(predictions, labels, 'train')\n",
    "        \n",
    "        # Get model loss\n",
    "        loss = monitor_batchs.metrics['train']['loss_model']\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Backpropagate\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    # ----------\n",
    "    with torch.no_grad():\n",
    "        for n_batch, (x, labels) in enumerate(dataloader_val):\n",
    "            \n",
    "            # Predict on the eval set\n",
    "            predictions = model(x)\n",
    "            \n",
    "            # Evaluate model and compute metrics\n",
    "            monitor_batchs.evaluate(predictions, labels, 'eval')\n",
    "            \n",
    "            # Get model loss\n",
    "            loss = monitor_batchs.metrics['eval']['loss_model']\n",
    "\n",
    "\n",
    "    # Compute & store: train and eval losses for the epoch\n",
    "    monitor_epochs.compute(monitor_batchs)\n",
    "    \n",
    "    # Display scores\n",
    "    print(f\"Epoch {epoch} - \"\\\n",
    "          f\"train acc: {monitor_epochs.metrics['train']['accuracy']} - \"\\\n",
    "          f\"eval acc: {monitor_epochs.metrics['eval']['accuracy']} - \"\\\n",
    "          f\"train mod loss: {monitor_epochs.metrics['train']['loss_model']} - \"\\\n",
    "          f\"eval mod loss: {monitor_epochs.metrics['eval']['loss_model']} - \"\\\n",
    "          f\"train comp loss: {monitor_epochs.metrics['train']['loss_compet']} - \"\\\n",
    "          f\"eval comp loss: {monitor_epochs.metrics['eval']['loss_compet']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 378.465625 248.518125 \nL 378.465625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"ma00deabc56\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#ma00deabc56\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(48.502557 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"103.270864\" xlink:href=\"#ma00deabc56\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(96.908364 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"154.857921\" xlink:href=\"#ma00deabc56\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(148.495421 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"206.444978\" xlink:href=\"#ma00deabc56\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(200.082478 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"258.032035\" xlink:href=\"#ma00deabc56\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(251.669535 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"309.619092\" xlink:href=\"#ma00deabc56\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(303.256592 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"361.206149\" xlink:href=\"#ma00deabc56\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(354.843649 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m343f49e974\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m343f49e974\" y=\"203.706335\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 1.15 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 207.505554)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m343f49e974\" y=\"173.011813\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.20 -->\n      <g transform=\"translate(7.2 176.811031)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m343f49e974\" y=\"142.31729\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.25 -->\n      <g transform=\"translate(7.2 146.116508)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m343f49e974\" y=\"111.622767\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.30 -->\n      <g transform=\"translate(7.2 115.421986)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m343f49e974\" y=\"80.928244\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.35 -->\n      <g transform=\"translate(7.2 84.727463)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m343f49e974\" y=\"50.233721\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.40 -->\n      <g transform=\"translate(7.2 54.03294)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m343f49e974\" y=\"19.539198\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.45 -->\n      <g transform=\"translate(7.2 23.338417)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p52fbb17740)\" d=\"M 51.683807 17.083636 \nL 56.842513 29.72978 \nL 62.001218 43.23537 \nL 67.159924 59.073744 \nL 72.31863 75.955731 \nL 77.477335 92.837719 \nL 82.636041 106.89581 \nL 87.794747 122.058905 \nL 92.953452 134.766437 \nL 98.112158 146.062021 \nL 103.270864 154.779266 \nL 108.42957 162.88262 \nL 113.588275 170.187916 \nL 118.746981 176.142654 \nL 123.905687 180.439887 \nL 129.064392 184.430175 \nL 134.223098 187.867962 \nL 139.381804 191.060192 \nL 144.540509 192.901863 \nL 149.699215 195.05048 \nL 154.857921 197.567431 \nL 160.016627 198.119932 \nL 165.175332 199.900215 \nL 170.334038 200.698272 \nL 175.492744 202.478554 \nL 180.651449 202.724111 \nL 185.810155 204.013281 \nL 190.968861 205.179673 \nL 196.127566 205.793563 \nL 201.286272 206.714399 \nL 206.444978 207.021344 \nL 211.603684 207.2669 \nL 216.762389 207.512456 \nL 221.921095 207.880791 \nL 227.079801 208.187736 \nL 232.238506 208.494681 \nL 237.397212 209.599684 \nL 242.555918 209.722462 \nL 247.714623 210.090796 \nL 252.873329 210.213574 \nL 258.032035 210.520519 \nL 263.190741 210.643298 \nL 268.349446 210.950243 \nL 273.508152 211.011632 \nL 278.666858 211.318577 \nL 283.825563 212.300802 \nL 288.984269 212.362191 \nL 294.142975 212.42358 \nL 299.30168 212.791914 \nL 304.460386 212.976081 \nL 309.619092 213.03747 \nL 314.777798 212.976081 \nL 319.936503 212.976081 \nL 325.095209 213.098859 \nL 330.253915 213.160248 \nL 335.41262 213.098859 \nL 340.571326 213.405805 \nL 345.730032 213.344416 \nL 350.888737 213.405805 \nL 356.047443 213.589972 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p52fbb17740)\" d=\"M 51.683807 29.791169 \nL 56.842513 43.910649 \nL 62.001218 59.749023 \nL 67.159924 76.6924 \nL 72.31863 93.267442 \nL 77.477335 108.614704 \nL 82.636041 122.734184 \nL 87.794747 135.380327 \nL 92.953452 146.246189 \nL 98.112158 155.82288 \nL 103.270864 163.680678 \nL 108.42957 170.494862 \nL 113.588275 176.081265 \nL 118.746981 180.86961 \nL 123.905687 184.921287 \nL 129.064392 188.236296 \nL 134.223098 190.998803 \nL 139.381804 193.331587 \nL 144.540509 195.541592 \nL 149.699215 197.260486 \nL 154.857921 198.795212 \nL 160.016627 200.145771 \nL 165.175332 201.557719 \nL 170.334038 202.294387 \nL 175.492744 203.39939 \nL 180.651449 204.320226 \nL 185.810155 205.056894 \nL 190.968861 205.732174 \nL 196.127566 206.284675 \nL 201.286272 207.082733 \nL 206.444978 207.389678 \nL 211.603684 207.94218 \nL 216.762389 208.55607 \nL 221.921095 208.985793 \nL 227.079801 209.476906 \nL 232.238506 209.722462 \nL 237.397212 210.213574 \nL 242.555918 210.397741 \nL 247.714623 210.888854 \nL 252.873329 211.011632 \nL 258.032035 211.502744 \nL 263.190741 211.686911 \nL 268.349446 211.809689 \nL 273.508152 212.178024 \nL 278.666858 212.300802 \nL 283.825563 212.669136 \nL 288.984269 212.853303 \nL 294.142975 212.914692 \nL 299.30168 213.221637 \nL 304.460386 213.405805 \nL 309.619092 213.467194 \nL 314.777798 213.589972 \nL 319.936503 213.589972 \nL 325.095209 213.958306 \nL 330.253915 214.081084 \nL 335.41262 214.142473 \nL 340.571326 214.203862 \nL 345.730032 214.32664 \nL 350.888737 214.449418 \nL 356.047443 214.756364 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p52fbb17740\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Plot train and validation losses history\n",
    "plt.plot(loss_epochs['train'])\n",
    "plt.plot(loss_epochs['eval'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nProbas predicted:\n [[0.38377    0.18623127 0.3964807  0.03351799]\n [0.3819571  0.18535154 0.39460778 0.03808346]\n [0.38377    0.18623127 0.3964807  0.03351799]\n ...\n [0.38377    0.18623127 0.3964807  0.03351799]\n [0.38377    0.18623127 0.3964807  0.03351799]\n [0.380693   0.1847381  0.39330178 0.04126702]]\n\nQuantity of unique probas: 31\n\n6 first uniques:\n [[0.37873518 0.18378803 0.39127913 0.04619766]\n [0.378821   0.18382968 0.3913678  0.04598145]\n [0.37890646 0.18387115 0.3914561  0.04576621]\n [0.3794113  0.18411614 0.39197767 0.0444948 ]\n [0.37949416 0.18415634 0.39206326 0.0442862 ]\n [0.3796587  0.1842362  0.39223325 0.04387179]]\n\nvalues used for predictions: 2\n\nAccuracy model 15.7374%\n\n\nPredictions:\n2    47638\nName: y_pred, dtype: int64\n\ntarget:\n0    23217\n1    16407\n2     7497\n3      517\nName: y, dtype: int64\n"
    }
   ],
   "source": [
    "# Transform tensors to numpy arrays\n",
    "y_pred = functional.softmax(predictions).detach().numpy()\n",
    "y = labels.numpy()\n",
    "\n",
    "# Display probas predicted\n",
    "print('\\nProbas predicted:\\n', y_pred)\n",
    "\n",
    "# Display the number of uniques probas (see the diversity of predictions)\n",
    "print(\"\\nQuantity of unique probas:\", len(np.unique(functional.softmax(predictions).detach().numpy(), axis=0)))\n",
    "print(\"\\n6 first uniques:\\n\", np.unique(functional.softmax(predictions).detach().numpy(), axis=0)[:6])\n",
    "\n",
    "# Transform array of predicted probas into vector of ints\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "\n",
    "# Values used\n",
    "print('\\nvalues used for predictions:', *np.unique(y_pred))\n",
    "\n",
    "# Transform arrays into dataframes\n",
    "df_results = pd.DataFrame({'y': y, 'y_pred': y_pred})\n",
    "\n",
    "# Compute accuracy ratio\n",
    "print(f'\\nAccuracy model {round(100 * sum(y_pred == y)/len(y), 4)}%')\n",
    "\n",
    "# Display value counts\n",
    "print('\\n\\nPredictions:')\n",
    "print(df_results['y_pred'].value_counts())\n",
    "print('\\ntarget:')\n",
    "print(df_results['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "On the test set (and no longer validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists batchs loss\n",
    "loss_batchs = {'test': []}\n",
    "\n",
    "# Test set\n",
    "# --------\n",
    "with torch.no_grad():\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_test):\n",
    "        # Predict on the test set\n",
    "        predictions = model(x)\n",
    "        \n",
    "        # Compute batch loss\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss_compet = competition_scorer(functional.softmax(predictions).detach().numpy(), labels.numpy())\n",
    "        \n",
    "        # Add batch loss to the list of current epoch\n",
    "        loss_batchs['test'].append(round(loss.item(), 4))\n",
    "\n",
    "# Compute train and test losses for the epoch, and add to epochs list\n",
    "loss_test = torch.tensor(loss_batchs['test'], dtype=float).mean()\n",
    "loss_test = round(loss_test.item(), 4)\n",
    "\n",
    "print(f\"Avg loss test: {loss_test}\\n\")\n",
    "print(f\"compet loss: {round(loss_compet, 4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights/weights_new.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with benchmarks preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = Y_train.shape[0]\n",
    "m_val = Y_val.shape[0]\n",
    "m_test = Y_test.shape[0]\n",
    "\n",
    "# Create numpy copy of target (from tensors)\n",
    "y_train = Y_train.numpy().astype(np.int_)\n",
    "y_val = Y_val.numpy().astype(np.int_)\n",
    "y_test = Y_test.numpy().astype(np.int_)\n",
    "\n",
    "# Random uniform train/test\n",
    "random_preds_train = np.random.uniform(size=(Y_train.shape[0], 4))\n",
    "random_preds_val = np.random.uniform(size=(Y_val.shape[0], 4))\n",
    "random_preds_test = np.random.uniform(size=(Y_test.shape[0], 4))\n",
    "\n",
    "# Create empty benchmark dumb\n",
    "dumb_preds_train = np.zeros((m_train, 4)) + .49\n",
    "dumb_preds_val = np.zeros((m_val, 4)) + .49\n",
    "dumb_preds_test = np.zeros((m_test, 4)) + .49\n",
    "\n",
    "# Benchmark dumb predict always 0 nights (the most )\n",
    "dumb_preds_train[range(m_train), 0] = .5\n",
    "dumb_preds_val[range(m_val), 0] = .5\n",
    "dumb_preds_test[range(m_test), 0] = .5\n",
    "\n",
    "# Evaluate preds\n",
    "# Random\n",
    "random_loss_train = competition_scorer(random_preds_train, y_train)\n",
    "random_loss_val = competition_scorer(random_preds_val, y_val)\n",
    "random_loss_test = competition_scorer(random_preds_test, y_test)\n",
    "# Dumb\n",
    "dumb_loss_train = competition_scorer(dumb_preds_train, y_train)\n",
    "dumb_loss_val = competition_scorer(dumb_preds_val, y_val)\n",
    "dumb_loss_test = competition_scorer(dumb_preds_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Random preds\")\n",
    "print(round(random_loss_train, 4))\n",
    "print(round(random_loss_val, 4))\n",
    "print(round(random_loss_test, 4))\n",
    "\n",
    "print(\"Dumb preds\\n\")\n",
    "print(round(dumb_loss_train, 4))\n",
    "print(round(dumb_loss_val, 4))\n",
    "print(round(dumb_loss_test, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn Tree and RF models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model' parameters\n",
    "clf_tree = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=None,\n",
    "    class_weight=None)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_rforest = RandomForestClassifier(\n",
    "    max_depth=2,\n",
    "    random_state=0,\n",
    "    n_estimators=300)\n",
    "\n",
    "# Transform type from tensor to numpy\n",
    "if False:\n",
    "    X_train = X_train.numpy()\n",
    "    X_val = X_val.numpy()\n",
    "    X_test = X_test.numpy()\n",
    "    Y_train = Y_train.numpy()\n",
    "    Y_val = Y_val.numpy()\n",
    "    Y_test = Y_test.numpy()\n",
    "\n",
    "# Transform categorical target into a one-hot vector\n",
    "if False:\n",
    "    Y_train = to_one_hot(Y_train, min_val=0, max_val=1, to_int=True)\n",
    "    Y_val = to_one_hot(Y_val, min_val=0, max_val=1, to_int=True)\n",
    "    Y_test = to_one_hot(Y_test, min_val=0, max_val=1, to_int=True)\n",
    "\n",
    "# Train the tree model\n",
    "clf_tree = clf_tree.fit(X_train, Y_train)\n",
    "clf_rforest = clf_rforest.fit(X_train, Y_train)\n",
    "\n",
    "# Yield tree train/val/test predictions\n",
    "preds_train_tree = clf_tree.predict(X_train)\n",
    "preds_val_tree = clf_tree.predict(X_val)\n",
    "preds_test_tree = clf_tree.predict(X_test)\n",
    "\n",
    "# Yield rforest train/val/test predictions\n",
    "preds_train_rforest = clf_rforest.predict(X_train)\n",
    "preds_val_rforest = clf_rforest.predict(X_val)\n",
    "preds_test_rforest = clf_rforest.predict(X_test)\n",
    "\n",
    "# Clip tree predictions to enhance score without changing predicted label\n",
    "preds_train_tree = preds_train_tree.clip(.45, .75)\n",
    "preds_val_tree = preds_val_tree.clip(.45, .75)\n",
    "preds_test_tree = preds_test_tree.clip(.45, .75)\n",
    "\n",
    "# Clip rforest predictions to enhance score without changing predicted label\n",
    "preds_train_rforest = preds_train_rforest.clip(.45, .75)\n",
    "preds_val_rforest = preds_val_rforest.clip(.45, .75)\n",
    "preds_test_rforest = preds_test_rforest.clip(.45, .75)\n",
    "\n",
    "# Evaluate tree train/val/test\n",
    "score_train_tree = competition_scorer(preds_train_tree, Y_train.argmax(axis=1))\n",
    "score_val_tree = competition_scorer(preds_val_tree, Y_val.argmax(axis=1))\n",
    "score_test_tree = competition_scorer(preds_test_tree, Y_test.argmax(axis=1))\n",
    "\n",
    "# Evaluate rforest train/val/test\n",
    "score_train_rforest = competition_scorer(preds_train_rforest, Y_train.argmax(axis=1))\n",
    "score_val_rforest = competition_scorer(preds_val_rforest, Y_val.argmax(axis=1))\n",
    "score_test_rforest = competition_scorer(preds_test_rforest, Y_test.argmax(axis=1))\n",
    "\n",
    "# Display results\n",
    "print(\"tree\")\n",
    "print(f'train score: {score_train_tree:.2f}')\n",
    "print(f'val score: {score_val_tree:.2f}')\n",
    "print(f'test score: {score_test_tree:.2f}')\n",
    "print(\"\\nrforest\")\n",
    "print(f'train score: {score_train_rforest:.2f}')\n",
    "print(f'val score: {score_val_rforest:.2f}')\n",
    "print(f'test score: {score_test_rforest:.2f}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}