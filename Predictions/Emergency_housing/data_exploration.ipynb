{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "#### Goal: Predict the number of nights granted to a request (not to an individual)\n",
    "\n",
    "\n",
    "#### Caracteristics of the model:\n",
    "Accuracy:\n",
    "- if used as a clearing tool removing overburden upfront, and thus only to get rid of obvious cases, the accuracy of such a tool could be its most important caracteristic.\n",
    "\n",
    "Interpretability:\n",
    "- could help families understand the decision (although not as important as in diseases predictions).\n",
    "- can also highlight and thus control biases (racial, sex, age).\n",
    "- since the tool would probably be used in combination with human selection, it could help save time by highlighting the main factors for each decision\n",
    "\n",
    "#### Conclusion:\n",
    "- a model easily interpretable could be prefered (tree).\n",
    "- or a highly accurate model (less interpretable) could also be used upfront (NN).\n",
    "\n",
    "\n",
    "#### Future improvements\n",
    "\n",
    "Imputations:\n",
    "- Build more robust, generalisable imputations (eg. impute future test samples with missing gender based on all easily interpretable categories group_composition_label and group_composition_id)\n",
    "\n",
    "- Automate NaNs imputation for future test samples\n",
    "\n",
    "- Reconstruct some NaNs by training models to predict the feature\n",
    "\n",
    "\n",
    "Datasets handling\n",
    "- I made the choice to keep the train and test sets split. This is to prevent gaining insight from the test set while doing pre-processing, analysis and while training the model. To prevent duplicate code, I thus placed most of the inner workings in the class Analysis, which makes the reading less fluent. To improve, see how to better combine the visual aspect of Jupyter Notebooks, while maintaining code standards like DRY philosophy.\n",
    "\n",
    "\n",
    "Pre-processing\n",
    "- impact historical data with the known global crises (financial crisis, immigration waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "I. Initialization\n",
    "\n",
    "1. Import packages, classes, functions\n",
    "\n",
    "2. Load databases (no join)\n",
    "\n",
    "3. Instanciate object Analysis\n",
    "\n",
    "\n",
    "II. Analyze I\n",
    "\n",
    "1. Overview\n",
    "\n",
    "2. Features: corr, dist, impact\n",
    "\n",
    "\n",
    "III. Pre-process data\n",
    "\n",
    "1. Impute NaNs\n",
    "\n",
    "2. Impute never seen before test set NaNs\n",
    "\n",
    "3. Remove outliers\n",
    "\n",
    "4. Transform categorical features\n",
    "\n",
    "5. Feature engineer\n",
    "\n",
    "\n",
    "\n",
    "IV. Analyze II\n",
    "\n",
    "1. Impact engineered features\n",
    "\n",
    "\n",
    "V. Build Model\n",
    "\n",
    "1. Benchmakrs\n",
    "\n",
    "2. Rush pytorch NN\n",
    "\n",
    "3. Simple model using principal components\n",
    "\n",
    "4. Ensemble\n",
    "\n",
    "\n",
    "VI. Predictions\n",
    "\n",
    "1. Train and Predict\n",
    "\n",
    "2. Hyperparameter tunning (split train set)\n",
    "\n",
    "\n",
    "VII. Evaluate methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages, classes, functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import tree\n",
    "\n",
    "# DL\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch import nn, optim\n",
    "\n",
    "# Utils\n",
    "import cobratools as cobra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test scorer\n",
    "def competition_scorer(y_true, y_pred, weights):\n",
    "    return log_loss(y_true, y_pred, sample_weight=10**y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False to only apply data transformations\n",
    "# (rather than derive the whole analysis)\n",
    "ANALYZE_ON = True\n",
    "\n",
    "# False for the competition, True if predicting > year 2019 requests\n",
    "FUTURE_PRED = False\n",
    "\n",
    "# Takes Â±4min\n",
    "IMPUTE_NANS = True\n",
    "\n",
    "# Set to True to visualize\n",
    "PRINT_ON = True  # verbose\n",
    "PLOT_ON = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_train = pd.read_csv(filepath_or_buffer='data/requests_train.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "requests_test = pd.read_csv(filepath_or_buffer='data/requests_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "individuals_train = pd.read_csv(filepath_or_buffer='data/individuals_train.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "individuals_test = pd.read_csv(filepath_or_buffer='data/individuals_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join datasets\n",
    "\n",
    "Since there are multiple requests by individuals and multiple individuals by request, the straightfoward approach would be to create columns for each individual' informations. This way, no information would be lost, but the curse of dimensionality is very near and the number of samples might be too low to extract useful information.\n",
    "\n",
    "The chosen approach is rather to only keep the request dataset' columns, and feature engineer additional columns based on the individuals data, eg.:\n",
    "- nb of past requests made by the same individual\n",
    "- nb nights granted in past requests of the same individual(s)/group\n",
    "- gender diversity of the group\n",
    "- etc.\n",
    "\n",
    "However, for analytics purpose, a dataframe with all the data is also created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Merge request and individuals datasets, for analytics purpose only\n",
    "    df_full_train = pd.merge(requests_train, individuals_train, on='request_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index col as request id\n",
    "# (not for individuals data set, since there is no pkey currently)\n",
    "# (hence not for df_full either)\n",
    "requests_train.set_index('request_id', inplace=True)\n",
    "requests_test.set_index('request_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate object analysis\n",
    "\n",
    "analyze_train and analyze_test will be the main dataframes, used for training and testing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate analysis object with request data\n",
    "analyze_train = cobra.Analysis(requests_train)\n",
    "analyze_test = cobra.Analysis(requests_test)\n",
    "analyze_ = cobra.Analysis(df_full_train)\n",
    "\n",
    "# Define properties\n",
    "\n",
    "# - target\n",
    "target = 'granted_number_of_nights' \n",
    "analyze_train.target = target\n",
    "analyze_full.target = target\n",
    "\n",
    "# - shape\n",
    "analyze_train.m = analyze_train.df.shape[0]\n",
    "analyze_test.m = analyze_test.df.shape[0]\n",
    "analyze_train.n = analyze_train.df.shape[1]\n",
    "analyze_test.n = analyze_test.df.shape[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "- Number of requests: 238191\n",
    "\n",
    "- Number of individuals: 384133\n",
    "\n",
    "- Number of features: 39\n",
    "\n",
    "- Requests are made for 1.6 pers on average.\n",
    "\n",
    "\n",
    "Principal components\n",
    "- housing_situation_label: with value \"emergency accomodation\". High probability to get 1 or two nights. Logical since the service treats emergency housing\n",
    "- housing_situation_2_label: with value \"emergency accomodation\". High probability to get 1 or two nights.\n",
    "\n",
    "--------------------\n",
    "\n",
    "\n",
    "Analysis by features\n",
    "\n",
    "\n",
    "A. housing_situation_id\n",
    "- correlation target-housing_situation_id: -0.458581. Strong negative impact. Although the linear numerical relation of the housing_situation_id categories is in my opinion flawed, the strong correlation is explainable as the category with the smallest value \"emergency accomodation\" might be correlated with higher granted_number_of_nights than the rest of the categories, which happen to have higher housing_situation_id values.\n",
    "\n",
    "- housing_situation_2_id: 0.283840. Strong positive impact. Same explanation as housing_situation_id.\n",
    "\n",
    "B. pregnancy\n",
    "- Pregnancy seems not to have a significant direct correlation with target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    analyze_train.describe(investigation_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    analyze_train.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### housing_situation_2_label\n",
    "\n",
    "- Â±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "\n",
    "- Â±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "\n",
    "- Â±75% (289,870) individuals are \"on the street\"\n",
    "\n",
    "- A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Â±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "    df_full[df_full['housing_situation_label'] == 'street']\n",
    "\n",
    "    # Â±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "    df_full.query(\"housing_situation_label == 'street' and housing_situation_2_label == 'on the street'\")\n",
    "\n",
    "    # Â±75% (289,870) individuals are \"on the street\"\n",
    "    df_full['housing_situation_2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    #### Impact on target\n",
    "    # Impact of feature on target\n",
    "    join_key = 'request_id'\n",
    "    target = 'granted_number_of_nights'\n",
    "    feature = 'housing_situation_2_label'\n",
    "    mask = df_train[feature] == 'emergency accomodation'\n",
    "\n",
    "    # Hist: drop duplicate requests (due to indiv data merged)\n",
    "    df_train[mask][[join_key, target]].drop_duplicates().hist()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### child_situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    #### Impact on target\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### animal_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'animal_presence'\n",
    "    mask = df_train[feature] == 't'\n",
    "    df_train[mask][[feature, target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requester_type along with group_main_requester_id\n",
    "if it is an urgentist, used to bring individuals to the service, its groups might have higher granted rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### request_backoffice_creator_id\n",
    "this might impact since each people has its own biases (as for the predictions of court decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data\n",
    "\n",
    "Methodology:\n",
    "\n",
    "- Clean-up request dataset\n",
    "\n",
    "- Feature engineer using indiv dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaNs\n",
    "\n",
    "Methodology:\n",
    "- inspect NaNs on train set\n",
    "\n",
    "- if pattern detected, apply modifications on train and test sets\n",
    "\n",
    "Observations:\n",
    "- reverse engineering: the system seems to derive group_composition_id from group_composition_label, and both are then necessary linked/redondant => drop group_composition_label\n",
    "\n",
    "- there can be multiple individuals by request, and multiple requests by individual\n",
    "\n",
    "Further:\n",
    "- Impute 14 pregnancy NaNs from child_to_come (not useful for the current objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs train summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get Na counts: by feature, by sample\n",
    "    na_ft_train, na_sp_train = analyze_train.get_na_counts()\n",
    "    na_ft_test, na_sp_test = analyze_test.get_na_counts()\n",
    "    if PRINT_ON:\n",
    "        print('Train: NaNs count by feature\\n\\n', na_ft_train[na_ft_train!=0])\n",
    "        #print('\\n\\nTest: NaNs count by feature\\n\\n', na_ft_test[na_ft_test!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_to_come NaNs\n",
    "\n",
    "Observation\n",
    "- There are 145947 NaNs for child_to_come on the train set (in request)\n",
    "\n",
    "- There are only 14 NaNs for pregnancy in train set (in individuals)\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: child_to_come is True if any indiv of the group is pregnant\n",
    "\n",
    "Conclusion\n",
    "- => Impute child_to_come from the pregnancy in the group of indiv of the request\n",
    "\n",
    "Control\n",
    "- Verify that the imputation is not only setting to 'f':\n",
    "- -> successful: from the 145947 requests, 5375 are set to 't'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Capture the indexes where NaNs\n",
    "    df_train_raw_nas = analyze_train.df[analyze_train.df['child_to_come'].isna()]\n",
    "    idx_nas = df_train_raw_nas['child_to_come'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # TODO: refactor (this takes Â±3min)\n",
    "    # Impute train set\n",
    "    analyze_train.impute_child_to_come(df_indiv=individuals_train)\n",
    "    # Impute test set\n",
    "    analyze_test.impute_child_to_come(df_indiv=individuals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get number of NaNs imputed as False and True\n",
    "    analyze_train.df.loc[idx_nas]['child_to_come'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute housing_situation_label\n",
    "\n",
    "The following code cells are organized as follows for clarity:\n",
    "- Imputation steps\n",
    "\n",
    "- Analysis\n",
    "\n",
    "Observations\n",
    "\n",
    "A. Meta numbers\n",
    "- Â±7% (16,748) NaNs for housing_situation_label (request)\n",
    "\n",
    "- 0 NaN for housing_situation_id (request)\n",
    "\n",
    "- 0 NaN for housing_situation_label_2 (individuals)\n",
    "\n",
    "- 0 NaN for housing_situation_id_2 (individuals)\n",
    "\n",
    "- 21 housing_situation_label (request)\n",
    "\n",
    "- 22 housing_situation_id (request)\n",
    "\n",
    "B. Specific ratios\n",
    "- Â±10% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "\n",
    "- Â±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "\n",
    "C. Analysis 1\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n",
    "\n",
    "D. Analysis 2\n",
    "- housing_situation_2_label can be very diverse when housing_situation_label is NaN (17 over 21 cat)\n",
    "\n",
    "- => housing_situation_label NaNs are not produced in a specific housing_situation_2_label situation\n",
    "\n",
    "E. Analysis 3\n",
    "- all individuals of a same request share the same housing_situation_2_label\n",
    "\n",
    "- => NaNs do not come from a problem of aggregating indiv data\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: the housing situation should logically have an impact on the result\n",
    "\n",
    "- Hyp: proba being on the street is significantly high to always impute NaN with 'street'\n",
    "\n",
    "- Hyp: housing_ids are not sorted in any specific order from which a logic could be derived. Thus, having numerical ids is dangereous and could lead to misinterpretations by the model.\n",
    "\n",
    "Conclusion\n",
    "- => Impute housing_situation_label NaNs as 'street'\n",
    "\n",
    "- => Drop housing_situation_id\n",
    "\n",
    "- => one-hot encode housing_situation_label\n",
    "\n",
    "\n",
    "Further improvements\n",
    "- derive more sub-groups: when a group is not housing_situation_label_2 'on the street', impute the request housing_situation_label with its most often matched value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute NaNs with the single value 'street'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # Impute housing_situation_label NaNs as 'street'\n",
    "    analyze_train.df.loc[analyze_train.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'\n",
    "    analyze_test.df.loc[analyze_test.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'\n",
    "\n",
    "    # Drop housing_situation_id\n",
    "    analyze_train.df.drop('housing_situation_id', axis=1, inplace=True)\n",
    "    analyze_test.df.drop('housing_situation_id', axis=1, inplace=True)\n",
    "\n",
    "    # One-hot encoding is applied later-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the mapping of housing_situation_id - housing_situation_label\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_id - housing_situation_label\n",
    "    map_housing_id_label = analyze_train.df.loc[:, ['housing_situation_id', 'housing_situation_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index for clarity\n",
    "    map_housing_id_label = map_housing_id_label.sort_values(by='housing_situation_id')\n",
    "    map_housing_id_label.reset_index(drop=True, inplace=True)\n",
    "    map_housing_id_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze relation between housing_situation_label (request) and housing_situation_2_label (indiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a temporary dataframe with columns:\n",
    "\n",
    "| request_id | gr_nb_nights | hous_id | hous_lab | indiv_id | hous_2id | hous2_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # request [gr_nb_nights, hous_id, hous_lab]\n",
    "    rq = analyze_train.df.loc[:, ['granted_number_of_nights', 'housing_situation_id', 'housing_situation_label']]\n",
    "\n",
    "    # individuals [request_id, indiv_id, hous_2id, hous2_lab]\n",
    "    ind = individuals_train.loc[:, ['request_id', 'individual_id', 'housing_situation_2_id', 'housing_situation_2_label']]\n",
    "    ind.set_index('request_id', inplace=True)\n",
    "\n",
    "    # Merge request and individuals datasets\n",
    "    df_full = pd.merge(rq, ind, on='request_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Nb of indivs (an indiv is considered a new indiv at each request)\n",
    "    nb_indivs = df_full.shape[0]\n",
    "\n",
    "    # Â±6% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "    df_full[df_full['housing_situation_label'].isna()]\n",
    "\n",
    "    # Â±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "    df_temp = df_full[df_full[\"housing_situation_label\"].isna()]\n",
    "    df_temp['housing_situation_2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect individuals with housing_situation_2_label \"on the street\":\n",
    "\n",
    "- they can have a very diverse housing_situation (17 categories over a total of 21)\n",
    "\n",
    "- => no pattern to derive from this point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    q = df_full.query(\"housing_situation_label.isna() and housing_situation_2_label != 'on the street'\")\n",
    "\n",
    "    # Count number of categories for housing_situation_2_label\n",
    "    n_cat_2 = len(q.loc[:, 'housing_situation_2_label'].unique())\n",
    "\n",
    "    # Total categories for the feature\n",
    "    n_cat_1 = len(analyze_train.get_col_uniques('housing_situation_label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if housing_situation_label NA exist when indiv within a group have different housing_situation_2\n",
    "\n",
    "- no divergence\n",
    "\n",
    "- => when group, all indiv have the same housing_situation_2_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # takes Â±1min\n",
    "    if False:\n",
    "        # Get request_id along with its group size\n",
    "        rq_id = df_full.index.value_counts()\n",
    "        for i in range(70000):\n",
    "            # Get ith rq_id\n",
    "            rq_id_i = rq_id.index[0]\n",
    "\n",
    "            # Observe if housing_situation_label same for all the group members\n",
    "            n_uni_grp = len(df_full.loc[rq_id_i]['housing_situation_label'].unique())\n",
    "            n_uni_indiv = len(df_full.loc[rq_id_i]['housing_situation_2_label'].unique())\n",
    "\n",
    "            if n_uni_grp > 1 or n_uni_indiv > 1:\n",
    "                print(i)\n",
    "                print(n_uni_grp, n_uni_indiv)\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further improvements: derive the most probable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_label - housing_situation_2_label\n",
    "    df_full_no_na = df_full[~df_full.housing_situation_label.isna()]\n",
    "    map_housing_labels = df_full_no_na.loc[:, ['housing_situation_label', 'housing_situation_2_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index for clarity\n",
    "    map_housing_labels = map_housing_labels.sort_values(by='housing_situation_label')\n",
    "    map_housing_labels.reset_index(drop=True, inplace=True)\n",
    "    map_housing_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute long_term_housing_request NaNs\n",
    "\n",
    "Nb NaNs: 165556"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute town NaNs\n",
    "\n",
    "Nb NaNs: 159959"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute victim_of_violence_type NaNs\n",
    "\n",
    "Nb NaNs: 234175\n",
    "\n",
    "is NaN if victim_of_violence is 'f'\n",
    "\n",
    "\n",
    "=> Replace these NaNs by say 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporarily drop columns with NaNs remaining\n",
    "(untill imputation methods are implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: impute properly\n",
    "list_drop = [\n",
    "    'long_term_housing_request',\n",
    "    'town',\n",
    "    'victim_of_violence_type'\n",
    "]\n",
    "for col in list_drop:\n",
    "    analyze_train.df.drop(col, axis=1, inplace=True)\n",
    "    analyze_test.df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temporarily drop numerical columns\n",
    "(that can't be used properly untill transformation methods are implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: transform rather than drop\n",
    "list_drop = [\n",
    "    'child_situation',\n",
    "    'district',\n",
    "    'group_composition_id',\n",
    "    'group_id',\n",
    "    'group_main_requester_id',\n",
    "    'request_backoffice_creator_id',\n",
    "    'social_situation_id'\n",
    "]\n",
    "\n",
    "for feature in list_drop:\n",
    "    analyze_train.df.drop(feature, axis=1, inplace=True)\n",
    "    analyze_test.df.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute remaining test set NaNs\n",
    "(that have no equivalent in train set, and thus can't be studied to build a clever imputation method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement method based on train set logic for any feature\n",
    "analyze_train.set_default_na_vals()\n",
    "\n",
    "# Transfer default NaNs to test object\n",
    "analyze_test.default_na_vals = analyze_train.default_na_vals\n",
    "\n",
    "# Impute any remaining NaN based on its default value\n",
    "analyze_test.impute_nans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop answer creation date\n",
    "hyp: the variable is not available at prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of the competition, is it expected to be used?\n",
    "if FUTURE_PRED:\n",
    "    analyze_train.df.drop('answer_creation_date', axis=1, inplace=True)\n",
    "    analyze_test.df.drop('answer_creation_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete old samples\n",
    "(if it was to predict future requests (> 2020))\n",
    "- Train/test split being done randomly (â  historically), it is important for this competition to train the model on the whole train set (don't remove old samples)\n",
    "- Delete samples with group_creation_date < 2015, since it is very unlikely that current demands are treated like +5 years ago (social services evolve)\n",
    "- Threshold date: see if later is better, potential gains from domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FUTURE_PRED:\n",
    "    # Drop samples with year < 2015\n",
    "    old_samples = analyze_train.df[analyze_train.df.group_creation_date.dt.year < 2015]\n",
    "    analyze_train.df.drop(old_samples.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender\n",
    "\n",
    "- => Only females are possibly pregnant, thus 30 males have made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Retrieve the individual ids, and correct for male -> pregnancy = 0\n",
    "#analyze_train.df['gender'].groupby(analyze_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterize large categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make clusters then transform using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dates\n",
    "- into linear numerical features (year, month)\n",
    "\n",
    "- and into categorical features (hot_season, col_season:T/F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features: Dates to year, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns of date type\n",
    "list_date_cols = [\n",
    "    'request_creation_date',\n",
    "    'group_creation_date'\n",
    "]\n",
    "\n",
    "# Don't use the feature if trying to build robust in-production model\n",
    "if not FUTURE_PRED:\n",
    "    list_date_cols.append('answer_creation_date')\n",
    "\n",
    "# Transform date type: string to timestamp\n",
    "for col in list_date_cols:\n",
    "    analyze_train.df[col] = pd.to_datetime(analyze_train.df[col])\n",
    "    analyze_test.df[col] = pd.to_datetime(analyze_test.df[col])\n",
    "\n",
    "# Create feature: 'year'\n",
    "for col in list_date_cols:\n",
    "    analyze_train.df[col[:-4]+'year'] = analyze_train.df[col].dt.year\n",
    "    analyze_test.df[col[:-4]+'year'] = analyze_test.df[col].dt.year\n",
    "\n",
    "# Create feature: 'month'\n",
    "for col in list_date_cols:\n",
    "    analyze_train.df[col[:-4]+'month'] = analyze_train.df[col].dt.month\n",
    "    analyze_test.df[col[:-4]+'month'] = analyze_test.df[col].dt.month\n",
    "\n",
    "# Drop raw features of type date\n",
    "for col in list_date_cols:\n",
    "    analyze_train.df.drop(col, axis=1, inplace=True)\n",
    "    analyze_test.df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feats: hot_season, col_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "hot_months = [7, 8]\n",
    "col_months = [1, 1, 11, 12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Town to regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of indivs in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past requests by indivs forming the group of the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Single individual\n",
    "\n",
    "# Get number of ALL requests of indiv with max n_requests\n",
    "#ind_id = df_full['individual_id'].value_counts().index[0]\n",
    "\n",
    "# Watch request made by the same indiv\n",
    "#df_full[df_full['individual_id'] == ind_id]\n",
    "\n",
    "# TODO: Past requests only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past granted request by indivs forming the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical features\n",
    "Prepare data to feed models\n",
    "\n",
    "- booleans: replace by (1, 0)\n",
    "\n",
    "- 2 < cats < 11: one-hot encoding\n",
    "\n",
    "- No transform on features with more than 11 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Display col name along its type\n",
    "    for col, col_type in zip(analyze_train.df.columns, analyze_train.get_cols_type()):\n",
    "        print(col_type, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform all categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Transform Boolean at col animal_presence: True/False=['f' 't']\nTransform Boolean at col child_to_come: True/False=[False  True]\n\nERROR - Transform Boolean at col group_type not recognized: ['individual' 'group']\n\nTransform Boolean at col victim_of_violence: True/False=['f' 't']\nTransform Boolean at col animal_presence: True/False=['f' 't']\nTransform Boolean at col child_to_come: True/False=[False  True]\n\nERROR - Transform Boolean at col group_type not recognized: ['group' 'individual']\n\nTransform Boolean at col victim_of_violence: True/False=['f' 't']\n\nERROR - Transform Boolean at col answer_creation_year not recognized: [2019 2018]\n\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(('group', 'individual'), False)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "# Pre-process columns:\n",
    "# - booleans: 't', 't' => True, False\n",
    "# - Categorical with few classes => one-hot encoding\n",
    "bools_train, failed_train = analyze_train.transform_categories(target=analyze_train.target)\n",
    "bools_test, failed_test = analyze_test.transform_categories(target=analyze_test.target)\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "analyze_train.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "analyze_test.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Export data\n",
    "#analyze_train.export_data('data/data_train_preprocessed.csv')\n",
    "#analyze_test.export_data('data/data_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis II\n",
    "(df_train)\n",
    "\n",
    "Analysis focused on impact of one-hot encoded variables and new engineered features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates\n",
    "Link btw group_creation_date and request_creation_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "#pd.DataFrame([rq_crea_dt_seconds, grp_crea_dt_seconds]).corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random uniform train/test\n",
    "random_preds_train = np.random.uniform(size=(requests_train.shape[0], 4))\n",
    "random_preds_test = np.random.uniform(size=(requests_test.shape[0], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyze_test.df.drop(['request_creation_year', 'group_creation_year', 'answer_creation_year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train/cross-validation split\n",
    "TRAIN_VAL_SPLIT = 0.8\n",
    "n_train_samples = round(analyze_test.df.shape[0] * TRAIN_VAL_SPLIT)\n",
    "\n",
    "# Mask - all features columns but target\n",
    "ma_feats = analyze_train.df.columns != target\n",
    "\n",
    "# Split train and cross-val sets && features (X) vs target (Y)\n",
    "X_train = analyze_train.df.iloc[n_train_samples:, ma_feats]\n",
    "X_val = analyze_train.df.iloc[:n_train_samples, ma_feats]\n",
    "Y_train = analyze_train.df[target][n_train_samples:]\n",
    "Y_val = analyze_train.df[target][:n_train_samples]\n",
    "\n",
    "# Transform sets to torch tensors\n",
    "X_train = torch.from_numpy(X_train.values)\n",
    "X_val = torch.from_numpy(X_val.values)\n",
    "Y_train = torch.from_numpy(Y_train.values)\n",
    "Y_val = torch.from_numpy(Y_val.values)\n",
    "\n",
    "# Split X-Y and transform to tensors\n",
    "X_test = torch.from_numpy(analyze_test.df.loc[:, ma_feats].values)\n",
    "Y_test = torch.from_numpy(analyze_test.df[target].values)\n",
    "\n",
    "# Cast to float type\n",
    "X_train = X_train.float()\n",
    "X_val = X_val.float()\n",
    "Y_train = Y_train.float()\n",
    "Y_val = Y_val.float()\n",
    "X_test = X_test.float()\n",
    "Y_test = Y_test.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate datasets\n",
    "#dataset_train = cobra.Dataset(X=X_train, Y=Y_train)\n",
    "#dataset_val = cobra.Dataset(X=X_val, Y=Y_val)\n",
    "#dataset_test = cobra.Dataset(X=X_test, Y=Y_test)\n",
    "dataset_train = Dataset(X=X_train, Y=Y_train)\n",
    "dataset_val = Dataset(X=X_val, Y=Y_val)\n",
    "dataset_test = Dataset(X=X_test, Y=Y_test)\n",
    "\n",
    "\n",
    "# Instanciate data loaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size = dataset_train.len)\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size = dataset_val.len)\n",
    "dataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size = dataset_test.len)\n",
    "\n",
    "# Set log-loss criterion\n",
    "#y_vals = [0, 1, 2, 3]\n",
    "#weights = [10**y for y in y_vals]\n",
    "#weights = [.2, .25, .27, .3]\n",
    "#class_weights = torch.FloatTensor(weights)\n",
    "criterion = nn.CrossEntropyLoss() #weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinitialize model and weights\n",
    "layers = [analyze_train.df.columns.size-1, 100, 48, 60, 4]\n",
    "#model = cobra.NN(layers)\n",
    "model = NN(layers, p=0.2)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.8)\n",
    "\n",
    "# Reset loss history\n",
    "loss_epochs = {\n",
    "    'train': [],\n",
    "    'eval': []\n",
    "    }\n",
    "loss_epochs_compet = {\n",
    "    'train': [],\n",
    "    'eval': []\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Avg epoch 0\n  loss train: 1.2863 - eval: 1.2685\ncompet train: 1.3967 - eval: 1.367\n\nAvg epoch 1\n  loss train: 1.2712 - eval: 1.2545\ncompet train: 1.3758 - eval: 1.3472\n\nAvg epoch 2\n  loss train: 1.2574 - eval: 1.2416\ncompet train: 1.3575 - eval: 1.333\n\nAvg epoch 3\n  loss train: 1.2443 - eval: 1.2295\ncompet train: 1.3423 - eval: 1.3218\n\nAvg epoch 4\n  loss train: 1.2319 - eval: 1.2182\ncompet train: 1.3302 - eval: 1.3133\n\nAvg epoch 5\n  loss train: 1.2202 - eval: 1.208\ncompet train: 1.3227 - eval: 1.3074\n\nAvg epoch 6\n  loss train: 1.2097 - eval: 1.1983\ncompet train: 1.3141 - eval: 1.3004\n\nAvg epoch 7\n  loss train: 1.1998 - eval: 1.1893\ncompet train: 1.3071 - eval: 1.2969\n\nAvg epoch 8\n  loss train: 1.1904 - eval: 1.1805\ncompet train: 1.3025 - eval: 1.2934\n\nAvg epoch 9\n  loss train: 1.1814 - eval: 1.1723\ncompet train: 1.2998 - eval: 1.2849\n\n"
    }
   ],
   "source": [
    "# Train model\n",
    "n_epochs = 10\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # Lists batchs loss\n",
    "    loss_batchs = {\n",
    "        'train': [],\n",
    "        'eval': []\n",
    "        }\n",
    "    loss_batchs_compet = {\n",
    "        'train': [],\n",
    "        'eval': []\n",
    "    }\n",
    "\n",
    "    # Training\n",
    "    # --------\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_train):\n",
    "\n",
    "        # Predict\n",
    "        predictions = model(x)\n",
    "\n",
    "        # Evaluate\n",
    "        loss = criterion(predictions, labels).mean()\n",
    "        loss_compet = competition_scorer(labels.numpy(), predictions.detach().numpy().clip(.025, .95))\n",
    "\n",
    "        # Compute gradients\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        # Backpropagate\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add batch loss to the list of current epoch\n",
    "        loss_batchs['train'].append(round(loss.item(), 4))\n",
    "        loss_batchs_compet['train'].append(round(loss_compet, 4))\n",
    "\n",
    "        #print('epoch {}, batch {}, loss {}'.format(epoch, n_batch, round(loss.item(), 4)))\n",
    "        #print('           compet loss {}\\n'.format(round(loss_compet, 4)))\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    # ----------\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_val):\n",
    "        # Predict on the eval set\n",
    "        predictions = model(x)\n",
    "        \n",
    "        # Compute batch loss\n",
    "        loss = criterion(predictions, labels).mean()\n",
    "        loss_compet = competition_scorer(labels.numpy(), predictions.detach().numpy().clip(.025, .95))\n",
    "        \n",
    "        # Add batch loss to the list of current epoch\n",
    "        loss_batchs['eval'].append(round(loss.item(), 4))\n",
    "        loss_batchs_compet['eval'].append(round(loss_compet, 4))\n",
    "\n",
    "\n",
    "    # Compute train and eval losses for the epoch, and add to epochs list\n",
    "    for set_name in ['train', 'eval']:\n",
    "        loss_epoch = torch.tensor(loss_batchs[set_name], dtype=float).mean()\n",
    "        loss_epoch_compet = pd.DataFrame(loss_batchs_compet[set_name]).mean()[0]\n",
    "        loss_epochs[set_name].append(round(loss_epoch.item(), 4))\n",
    "        loss_epochs_compet[set_name].append(round(loss_epoch_compet, 4))\n",
    "\n",
    "\n",
    "    print(f\"Avg epoch {epoch}\")\n",
    "    print(f\"  loss train: {loss_epochs['train'][-1]} - eval: {loss_epochs['eval'][-1]}\")\n",
    "    print(f\"compet train: {loss_epochs_compet['train'][-1]} - eval: {loss_epochs_compet['eval'][-1]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, layers, p=0):\n",
    "        super(NN, self).__init__()\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "\n",
    "        # Set seed to reproduce results\n",
    "        torch.manual_seed(1000)\n",
    "        \n",
    "        for input_size, output_size in zip(layers, layers[1:]):\n",
    "            self.hidden_layers.append(nn.Linear(input_size, output_size))\n",
    "            #self.hidden_layers.append(nn.Dropout(p=p))\n",
    "            self.hidden_layers.append(nn.BatchNorm1d(output_size))\n",
    "\n",
    "    def forward(self, activation):\n",
    "        for i_layer, linear_transform in enumerate(self.hidden_layers):\n",
    "            if i_layer < len(self.hidden_layers) - 1:\n",
    "                activation = torch.relu(linear_transform(activation))\n",
    "            else:\n",
    "                activation = linear_transform(activation)\n",
    "        return activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "/Users/Pro/shortcuts/virtualenvs/pytorch/lib/python3.6/site-packages/ipykernel_launcher.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n  \"\"\"\n"
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'bool' object is not iterable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-723-4901a01d96ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0ml_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#.argmax(axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_pred\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'bool' object is not iterable"
     ]
    }
   ],
   "source": [
    "l_pred = predictions.detach().numpy() #.argmax(axis=1)\n",
    "if True:\n",
    "    l_pred = predictions.detach().numpy() #.argmax(axis=1)\n",
    "    target = labels.numpy()\n",
    "    sum(l_pred == y)/len(target)\n",
    "\n",
    "a = pd.DataFrame({'A':target})\n",
    "l = pd.DataFrame({'L':l_pred.argmax(axis=1)})\n",
    "#print('\\nvalues used for predictions:',*l.drop_duplicates()['L'].sort_values())\n",
    "print(l_pred)\n",
    "#print(l)\n",
    "print('\\nPredictions:')\n",
    "print(l['L'].value_counts())\n",
    "print('\\ntarget:')\n",
    "print(a['A'].value_counts())\n",
    "\n",
    "sum(l['L'] == target)/len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mcc057a5448\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#mcc057a5448\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(37.369744 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"85.369154\" xlink:href=\"#mcc057a5448\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2.5 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(77.417591 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"125.417001\" xlink:href=\"#mcc057a5448\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 5.0 -->\n      <g transform=\"translate(117.465438 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"165.464847\" xlink:href=\"#mcc057a5448\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 7.5 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(157.513285 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"205.512694\" xlink:href=\"#mcc057a5448\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(194.379882 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"245.560541\" xlink:href=\"#mcc057a5448\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 12.5 -->\n      <g transform=\"translate(234.427729 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"285.608388\" xlink:href=\"#mcc057a5448\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 15.0 -->\n      <g transform=\"translate(274.475576 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"325.656235\" xlink:href=\"#mcc057a5448\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 17.5 -->\n      <g transform=\"translate(314.523423 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mf35beceaaf\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf35beceaaf\" y=\"202.785366\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.2 -->\n      <g transform=\"translate(7.2 206.584584)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf35beceaaf\" y=\"159.568766\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(7.2 163.367985)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf35beceaaf\" y=\"116.352166\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(7.2 120.151385)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf35beceaaf\" y=\"73.135566\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.5 -->\n      <g transform=\"translate(7.2 76.934785)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mf35beceaaf\" y=\"29.918966\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 33.718185)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#pc7ee6a53c9)\" d=\"M 45.321307 17.083636 \nL 61.340446 38.000471 \nL 77.359584 64.232947 \nL 93.378723 87.008095 \nL 109.397862 107.449546 \nL 125.417001 121.494941 \nL 141.436139 132.774474 \nL 157.455278 142.238909 \nL 173.474417 150.62293 \nL 189.493556 158.272268 \nL 205.512694 165.48944 \nL 221.531833 172.015146 \nL 237.550972 177.979037 \nL 253.570111 183.640412 \nL 269.589249 188.99927 \nL 285.608388 194.055612 \nL 301.627527 198.593355 \nL 317.646666 202.871799 \nL 333.665804 206.934159 \nL 349.684943 210.823653 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pc7ee6a53c9)\" d=\"M 45.321307 37.438655 \nL 61.340446 63.887214 \nL 77.359584 87.526694 \nL 93.378723 108.097795 \nL 109.397862 122.316057 \nL 125.417001 133.898105 \nL 141.436139 143.232891 \nL 157.455278 151.660128 \nL 173.474417 159.352683 \nL 189.493556 166.569855 \nL 205.512694 173.181995 \nL 221.531833 179.232319 \nL 237.550972 184.80726 \nL 253.570111 190.036469 \nL 269.589249 194.919944 \nL 285.608388 199.328038 \nL 301.627527 203.520048 \nL 317.646666 207.409542 \nL 333.665804 211.212602 \nL 349.684943 214.756364 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc7ee6a53c9\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO3dd3hUVf7H8fdJhxBCOqRCSAgl1AQQpElvggpi7y7LWnbt665rWXV3VVx114auspZFFFEBAQUsSAud0EsSICEQkhBCEkjPnN8fd1B+SEgumclkJt/X88xDmHvvmW+GyYebc889R2mtEUII4fzcHF2AEEII25BAF0IIFyGBLoQQLkICXQghXIQEuhBCuAgPR71wcHCwbt++vaNeXgghnNKWLVtOaK1DLrTNYYHevn17Nm/e7KiXF0IIp6SUyqxtm3S5CCGEi5BAF0IIFyGBLoQQLkICXQghXIQEuhBCuAgJdCGEcBES6EII4SKcLtDzisv569e7qay2OLoUIYRoUpwu0LdkFvLftYd54Zt9ji5FCCGaFKcL9HHd23H7wPbMXnuIpTtzHF2OEEI0GU4X6AB/Ht+FXlFteGz+Dg7mn3Z0OUII0SQ4ZaB7ebjx5k198HRX3DNnK2WVNY4uSQghHM4pAx0gok0LXr2uF/tzS/jLgl3I2qhCiObOaQMdYFhCKPcPj+eLrdnM23zE0eUIIYRDOXWgA/xhRDyD4oJ5cuFudh8rcnQ5QgjhME4f6O5uin9d34vAll7cM2crRWVVji5JCCEcwukDHSColTdv3Nibo4VlPPr5dulPF0I0Sy4R6ADJ7QN5fFxnlu/J5b3VhxxdjhBCNLo6A10pNVsplaeU2nWRfYYppVKVUruVUj/ZtsT6u2tQB8Z2a8sL3+5j0+GTjipDCCEcoj5n6B8AY2vbqJRqA7wFTNJadwOutU1p5imleOnaHkQFtODeOVvJL6lwVClCCNHo6gx0rfUq4GKnuzcCX2qts6z759motkvS2seTt25Koqisij98uo0ai/SnCyGaB1v0oXcCApRSK5VSW5RSt9a2o1JqulJqs1Jqc35+vg1e+sK6hrfmuasSWZdRwGvfHbDb6wghRFNii0D3AJKACcAY4EmlVKcL7ai1fldrnay1Tg4JCbHBS9duWnIU05Ijef2HdH7c59BfGoQQolHYItCzgWVa6zNa6xPAKqCnDdptsGcnJ9K5rR8PfJZKdmGpo8sRQgi7skWgLwQGKaU8lFItgf7AXhu022A+nu68fXMSFovm3jlbqaiWSbyEEK6rPsMW5wIpQIJSKlspdZdSaoZSagaA1nov8C2wA9gIvKe1rnWIY2PrEOzLzGt7sD27iL8taRL/zwghhF141LWD1vqGeuwzE5hpk4rsYGxiO34zuAP/WX2IpJgAJveKcHRJQghhc853p6jWkL3F9GGPje1MckwAf/pyJ+l5JXYoTAghHMv5An3bx/DecMhcZ+owT3c33rixDy083ZnxP1kUQwjhepwv0BOngH8ULHkYaszNrNjW34fXru9Fet5pXv8hzU4FCiGEYzhfoHv5wtgXIG8PbHjH9OGD40O4pk8E/1l9ULpehBAuxfkCHaDzBIgfDSv/AcXHTB/+5/FdaOHpzpMLdstUu0IIl+Gcga4UjHvR6HJZ9oTpw4NbefPY2M6kHCxgYar5/xCEEKIpcs5ABwiMhcEPwe4vIeNH04ff0C+anpH+PL9kr6xyJIRwCc4b6ACXPwABHWDpI1BtbqpcdzfF81d15+SZCl5Zvt9OBQohRONx7kD39IHxM6EgHda9bvrw7pH+3HJZDB+vz2RntiwwLYRwbs4d6ADxo6DLlbDqZSjMNH34Q6MTCPT15i8Ldsrc6UIIp+b8gQ7GMEal4Ns/mT7Uv4UnT07swvbsIuZuzLJDcUII0ThcI9D9I2HoY7B/CRxYZvrwST3DGRAbxEvf7pNl64QQTss1Ah3gsnshOAGWPgpVZaYOVUrx3FWJlFXV8I9vZEZGIYRzcp1A9/CCCS/DqUxY86rpw+NCWzF9SCxfbj3K+oMFdihQCCHsy3UCHaDDEEicCmteg4IM04ffd0U8EW1a8OSCXVRWW+xQoBBC2I9rBTrAmL+Buxd885gx1a4JLbzc+eukbqTlnWb22kN2KlAIIezD9QLdry1c8WdI/w72fm368JFdwxjVNYx/fZfG0VPm+uKFEMKRXC/QAfpNh7BEYxhj5RnThz99ZVc0mme/3m2H4oQQwj5cM9DdPWDCP6E4G356yfThkQEt+f2IeJbtzuWHfbl2KFAIIWzPNQMdIPoy6HUTpLwBeftMH373oFjiQlvx1MLdsrqREMIpuG6gA4z8q7EgxtJHTF8g9fJw47nJiWQXlvHWynQ7FSiEELbj2oHeKgRGPAWHV8PO+aYPH9AxiKt7RzDrpwwy8k/boUAhhLAd1w50gKQ7ILw3LH8Cys3PqPjn8V3w8XTnqYW7ZHUjIUST5vqB7uZuXCA9nQc//sP04SF+3jw2JoG16QV8vSPHDgUKIYRtuH6gA0QkQdLtsPEdOL7T9OE39o+hR6Q/zy3eQ3G5rG4khGiamkegg9GX3iIAljwMFnO39RurGyVy4nQFryw/YKcChRCiYZpPoLcMNEa9HNkA2z8xfXiPyDbc3D+Gj1IOs+uorG4khGh6mk+ggzEuPbIfrHgKSk+aPvyRMQkE+nrxlwW7sMjqRkKIJqZ5BbqbG0x81RjtsvQR04f7t/DkiQldSD1ySibvEkI0Oc0r0AHaJsLQP8KuL2D3V6YPv6pXBKO7hvHSt/vZm1NshwKFEOLSNL9ABxj0ILTrBYsfMoYzmqCU4oUpPfBv6ckDn6ZSXiXTAgghmobmGejunnD1LGMmxsUPmp4WINDXi5lTe7A/t4SZy/bbqUghhDCneQY6QGgXGP4E7FsMOz4zffiwhFBuGxDD+2sOsSbthB0KFEIIc5pvoAMMuA+i+sPSx6D4mOnDHx/XhbjQVjz8eSqnSivtUKAQQtRfnYGulJqtlMpTSu2qZfswpVSRUirV+njK9mXaiZs7XPU21FTCovsvacm6167rxckzlfz5q50y14sQwqHqc4b+ATC2jn1Wa617WR/PNrysRhTUEUY9ayxZt/VD04cnRvjz0KgElu48zhdbj9qhQCGEqJ86A11rvQowfxeOM+l7N7QfDMuegMJM04dPHxJLvw6BPL1wF1kFpXYoUAgh6marPvQBSqntSqlvlFLdattJKTVdKbVZKbU5Pz/fRi9tA25uMPlNQMHCey9prpdXpvXETSkempdKdY2544UQwhZsEehbgRitdU/gdWBBbTtqrd/VWidrrZNDQkJs8NI2FBADY/5mLIax6T+mD48MaMlzVyWyObOQWT9l2KFAIYS4uAYHuta6WGt92vr1UsBTKRXc4Mococ+tEDcKVjwNJ8wvOze5VzhX9gznte/S2H7klB0KFEKI2jU40JVSbZVSyvp1P2ubBQ1t1yGUgkmvg4cXLPgdWMzdBaqU4vnJiYT6efPgZ6mUVlbbqVAhhPi1+gxbnAukAAlKqWyl1F1KqRlKqRnWXaYCu5RS24F/A9drZx6/17odjJsJ2Rsh5Q3Th/u39OTlaT05VHCGvy3Za4cChRDiwjzq2kFrfUMd298AzCdfU9ZjGuxdBD88D/GjjbtKTRjYMZjpg2N5Z9VBhncOZUSXMDsVKoQQv2jed4rWRimY+Bp4+8FXM6DG/LJzD43uRJd2rXls/g7ySyrsUKQQQvx/Eui1aRUCE16BnFRY/Yrpw7093PnX9b0oqajm8S92yF2kQgi7k0C/mG5XQeJUWPUS5Gw3fXinMD/+NK4z3+/L45ONWXYoUAghfiGBXpfxM6FlkNH1Um2+6+S2Ae0ZHB/Mc4v3kJF/2g4FCiGEQQK9Li0DjaGMeXtg5QumD3dzU7x8bU98PN158LNUquQuUiGEnUig10enMdD7Zlj7GhzZZPrwsNY+vHBNd3ZkF/Hv79PsUKAQQkig19+Yv4NfuHHDUVWZ6cPHJrbj2qRI3vwxnc2HXXuuMyGEY0ig15ePP0x+AwrS4PvnLqmJpyd1IzKgJQ98lkpxufmhkEIIcTES6GZ0vMKYanf9W5D+venDW3l78Op1vcgpKueReduxWGQooxDCdiTQzRr1rHHn6Bd3wynzQxGTYgL48/guLN+Ty6xVMiujEMJ2JNDN8vKFaR+DpRrm3QpV5aabuPPy9lzZM5yXl+2XBaaFEDYjgX4pguOMtUiPbYNv/2j6cKUUL07pTnyoH/fP3Up2oaxyJIRoOAn0S9VlIlz+AGz5ALbNMX14Sy8PZt2SRHWN5p45WymvMjdVrxBCnE8CvSGGPwkdhsCShy5paoAOwb68cl0vdmQX8cyi3XYoUAjRnEigN4S7B0yZDS0C4bNboKzQdBOjuoZx3xVxfLrpCJ/KfC9CiAaQQG+oViEw7SMoPgZfTje9wDTAg6M6MTg+mKcW7pal64QQl0wC3Rai+sLYf0Daclj9sunD3d0U/76+NyF+3twzZysnz1TaoUghhKuTQLeVvndDj+vgx79D2nemDw/w9WLWzUnkn67g93O3USM3HQkhTJJAt5WzqxyFdYMv74bCTNNNdI/05/nJiaxJP8E/l++3Q5FCCFcmgW5LXi2N/nSL5ZJvOprWN4ob+kXz1soMlu0+bocihRCuSgLd1oI6wtWzjKXrvnn0kpp4ZlJXekb68/C87bIohhCi3iTQ7aHzeBj8MGz9CLZ+bPpwbw933r45CS8PN2Z8vIUzFdV2KFII4Wok0O3liicgdhgseRiOpZo+PLxNC16/oTcZ+ad5TBaZFkLUgwS6vbi5w5T3wTcE5t0CpeYXtbg8LphHx3RmyY4c3l9zyA5FCiFciQS6PfkGGxdJS45f8k1HM4bGMrZbW/7xzT7WHyywQ5FCCFchgW5vkUkw9gVIXwGrXjJ9uFKKmdf2ICaoJfd9spXjReZHzgghmgcJ9MaQfCf0vAFWvgBpK0wf7ufjyTs3J1FaWcPv5myhstr8mb4QwvVJoDcGpWDCKxCWaKx0VHjYdBPxYX7MnNqTbVmneH7JHtvXKIRwehLojcWrJVz3EWhtzMxYYX58+YQe7Zg+JJaPUjL55/L9MvJFCPH/SKA3psBYuOZdyN0FH06E0/mmm3hsTALTkiN5/Yd0Hp63XbpfhBA/k0BvbAlj4fpPIG8fvD8SCswtFO3h7saLU3rw0KhOfLntKHd8sJHi8io7FSuEcCYS6I6QMA5uXwwVJfD+KMjebOpwpRS/HxHPy9f2ZMPBk1z7dgrHTpXZqVghhLOQQHeUyGS4awV4+8EHE2H/N6abmJoUyQd39OPoqTKueWsde44V26FQIYSzkEB3pKCORqiHdoZPb4TNs003MSg+mM9nDABg2jsprE4z3y8vhHANdQa6Umq2UipPKbWrjv36KqWqlVJTbVdeM9AqFG5bDHEjYfGD8MPzxkgYE7q0a81X9w4kMqAFd/x3E59vPmKnYoUQTVl9ztA/AMZebAellDvwIrDcBjU1P96t4Pq50PsWWDUTFt4LNeYudLbzb8G8GQO4LDaIR+fv4F/fpcmwRiGamToDXWu9CqhrZqn7gS+APFsU1Sy5e8Ck12HYnyB1Dnxynemx6q19PJl9e1+m9Ink1e8O8McvdlBVI8MahWguGtyHrpSKAK4G3m54Oc2cUjDscSPYD66ED8ZDSa6pJrw83Hj52h78fkQ88zZnc+cHmyiRYY1CNAu2uCj6GvBHrXWdp4JKqelKqc1Kqc35+XLxrlZ9boUbPoUTacZY9RNppg5XSvHQqE68NKUH6zIKmPbOenKLZVIvIVydLQI9GfhUKXUYmAq8pZS66kI7aq3f1Vona62TQ0JCbPDSLqzTaGOsemUpvD8ajmw03cS0vlHMvr0vWQVnuPrNtRzILbFDoUKIpqLBga617qC1bq+1bg/MB+7RWi9ocGUCIpLg7hXQog18eCXsXWy6iaGdQpg3YwDVFs2Ut9exLuOEHQoVQjQF9Rm2OBdIARKUUtlKqbuUUjOUUjPsX54gMNYYqx7WzVj5aNN7ppvoFu7PV/deTjt/H26bvZEF247aoVAhhKMpRw1tS05O1ps3m7vlvVmrPAPz74QD38KgB2H4U+Bm7hesorIqZny8hZSDBdw+sD2Pj+uMj6e7nQoWQtiDUmqL1jr5QtvkTlFn4eUL182BpNthzaswZyqcNjdK1L+FJx/e2Y/bB7bng3WHufL1New+VmSfeoUQjU4C3Zm4e8DE12Diq5C5Ft4eCGnfmWrCy8ONZyZ146M7+1FUVsVVb67l3VUZWCxyE5IQzk4C3dkoZSxpN30l+IbCnCnw7Z+husJUM0M6hfDtA0MY3jmUvy/dx03vbZAZG4VwchLoziq0C/zmB+g3Hda/Ce+ZH68e6OvFrJuTeGlqD3Zkn2Lsa6tYtP2YnQoWQtibBLoz8/SB8TONm5CKsuGdIbD1I1OTeymlmJYcxdI/DKZjaCt+P3cbD3y6TRbNEMIJSaC7goRx8Lt1ENkXFt0P8++AslOmmogJ8uXz3w7gwZGd+HpHDuNeW82GgwV2KlgIYQ8S6K6idTu4ZQGMfAb2fg2zBkPWelNNeLi78YeR8Xw+YwAe7orr/7OeF7/dJ+uWCuEkJNBdiZubMUb9zuXG1/8dBytfBEuNqWb6RAew9PeDuS45irdXZnDN22tJzzM386MQovFJoLuiyCT47Wrofi2s/LuxxN0pc4te+Hp78MKUHrxzSxJHC8uY+PpqPk45LHOsC9GESaC7Kp/WcM27cPW7cHwHzLoc9iw03cyYbm1Z9sAQ+nUI4smFu7njg03klcjMjUI0RRLorq7ndTBjNQTFwbxbYdHvjRkcTQht7cOHd/Tlr5O6kZJRwNjXVvPFlmy5GUmIJkYCvTkIjIU7lxn961s/gneHQuY6U00opbhtYHsW3z+IqMCWPPz5dqbOWseuozJ1gBBNhQR6c+HuaYyAuXWBcYb+33HGZF9F2aaaiQ/z46vfDeSlqT3IOlnKlW+s4U9f7uTkmUq7lC2EqD+ZbbE5qiyFta/B2n+Bso6MGXg/eLYw1UxRWRX/+i6ND1MO08rbg0dGd+LG/jG4uyn71C2EuOhsixLozVlhJqx40rhY2iYaRv8NulxpzBdjwv7jJTyzaDcpBwvo0q41z07uRt/2gXYqWojmTabPFRcWEAPTPoLbvgYvP2MBjY8mQe5uU80ktPXjk9/0580b+1BUWsm1s1J44NNtso6pEI1MztCFoaYatvwXfngeKoqh790w7E/Q0tyZdmllNW/9mMG7qw7i6a64f0Q8d17eAS8POXcQwhaky0XUX+lJ+PFvsHk2+LSB4U9A0h3gZm5lo8yCMzy3eA/f7c0jNtiXpyd1Y2gnWRhciIaSQBfmHd8F3z4Oh1dDWCKMexHaDzLdzI/783j26z0cOnGGUV3DeHJCV6KDWtqhYCGaBwl0cWm0Ni6YLv8LFB2BblfDqOegTZSpZiqqa3h/zSHe+CGdaotmxpBYfju0I77eHnYqXAjXJYEuGqayFNb921jLFAWDHjCGOXr5mmomp6iMfyzdx6Ltxwhu5cW9V8RxY/9ovD1koWoh6ksCXdjGqSxY/iTsWWAsfzfkUWPRag8vU81szSpk5rf7STlYQLi/Dw+M7MQ1fSLwcJcLp0LURQJd2FbWBvj+r8ZC1W2ijdEwPa4zdeFUa83a9AJmLtvH9uwiYoN9eWh0J8YntsNNbkwSolYS6ML2tIaM7+H7ZyFnO4R0huF/gc4TTd2YpLVm+Z5c/rl8PwdyT9O1XWseHZPAsIQQlMkbnIRoDiTQhf1YLLB3kTF+vSANwvvAiKeg4xWmmqmxaBZtP8qrK9LIOllKckwAj45JoH9skJ0KF8I5SaAL+6uphu1zYeULUJwNHYbA8Kcgqq+pZiqrLczbfIR/f59GXkkFQzqF8OjoBLpH+tupcCGciwS6aDxV5cYdp6tehtITkDDB6IoJ62qqmfKqGj5KOczbKzMoLK1iXGJbHh7dibhQP/vULYSTkEAXja+iBNbPMoY7VpRAj2nGxdPADqaaKSmv4v01h3hv9SFKK6u5unckD4yMJypQbk4SzZMEunCc0pPG+PWN74KlGvrcBkMfA7+2ppo5eaaSWT9l8OG6w1i0ZkqfSGYM7Uj7YHNj4YVwdhLowvGKj8GqmcaKSW6exvj1gfeDf4SpZo4XlfPWynQ+3XSE6hoLE3uEc88VHenctrV96haiiZFAF01HQYYR7DvmGYtr9LrRuPM0MNZUM3kl5by/5hD/S8nkTGUNI7uEcs8VcfSJDrBT4UI0DRLooukpPGysmLTtf0ZXTOJUGPwQhHYx1UxRaRUfphxm9tpDnCqtYkBsEPcNj2NgxyAZxy5ckgS6aLqKcyDlDWO63qpS48akIY9AeG9TzZypqGbuxizeXXWQvJIKeka14d5hHRnZJUzuPBUuRQJdNH1nCmDD27DhXagogo4jjGCPGWiqmYrqGr7YcpRZP2WQdbKUTmGtuGdYHBN7tJO5YoRLkEAXzqO8GDa9BylvGuPYowfCkIeNgDfRhVJdY2HxjhzeWpnOgdzTRAe2ZMbQjkxJipDZHYVTa1CgK6VmAxOBPK114gW2TwaeAyxANfCA1npNXUVJoIuLqiw1RsSs+zcUH4V2vYwz9oQJ4Fb/M22LRfPd3lze/DGd7dlFhLX25jeDY7m+XzStZD524YQaGuhDgNPAR7UEeivgjNZaK6V6APO01p3rKkoCXdRLdaUxpcCaV6HwEIR0MS6edrsG3OsfyGdnd3zzx3RSDhbg5+PBjf2juWNgB9r6+9jxGxDCthrc5aKUag8svlCgn7ffAGC21rrOoQoS6MKUmmrY/RWs/ifk7wX/KLjsd9D7FvAxNwZ9W1Yh760+xDe7cnBTikk9w7l7cCxdw2Usu2j67B7oSqmrgX8AocAErXVKLftNB6YDREdHJ2VmZtanfiF+YbHAgW+NkTGZa8G7NSTdBv1ngH+kqaayCkqZvfYQ8zYfobSyhkFxwdw9uANDO8nUvaLpaswz9CHAU1rrkXW1KWfoosGObjWCffcC44Jpt2tg4H3QrqepZopKq5izMZMP1h4mr6SCTmGtuHtwLJN7hcsFVNHkNFqgW/c9CPTTWp+42H4S6MJmTmUZE4Ft/RAqTxtT9w64H+JGmrqAWllt4evtx/jP6oPsO15CiJ83tw9sz039o2nT0twye0LYi10DXSkVB2RYL4r2Ab4GInUdDUugC5srO2WE+vpZUHLMWEVpwL3QfRp41v/Cp9aaNekneHfVQVannaCFpzvXJkdy16AOxATJZGDCsRo6ymUuMAwIBnKBpwFPAK31LKXUH4FbgSqgDHhUhi0Kh6quNC6gprwOx3eCbwj0+y30vQtaBppqat/xYt5bfYiFqUeptmjGdG3Lb4Z0ICnGXDtC2IrcWCSaJ63h0Cqjnz1tOXi0MCYDG3AvBHU01VRucTkfrjvM/9ZnUlxeTfcIf27qH82kXuG09JLx7KLxSKALkbfPCPYdn0FNFcSPgr53W/vZ63/h80xFNV9uzeZ/67PYn1uCn7cHV/eJ4Kb+MSS0ldWUhP1JoAtxVkkubH4ftnwIp49Dm2hIusMYz94qpN7NaK3ZklnInA1ZLNmRQ2WNhb7tA7ipfwxjE9vi4ymjY4R9SKALcb6aKti3xJg35vBqcPeCrpONs/ao/qbmjTl5ppL5W44wZ0MWmQWlBLT0ZFpyFDf0i5YVlYTNSaALcTH5+43pe1M/gYpiCEuE5DuNdVC969+NYrFo1mUU8L/1mazYm0uNRTM4Ppib+scwskuozPYobEICXYj6qDwDO+fDpv8Yo2O8/KDn9cboGJMLb+QWl/PZpiPM3ZhFTlE5Ya29ua5vNNf3jSK8TQs7fQOiOZBAF8IMrSF7s9Eds/srqKmAmMuNs/Yuk8Cj/jcZVddY+HF/PnM2ZPLTgXwUMKJLGNOSoxiWEIKnnLULkyTQhbhUZwog9X+w6X04lWmMae9zq3ERNbCDqaaOnCxl7sYs5m0+wonTlQT5ejG5VwRTkiLoFu5vp29AuBoJdCEaymKBjB+Ms/YD3wIaYgZB75uMi6le9b/4WVVj4af9+czfks33+3KpqtF0adeaKX0imNwrghA/b/t9H8LpSaALYUtF2cYc7amfwMmD4NUKul5lhHv0AFMjZArPVPL1jmN8sSWb7dlFuLsphnUKYWpSJMO7hMrkYOJXJNCFsAetIWu90SWze4ExMVhgrHE3as8bTE/nm5Zbwvyt2SzYdpTc4gratPTkyh7hTE2KpEekv0zpKwAJdCHsr+I07F1knLUfXg0oiB0GvW+GzhPAs/4jW2osxuRg87dks3z3cSqqLcSFtmJKn0iu7h0hKyw1cxLoQjSmk4esXTJzoSgLvP0h8Roj3COSTHXJFJVVsXRnDvO3ZLMlsxA3BYPiQ7i6dziju7bFV9ZFbXYk0IVwBIvFOFtPnQN7FkF1GQQnGF0y3a8F/whTzR06cYYvt2bz5dajHD1Vho+nG6O6tuWqXuEMjg/By0OGQDYHEuhCOFp5sTGmPXUOHNkAKIgZCIlTjAuqvkH1bspi0WzJKmTBtqMs2ZnDqdIqAlp6Mr57Oyb3iiA5JgA3N+lvd1US6EI0JQUZxh2pu+bDiQPg5gEdh0PiVOg83tR0A5XVFlan5bMw9Rgr9uRSVlVDRJsWXNkznKt6h9O5rSx87Wok0IVoirQ2phjYNR92fQlFR4w52zuNge5TIW6UqZWWzlRUs2JPLgtSj7I67QQ1Fk1CmB+Te4czqWc4kQEt7fjNiMYigS5EU2exQPZG2Pm5MQSy9AR4t4YuVxrdMh2Ggnv9L4AWnK5g6c4cFqQeY0tmIQDJMQFM7h3BhO7tCPSVNVKdlQS6EM6kphoOrYSdX8C+xcYMkL4h0O1qo1smqp+pkTJHTpayaPsxFmw7SlreaTzcFJfHBTOhRzvGdG2Lf0tP+30vwuYk0IVwVlXlxvJ5u+bDgWVQXQ7+0dBtMnSZbAyDdKvf6BatNfuOl7Aw9RhLdh7jyMkyPNwUg+KDmdC9HaMl3J2CBLoQrqC8GJvC1UIAAA3VSURBVPYvNS6oHlwJlipoHWF0y3SdbCzMUc/l9LTW7DxaxJIdOSzZmUN2YRme7opBccFM6BHOqK5h+LeQcG+KJNCFcDVlp4xJwvYsgvTvjCl+fUOt4T7JmDisnn3uWmt2ZBexdGcOi3fkcPSUEe6D40MY372dhHsTI4EuhCurKDG6ZfYshLQVUFUKLQKNKQe6XgUdhtR7DnetNdut4b7knHAfcjbcu4XR2kfC3ZEk0IVoLipLjTP2vYtg/7dQWQI+/pAw3uiWib2i3kMhtdakHjn1c7gfKyrHy92NwfHBjE1sy8guYQTIaJlGJ4EuRHNUVW70te9ZCPuXQHmRMdVvpzHQeSLEjTDCvh601mw7coqlO3JYutMId3c3Rb/2gYzpFsaobm2JkKX1GoUEuhDNXXUlHF5l9LnvWwylBeDmCe0HGWfvCWOhTXS9mjp7QXX57lyW7T5OWt5pALpH+DOmWxhjurUlLrSVTPdrJxLoQohfWGoge5MxYmbfUihIM54P6w4J44xHu171Hg55MP80y6zhnnrkFACxwb6MsoZ7r8g2MreMDUmgCyFqdyIN9n9jPI6sB20Bv3bQaaxxYbX94Hr3ux8vKmfF3lyW7z5OSkYB1RZNWGtvRnU1wr1/hyCZFbKBJNCFEPVzpsAYMbN/KaR/D1VnwNMX4oYbXTPxo8E3uF5NFZVW8cP+XJbtyuWnA/mUVdXg5+PBiM6hDO8SxpD4YNq0lIuqZkmgCyHMqyqHw2uMcN//DZQcA+Vm3MAUN9KYIbKeXTPlVTWsTjvBst3H+X5vLoWlVbgp6BnVhmGdQhmaEEKPCH/pmqkHCXQhRMNoDTnbrV0zS+H4DuP5FoHQ8QroOML4s3V4nU3VWDTbs0+xcn8+Px3IZ0f2KbSGQF8vhsQHMzQhhCHxIQS18rbzN+WcJNCFELZ1Os8YEpn+PWT8AGfyjOdDuxpn7h2vgJjL67WWasHpCtakn2Dl/nxWHcin4EwlShmjZoZ1CmFoQii9otrgLmfvgAS6EMKetIbc3ZBhDffMFGMqAndvY1WmuBFGyId2rXOWSItFs+tYET/tz2flgXy2ZRVi0eDfwpPB8cEM7RTC0IQQQv2a70LZEuhCiMZTWQqZ634J+Px9xvOt2lrP3odD7FBoFVpnU0WlVaxOz+cna/dMXkkFAJ3b+jEoLphB8cH06xBIS6/ms1i2BLoQwnGKjhrBnvEDHPwRyowFNwjtZgR7h6HGmbzPxZfL01qzN6eElQfyWJt+gk2HC6mstuDprugTHcDg+GAujwume4Q/Hu6uOzSyQYGulJoNTATytNaJF9h+E/BHQAElwO+01tvrKkoCXYhmyFIDOalw8Cc49BNkrTfmeFfuxtzuZwM+qh94XPyiaFllDZszT7Im/QRr0k6w+1gxAH4+HgzsGMSgOCPgOwT7utRdqw0N9CHAaeCjWgJ9ILBXa12olBoHPKO17l9XURLoQgiqyo2l984G/NGtoGuMtVWjL/sl4Nv1rHOu94LTFazLKGBt+glWp53g6KkyACLatODyuCAutwZ8sJOPnmlwl4tSqj2w+EKBft5+AcAurXVEXW1KoAshfqW8yOh/PxvweXuM5338jTtWY4cZAR8cf9ELrFprMgtKfz57X5dxguLyagC6tGvNwI5BDIgNol9soNNNB9yYgf4I0FlrfXct26cD0wGio6OTMjMz63xtIUQzVpILh1YZa6weXAVFWcbzrcKMfveYy40/Q7pc9AanGotm19GinwN+S5bR/+6mIDHCnwGxQVzWMYi+7QNp5d20L7A2SqArpa4A3gIGaa0L6mpTztCFEKZoDYWHjTP3zHVweC0UZxvbfNpYA976aNvzois2lVfVsC3rFCkHC1ifUcC2I4VU1Wjc3RQ9Io2AH9AxiOSYQFp41W9Zv8Zi90BXSvUAvgLGaa0P1KcoCXQhRIMVZhrhnrnW+PNkhvG8VytjioKzZ/ERfS56kbWssoYtmYWkHDxBSkYBO7KLqLZoPN0VvaLa/HwG3yc6AB9Pxwa8XQNdKRUN/ADcqrVeV9+iJNCFEDZXctwa8NZH3m7jeXdviOz7yxl8VD/w8q21mTMV1WzOLCQlo4CUgwXszD6FRYOXhxu9o9pwWWwQ/TsE0js6oNHP4Bs6ymUuMAwIBnKBpwFPAK31LKXUe8AU4GyHeHVtL3YuCXQhhN2VnoSslF/O4nO2G9MDK3dj5EzMQIgeYDx8g2ptpqS8ik2HT/4c8HuOFWPR4Omu6BHZhn4dAunXIZDkmAD87HyRVW4sEkIIgPJiOLIRstYZY+CzNxvTFAAEdzKC/WzIt4mudSRNcXkVWzIL2XjoJBsO/tJF46aga3hr+ncIol+HQPq2DyTQxuuuSqALIcSFVFfAsW3GGXxWCmRtgIoiY1vrCGMs/NmQv8hImrLKGrZlFbLh0Ek2HjrJ1qxCKqotAHQKa2U9gze6acJaN2weGgl0IYSoD0uNMfY9a/0vIV+SY2zz8YeoyyBmgHHBNbx3rbNJVlTXsDO76OeA33z4JGcqawBoH9SSuwbHcstlMZdUogS6EEJcirNDJc/2w2et/2UNVjcPaNsdIvsZF1yj+kKbmAt201TXWNiTU2x00Rw6yaiuYUxLjrqkkiTQhRDCVk7nG4tsZ280+uCPboGqUmObb+gv4R7ZzziL92pp05e/WKA37VuihBCiqWkVAp3HGw+AmmpjeGT2JjhiDfr9S4xtyh3aJv7/s/iADnXOC3+p5AxdCCFs7UzBOWfxm4xJxypPG9taBsOgB2HgfZfUtJyhCyFEY/INgoSxxgOsF1v3GgF/ZBP4tbXLy0qgCyGEvblZu17aJkLynfZ7Gbu1LIQQolFJoAshhIuQQBdCCBchgS6EEC5CAl0IIVyEBLoQQrgICXQhhHAREuhCCOEiHHbrv1Iqn19WOTIrGDhhw3JsranXB02/RqmvYaS+hmnK9cVorUMutMFhgd4QSqnN9VnmzlGaen3Q9GuU+hpG6muYpl5fbaTLRQghXIQEuhBCuAhnDfR3HV1AHZp6fdD0a5T6Gkbqa5imXt8FOWUfuhBCiF9z1jN0IYQQ55FAF0IIF9GkA10pNVYptV8pla6UevwC272VUp9Zt29QSrVvxNqilFI/KqX2KKV2K6X+cIF9himlipRSqdbHU41Vn/X1Dyuldlpf+1fr/SnDv63v3w6lVJ9GrC3hnPclVSlVrJR64Lx9Gv39U0rNVkrlKaV2nfNcoFJqhVIqzfpnQC3H3mbdJ00pdVsj1jdTKbXP+m/4lVKqTS3HXvTzYMf6nlFKHT3n33F8Lcde9OfdjvV9dk5th5VSqbUca/f3r8G01k3yAbgDGUAs4AVsB7qet889wCzr19cDnzVife2APtav/YADF6hvGLDYge/hYSD4ItvHA98ACrgM2ODAf+vjGDdMOPT9A4YAfYBd5zz3EvC49evHgRcvcFwgcND6Z4D164BGqm804GH9+sUL1Vefz4Md63sGeKQen4GL/rzbq77ztv8TeMpR719DH035DL0fkK61Pqi1rgQ+BSaft89k4EPr1/OBEUrZaTnt82itc7TWW61flwB7gYjGeG0bmgx8pA3rgTZKqXYOqGMEkKG1vtQ7h21Ga70KOHne0+d+zj4ErrrAoWOAFVrrk1rrQmAFMLYx6tNaL9daV1v/uh6ItPXr1lct71991OfnvcEuVp81O6YBc239uo2lKQd6BHDknL9n8+vA/Hkf6we6CAhqlOrOYe3q6Q1suMDmAUqp7Uqpb5RS3Rq1MNDAcqXUFqXU9Atsr8973Biup/YfIke+f2eFaa1zrF8fB8IusE9TeS/vxPit60Lq+jzY033WLqHZtXRZNYX3bzCQq7VOq2W7I9+/emnKge4UlFKtgC+AB7TWxedt3orRjdATeB1Y0MjlDdJa9wHGAfcqpYY08uvXSSnlBUwCPr/AZke/f7+ijd+9m+RYX6XUE0A1MKeWXRz1eXgb6Aj0AnIwujWaohu4+Nl5k/95asqBfhSIOufvkdbnLriPUsoD8AcKGqU64zU9McJ8jtb6y/O3a62LtdanrV8vBTyVUsGNVZ/W+qj1zzzgK4xfa89Vn/fY3sYBW7XWuedvcPT7d47cs11R1j/zLrCPQ99LpdTtwETgJut/Or9Sj8+DXWitc7XWNVprC/CfWl7X0e+fB3AN8Flt+zjq/TOjKQf6JiBeKdXBehZ3PbDovH0WAWdHE0wFfqjtw2xr1v6294G9WutXatmn7dk+faVUP4z3u1H+w1FK+Sql/M5+jXHhbNd5uy0CbrWOdrkMKDqna6Gx1HpW5Mj37zznfs5uAxZeYJ9lwGilVIC1S2G09Tm7U0qNBR4DJmmtS2vZpz6fB3vVd+51matred36/Lzb00hgn9Y6+0IbHfn+meLoq7IXe2CMwjiAcfX7Cetzz2J8cAF8MH5VTwc2ArGNWNsgjF+9dwCp1sd4YAYww7rPfcBujCv264GBjVhfrPV1t1trOPv+nVufAt60vr87geRG/vf1xQho/3Oec+j7h/GfSw5QhdGPexfGdZnvgTTgOyDQum8y8N45x95p/SymA3c0Yn3pGP3PZz+HZ0d+hQNLL/Z5aKT6PrZ+vnZghHS78+uz/v1XP++NUZ/1+Q/Ofu7O2bfR37+GPuTWfyGEcBFNuctFCCGECRLoQgjhIiTQhRDCRUigCyGEi5BAF0IIFyGBLoQQLkICXQghXMT/AfqzcmG3UkzFAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m72a0acb8c1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m72a0acb8c1\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(37.369744 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"85.369154\" xlink:href=\"#m72a0acb8c1\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 2.5 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(77.417591 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"125.417001\" xlink:href=\"#m72a0acb8c1\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 5.0 -->\n      <g transform=\"translate(117.465438 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"165.464847\" xlink:href=\"#m72a0acb8c1\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 7.5 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(157.513285 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"205.512694\" xlink:href=\"#m72a0acb8c1\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 10.0 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(194.379882 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"245.560541\" xlink:href=\"#m72a0acb8c1\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 12.5 -->\n      <g transform=\"translate(234.427729 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"285.608388\" xlink:href=\"#m72a0acb8c1\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 15.0 -->\n      <g transform=\"translate(274.475576 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"325.656235\" xlink:href=\"#m72a0acb8c1\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 17.5 -->\n      <g transform=\"translate(314.523423 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"mb6a1b8efa1\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6a1b8efa1\" y=\"187.553912\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(7.2 191.35313)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6a1b8efa1\" y=\"140.286401\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 144.08562)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6a1b8efa1\" y=\"93.018891\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(7.2 96.81811)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#mb6a1b8efa1\" y=\"45.751381\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 2.0 -->\n      <g transform=\"translate(7.2 49.5506)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_13\">\n    <path clip-path=\"url(#p9a6d02108e)\" d=\"M 45.321307 17.083636 \nL 61.340446 41.473672 \nL 77.359584 63.216726 \nL 93.378723 90.86822 \nL 109.397862 119.748668 \nL 125.417001 143.666028 \nL 141.436139 154.844795 \nL 157.455278 166.141729 \nL 173.474417 175.075289 \nL 189.493556 182.44902 \nL 205.512694 188.333825 \nL 221.531833 193.27328 \nL 237.550972 197.598257 \nL 253.570111 201.190588 \nL 269.589249 204.050273 \nL 285.608388 205.822804 \nL 301.627527 207.855307 \nL 317.646666 209.50967 \nL 333.665804 210.596823 \nL 349.684943 211.234934 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p9a6d02108e)\" d=\"M 45.321307 43.104401 \nL 61.340446 66.407283 \nL 77.359584 92.522582 \nL 93.378723 123.648238 \nL 109.397862 145.556729 \nL 125.417001 156.711861 \nL 141.436139 166.921643 \nL 157.455278 175.926104 \nL 173.474417 183.654342 \nL 189.493556 190.129991 \nL 205.512694 195.353051 \nL 221.531833 200.032534 \nL 237.550972 203.388527 \nL 253.570111 206.035508 \nL 269.589249 208.044377 \nL 285.608388 209.438769 \nL 301.627527 211.093132 \nL 317.646666 211.920313 \nL 333.665804 212.747494 \nL 349.684943 214.756364 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p9a6d02108e\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "n_skip = 0\n",
    "plt.plot(loss_epochs['train'][n_skip:])\n",
    "plt.plot(loss_epochs['eval'][n_skip:])\n",
    "plt.show()\n",
    "plt.plot(loss_epochs_compet['train'][n_skip:])\n",
    "plt.plot(loss_epochs_compet['eval'][n_skip:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Avg loss test: 1.1559\n\ncompet loss: 1.5950991248107869\n"
    }
   ],
   "source": [
    "# Lists batchs loss\n",
    "loss_batchs = {\n",
    "    'test': []\n",
    "    }\n",
    "\n",
    "# Test set\n",
    "# --------\n",
    "for n_batch, (x, labels) in enumerate(dataloader_test):\n",
    "    # Predict on the test set\n",
    "    predictions = model(x)\n",
    "    \n",
    "    # Compute batch loss\n",
    "    loss = criterion(predictions, labels)\n",
    "    loss_compet = competition_scorer(labels.numpy(), predictions.detach().numpy().clip(.0025, .95))\n",
    "    \n",
    "    # Add batch loss to the list of current epoch\n",
    "    loss_batchs['test'].append(round(loss.item(), 4))\n",
    "\n",
    "# Compute train and test losses for the epoch, and add to epochs list\n",
    "loss_test = torch.tensor(loss_batchs['test'], dtype=float).mean()\n",
    "loss_test = round(loss_test.item(), 4)\n",
    "\n",
    "print(f\"Avg loss test: {loss_test}\\n\")\n",
    "print(f\"compet loss: {loss_compet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify matching btwn compet_scorer and criterion\n",
    "# NO MATCH !!\n",
    "if False:\n",
    "    y_vals = [0, 1, 2, 3]\n",
    "    weights = [10**y for y in y_vals]\n",
    "    class_weights = torch.FloatTensor(weights)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    criterion_loss = criterion(predictions, labels)\n",
    "    print(criterion_loss)\n",
    "\n",
    "if True:\n",
    "    # Define the test scorer\n",
    "    def competition_scorer(y_true, y_pred):\n",
    "        return log_loss(y_true, y_pred) #, sample_weight=10**y_true)\n",
    "    #compet_loss = competition_scorer(labels.numpy(), predictions.detach().numpy())\n",
    "    #print(compet_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0.7083767843022996\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "y_true and y_pred contain different number of classes 2, 4. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 3]",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-340-5f21f1592ad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompetition_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_compet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-340-5f21f1592ad7>\u001b[0m in \u001b[0;36mcompetition_scorer\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Define the test scorer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompetition_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 10**y_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Set log-loss criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/shortcuts/virtualenvs/pytorch/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mlog_loss\u001b[0;34m(y_true, y_pred, eps, normalize, sample_weight, labels)\u001b[0m\n\u001b[1;32m   2285\u001b[0m                              \"y_true: {2}\".format(transformed_labels.shape[1],\n\u001b[1;32m   2286\u001b[0m                                                   \u001b[0my_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2287\u001b[0;31m                                                   lb.classes_))\n\u001b[0m\u001b[1;32m   2288\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2289\u001b[0m             raise ValueError('The number of classes in labels is different '\n",
      "\u001b[0;31mValueError\u001b[0m: y_true and y_pred contain different number of classes 2, 4. Please provide the true labels explicitly through the labels argument. Classes found in y_true: [0 3]"
     ]
    }
   ],
   "source": [
    "y_vals = [0, 1, 2, 3]\n",
    "weights = [10**y for y in y_vals]\n",
    "# Define the test scorer\n",
    "def competition_scorer(y_true, y_pred):\n",
    "    return log_loss(y_true, y_pred, sample_weight=10**y_true)  # 10**y_true\n",
    "\n",
    "# Set log-loss criterion\n",
    "#weights = [0.00001+ 1/10**y for y in y_vals]\n",
    "#class_weights = torch.FloatTensor(weights)\n",
    "criterion = nn.CrossEntropyLoss() #weight=class_weights, reduction='none')\n",
    "\n",
    "def cross_entropy(predictions, targets):\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets * np.log(predictions)) / N\n",
    "    return ce\n",
    "\n",
    "predictions = np.array([[0.25,0.25,0.25,0.25],\n",
    "                        [0.01,0.01,0.01,0.97]])\n",
    "targets = np.array([[1,0,0,0],\n",
    "                   [0,0,0,1]])\n",
    "\n",
    "target_compet = np.array([0, 3])\n",
    "\n",
    "predictions_t = torch.from_numpy(predictions).float()\n",
    "targets_t = torch.from_numpy(np.array([0, 3]))\n",
    "\n",
    "print(cross_entropy(predictions, targets))\n",
    "print(competition_scorer(target_compet, predictions))\n",
    "print(criterion(predictions_t, targets_t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed a significant (negative) correlation of housing_situation_id with granted_number_of_nights, let's train a univariate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model' parameters\n",
    "clf = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=2,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=None,\n",
    "    class_weight=None)\n",
    "\n",
    "# Build train/test datasets with housing_situation_id only\n",
    "X_train = np.array(requests_train['housing_situation_id']).reshape(-1, 1)\n",
    "X_test = np.array(requests_test['housing_situation_id'].values).reshape(-1, 1)\n",
    "Y_train = requests_train.granted_number_of_nights.values\n",
    "Y_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Transform categorical target into a one-hot vector\n",
    "Y_train_onehot = to_onehot(Y_train)\n",
    "Y_test_onehot = to_onehot(Y_test)\n",
    "\n",
    "# Train the model\n",
    "clf = clf.fit(X_train, Y_train_onehot)\n",
    "\n",
    "# Yield train/test predictions\n",
    "preds_train_tree_univar = clf.predict(X_train)\n",
    "preds_test_tree_univar = clf.predict(X_test)\n",
    "\n",
    "# Fill predictions to .2 elsewhere\n",
    "preds_train_tree_univar[preds_train_tree_univar == 0] = .2\n",
    "preds_test_tree_univar[preds_test_tree_univar == 0] = .2\n",
    "\n",
    "# Evaluate train/test\n",
    "score_train = competition_scorer(Y_train, preds_train_tree_univar)\n",
    "score_test = competition_scorer(Y_test, preds_test_tree_univar)\n",
    "\n",
    "# Display results\n",
    "print(f'train score: {score_train:.2f}')\n",
    "print(f'test score: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = clf.predict_proba(X_train)\n",
    "v0 = probas[0].max(1)\n",
    "v1 = probas[1].max(1)\n",
    "v2 = probas[2].max(1)\n",
    "v3 = probas[3].max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_test = competition_scorer(y_true_test, random_preds_test)\n",
    "dumb_score_test = competition_scorer(y_true_test, dumb_preds_test)\n",
    "\n",
    "# Display results\n",
    "print(f'test score random: {random_score_test:.2f}')\n",
    "print(f'test score dumb: {dumb_score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_train = requests_train.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_train = competition_scorer(y_true_train, random_preds_train)\n",
    "dumb_score_train = competition_scorer(y_true_train, dumb_preds_train)\n",
    "\n",
    "# Display results\n",
    "print(f'train score random: {random_score_train:.2f}')\n",
    "print(f'train score dumb: {dumb_score_train:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree\n",
    "fn = ['housing_situation_id']\n",
    "cn = ['0', '1', '2', '3']\n",
    "\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True)\n",
    "\n",
    "requests_train['housing_situation_id'].hist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}