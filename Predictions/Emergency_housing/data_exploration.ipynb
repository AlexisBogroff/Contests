{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "#### Goal: Predict the number of nights granted to a request (not to an individual)\n",
    "\n",
    "\n",
    "#### Caracteristics of the model:\n",
    "Accuracy:\n",
    "- if used as a clearing tool removing overburden upfront, and thus only to get rid of obvious cases, the accuracy of such a tool could be its most important caracteristic.\n",
    "\n",
    "Interpretability:\n",
    "- could help families understand the decision (although not as important as in diseases predictions).\n",
    "- can also highlight and thus control biases (racial, sex, age).\n",
    "- since the tool would probably be used in combination with human selection, it could help save time by highlighting the main factors for each decision\n",
    "\n",
    "#### Conclusion:\n",
    "- a model easily interpretable could be prefered (tree).\n",
    "- or a highly accurate model (less interpretable) could also be used upfront (NN).\n",
    "\n",
    "\n",
    "#### Future improvements\n",
    "\n",
    "Imputations:\n",
    "- Build more robust, generalisable imputations (eg. impute future test samples with missing gender based on all easily interpretable categories group_composition_label and group_composition_id)\n",
    "\n",
    "- Automate NaNs imputation for future test samples\n",
    "\n",
    "- Reconstruct some NaNs by training models to predict the feature\n",
    "\n",
    "\n",
    "Datasets handling\n",
    "- I made the choice to keep the train and test sets split. This is to prevent gaining insight from the test set while doing pre-processing, analysis and while training the model. To prevent duplicate code, I thus placed most of the inner workings in the class Analysis, which makes the reading less fluent. To improve, see how to better combine the visual aspect of Jupyter Notebooks, while maintaining code standards like DRY philosophy.\n",
    "\n",
    "\n",
    "Pre-processing\n",
    "- impact historical data with the known global crises (financial crisis, immigration waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "I. Initialization\n",
    "\n",
    "1. Import packages, classes, functions\n",
    "\n",
    "2. Load databases (no join)\n",
    "\n",
    "3. Instantiate object Analysis\n",
    "\n",
    "\n",
    "II. Analyze I\n",
    "\n",
    "1. Overview\n",
    "\n",
    "2. Features: corr, dist, impact\n",
    "\n",
    "\n",
    "III. Pre-process data\n",
    "\n",
    "1. Impute NaNs\n",
    "\n",
    "2. Impute never seen before test set NaNs\n",
    "\n",
    "3. Remove outliers\n",
    "\n",
    "4. Transform categorical features\n",
    "\n",
    "5. Feature engineer\n",
    "\n",
    "\n",
    "\n",
    "IV. Analyze II\n",
    "\n",
    "1. Impact engineered features\n",
    "\n",
    "\n",
    "V. Build Model\n",
    "\n",
    "1. Benchmakrs\n",
    "\n",
    "2. Rush pytorch NN\n",
    "\n",
    "3. Simple model using principal components\n",
    "\n",
    "4. Ensemble\n",
    "\n",
    "\n",
    "VI. Predictions\n",
    "\n",
    "1. Train and Predict\n",
    "\n",
    "2. Hyperparameter tunning (split train set)\n",
    "\n",
    "\n",
    "VII. Evaluate methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "# Utils\n",
    "import cobratools as cobra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set False to only apply data transformations\n",
    "ANALYZE_ON = False\n",
    "\n",
    "# False for the competition, True if predicting > year 2019 requests\n",
    "FUTURE_PRED = False  #d:False\n",
    "\n",
    "# Takes ±4min (on light laptop/seconds on collab)\n",
    "IMPUTE_NANS = True\n",
    "EXPORT_DATA = False  #d:False\n",
    "LOAD_PREPROCESSED_DATA = True\n",
    "\n",
    "# Set to True to visualize\n",
    "PRINT_ON = False\n",
    "PLOT_ON = False\n",
    "\n",
    "# Debug\n",
    "RELOAD = False  #d:False\n",
    "\n",
    "# Project specificities\n",
    "TARGET = 'granted_number_of_nights'\n",
    "N_TARGET_CLASS = 4\n",
    "\n",
    "# Data format\n",
    "PRECISION = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug reload\n",
    "Without the need to re-perform data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELOAD:\n",
    "    # Backup data\n",
    "    backup_train = obj_train.df.copy()\n",
    "    backup_test = obj_test.df.copy()\n",
    "    \n",
    "    # Reload updated class and functions\n",
    "    importlib.reload(cobra)\n",
    "\n",
    "    # Re-instanciate obj_train and obj_test\n",
    "    obj_train = cobra.Analysis(backup_train)\n",
    "    obj_test = cobra.Analysis(backup_test)\n",
    "    \n",
    "    # Re-set target variable\n",
    "    obj_train.target = TARGET\n",
    "    obj_test.target = TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_train = pd.read_csv(filepath_or_buffer='data/requests_train.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "requests_test = pd.read_csv(filepath_or_buffer='data/requests_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "individuals_train = pd.read_csv(filepath_or_buffer='data/individuals_train.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "individuals_test = pd.read_csv(filepath_or_buffer='data/individuals_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join datasets\n",
    "\n",
    "Since there are multiple requests by individuals and multiple individuals by request, the straightfoward approach would be to create columns for each individual' informations. This way, no information would be lost, but the curse of dimensionality is very near and the number of samples might be too low to extract useful information.\n",
    "\n",
    "The chosen approach is rather to only keep the request dataset' columns, and feature engineer additional columns based on the individuals data, eg.:\n",
    "- nb of past requests made by the same individual\n",
    "- nb nights granted in past requests of the same individual(s)/group\n",
    "- gender diversity of the group\n",
    "- etc.\n",
    "\n",
    "However, for analytics purpose, a dataframe with all the data is also created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge request and individuals datasets, for analytics purpose only\n",
    "df_full_train = pd.merge(requests_train, individuals_train, on='request_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index col as request id\n",
    "# (not for individuals data set, since there is no pkey currently)\n",
    "# (hence not for obj_full_train either)\n",
    "requests_train.set_index('request_id', inplace=True)\n",
    "requests_test.set_index('request_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate object analysis\n",
    "\n",
    "obj_train and obj_test will be the main dataframes, used for training and testing the model\n",
    "\n",
    "They are primilary built with the request data sets, then features engineered from individuals' data sets are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate analysis object with request data\n",
    "obj_train = cobra.Analysis(requests_train)\n",
    "obj_test = cobra.Analysis(requests_test)\n",
    "obj_full_train = cobra.Analysis(df_full_train)\n",
    "\n",
    "# Define properties\n",
    "\n",
    "# - set target (no copy)\n",
    "obj_train.target = TARGET\n",
    "obj_test.target = TARGET\n",
    "obj_full_train.target = TARGET\n",
    "\n",
    "# - set shape\n",
    "obj_train.m = obj_train.df.shape[0]\n",
    "obj_test.m = obj_test.df.shape[0]\n",
    "obj_train.n = obj_train.df.shape[1]\n",
    "obj_test.n = obj_test.df.shape[1]\n",
    "obj_full_train.m = obj_full_train.df.shape[0]\n",
    "obj_full_train.n = obj_full_train.df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "- Number of requests: 238191\n",
    "\n",
    "- Number of individuals: 384133\n",
    "\n",
    "- Number of features: 39\n",
    "\n",
    "- Requests are made for 1.6 pers on average.\n",
    "\n",
    "\n",
    "Principal components\n",
    "- housing_situation_label: with value \"emergency accomodation\". High probability to get 1 or two nights. Logical since the service treats emergency housing\n",
    "- housing_situation_2_label: with value \"emergency accomodation\". High probability to get 1 or two nights.\n",
    "\n",
    "--------------------\n",
    "\n",
    "\n",
    "Analysis by features\n",
    "\n",
    "\n",
    "A. housing_situation_id\n",
    "- correlation target-housing_situation_id: -0.458581. Strong negative impact. Although the linear numerical relation of the housing_situation_id categories is in my opinion flawed, the strong correlation is explainable as the category with the smallest value \"emergency accomodation\" might be correlated with higher granted_number_of_nights than the rest of the categories, which happen to have higher housing_situation_id values.\n",
    "\n",
    "- housing_situation_2_id: 0.283840. Strong positive impact. Same explanation as housing_situation_id.\n",
    "\n",
    "B. pregnancy\n",
    "- Pregnancy seems not to have a significant direct correlation with target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    obj_train.describe(investigation_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    obj_train.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### housing_situation_2_label\n",
    "\n",
    "- ±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "\n",
    "- ±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "\n",
    "- ±75% (289,870) individuals are \"on the street\"\n",
    "\n",
    "- A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # ±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "    obj_full_train.df[obj_full_train.df['housing_situation_label'] == 'street']\n",
    "\n",
    "    # ±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "    obj_full_train.df.query(\"housing_situation_label == 'street' and housing_situation_2_label == 'on the street'\")\n",
    "\n",
    "    # ±75% (289,870) individuals are \"on the street\"\n",
    "    print(obj_full_train.df['housing_situation_2_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Obs: A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights.\n",
    "\n",
    "    # Impact of feature on target\n",
    "    feature = 'housing_situation_2_label'\n",
    "    mask = obj_full_train.df[feature] == 'emergency accomodation'\n",
    "\n",
    "    # Hist: drop duplicate requests (due to multiple indivs by request)\n",
    "    obj_full_train.df[mask][['request_id', target]].drop_duplicates().hist()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### child_situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'child_situation'\n",
    "\n",
    "    # Display unique values\n",
    "    uniques = obj_train.get_col_uniques(feature)\n",
    "    uniques.sort()\n",
    "    print(\"child_situation possible values:\", *uniques)\n",
    "\n",
    "    # Display distribution\n",
    "    # Obs: Almost any request has child_situation == -1\n",
    "    # hyp: -1 means NaN\n",
    "    dist = obj_train.df[feature].value_counts()\n",
    "    \n",
    "    # Count all non NaNs values\n",
    "    dist_positive = sum(dist[dist.index != -1])\n",
    "    ratio_non_na = dist_positive / obj_train.m\n",
    "    \n",
    "    # Print distribution\n",
    "    print(\"\\nDistribution\\n\", dist)\n",
    "    \n",
    "    # Plot histogram\n",
    "    print(f\"\\n\\nChild_situation non NaN ratio: {round(ratio_non_na * 100, 2)}%\\n\\n\")\n",
    "\n",
    "    # Correlation with target (for non NaNs)\n",
    "    # The proportion of non NaNs is increasing with target values\n",
    "    # The probability of granting more nights is greater when non NaN\n",
    "    dist_grpby = obj_train.df[target].groupby(obj_train.df[feature])\n",
    "    if PLOT_ON:\n",
    "        dist_grpby.hist()\n",
    "        plt.show()\n",
    "\n",
    "    # Study only positive 'child_situation' samples\n",
    "    # TODO: produce a study\n",
    "    mask_pos = obj_train.df['child_situation'] != -1\n",
    "    dist_grpby_pos = obj_train.df[mask_pos][target].groupby(obj_train.df[feature])\n",
    "    if PLOT_ON:\n",
    "        dist_grpby_pos.hist()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### victime_of_violence_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'victim_of_violence_type'\n",
    "    feature_base = 'victim_of_violence'\n",
    "\n",
    "    # Inspect a specific group with violence type \"child\"\n",
    "    # ---------------------------------------------------\n",
    "    # TODO: go further this anecdotical impression\n",
    "    # Obs: \n",
    "    # - violence child can counter intuitively be applied on individuals without child, but awaiting a child.\n",
    "    # - requests seem more likely granted when multiple (non granted) requests have been made in the past\n",
    "    # - requests seem less likely granted when a recent request was granted\n",
    "    # => feature engineer measures to represent these observations\n",
    "\n",
    "    # Mask to filter on child violence only\n",
    "    mask_child_violence = obj_train.df[feature] == 'child'\n",
    "\n",
    "    # Mast to filter group1 entries only\n",
    "    mask_group1 = obj_train.df[mask_child_violence]['group_id'] == '8d79d2cd16e886a947158b5f6e2eff43'\n",
    "\n",
    "    # Sort entries by request_creation_date\n",
    "    grp1_sorted_rq_date = obj_train.df[mask_child][mask_group1].sort_values(by='request_creation_date')\n",
    "\n",
    "    # Get dates and housing values along with target\n",
    "    grp1_sorted_rq_date[[target, 'request_creation_date', 'answer_creation_date', 'housing_situation_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### animal_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'animal_presence'\n",
    "    mask = df_train[feature] == 't'\n",
    "    df_train[mask][[feature, target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requester_type along with group_main_requester_id\n",
    "if it is an urgentist, used to bring individuals to the service, its groups might have higher granted rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### request_backoffice_creator_id\n",
    "this might impact since each people has its own biases (as for the predictions of court decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data\n",
    "\n",
    "Methodology:\n",
    "\n",
    "- Clean-up obj_train.df (initially request dataset)\n",
    "\n",
    "- Feature engineer (using indiv dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaNs\n",
    "\n",
    "Methodology:\n",
    "- inspect NaNs on train set\n",
    "\n",
    "- if pattern detected, apply modifications on train and test sets\n",
    "\n",
    "Observations:\n",
    "- reverse engineering: the system seems to derive group_composition_id from group_composition_label, and both are then necessary linked/redondant => drop group_composition_label\n",
    "\n",
    "Further:\n",
    "- Impute 14 pregnancy NaNs from child_to_come (not useful for the current objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs train summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get Na counts: by feature, by sample\n",
    "    na_ft_train, na_sp_train = obj_train.get_na_counts()\n",
    "    na_ft_test, na_sp_test = obj_test.get_na_counts()\n",
    "    \n",
    "    if PRINT_ON:\n",
    "        print('Train: NaNs count by feature\\n\\n', na_ft_train[na_ft_train!=0])\n",
    "        #print('\\n\\nTest: NaNs count by feature\\n\\n', na_ft_test[na_ft_test!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_to_come NaNs\n",
    "\n",
    "Observation\n",
    "- There are 145947 NaNs for child_to_come on the train set (in request)\n",
    "\n",
    "- There are only 14 NaNs for pregnancy in train set (in individuals)\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: child_to_come is True if any indiv of the group is pregnant\n",
    "\n",
    "Conclusion\n",
    "- => Impute child_to_come from the pregnancy in the group of indiv of the request\n",
    "\n",
    "Control\n",
    "- Verify that the imputation is not only setting to 'f':\n",
    "- -> successful: from the 145947 requests, 5375 are set to 't'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Capture the indexes where NaNs\n",
    "    df_train_raw_nas = obj_train.df[obj_train.df['child_to_come'].isna()]\n",
    "    idx_nas = df_train_raw_nas['child_to_come'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # TODO: refactor (this takes ±3min on light laptop, second on collab)\n",
    "    # Impute train set\n",
    "    obj_train.impute_child_to_come(df_indiv=individuals_train)\n",
    "    # Impute test set\n",
    "    obj_test.impute_child_to_come(df_indiv=individuals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get number of NaNs imputed as False and True\n",
    "    obj_train.df.loc[idx_nas]['child_to_come'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute housing_situation_label\n",
    "\n",
    "The following code cells are organized as follows for clarity:\n",
    "- Imputation steps\n",
    "\n",
    "- Analysis\n",
    "\n",
    "Observations\n",
    "\n",
    "A. Meta numbers\n",
    "- ±7% (16,748) NaNs for housing_situation_label (request)\n",
    "\n",
    "- 0 NaN for housing_situation_id (request)\n",
    "\n",
    "- 0 NaN for housing_situation_label_2 (individuals)\n",
    "\n",
    "- 0 NaN for housing_situation_id_2 (individuals)\n",
    "\n",
    "- 21 housing_situation_label (request)\n",
    "\n",
    "- 22 housing_situation_id (request)\n",
    "\n",
    "B. Specific ratios\n",
    "- ±10% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "\n",
    "- ±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "\n",
    "C. Analysis 1\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n",
    "\n",
    "D. Analysis 2\n",
    "- housing_situation_2_label can be very diverse when housing_situation_label is NaN (17 over 21 cat)\n",
    "\n",
    "- => housing_situation_label NaNs are not produced in a specific housing_situation_2_label situation\n",
    "\n",
    "E. Analysis 3\n",
    "- all individuals of a same request share the same housing_situation_2_label\n",
    "\n",
    "- => NaNs do not come from a problem of aggregating indiv data\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: the housing situation should logically have an impact on the result\n",
    "\n",
    "- Hyp: proba being on the street is significantly high to always impute NaN with 'street'\n",
    "\n",
    "- Hyp: housing_ids are not sorted in any specific order from which a logic could be derived. Thus, having numerical ids is dangereous and could lead to misinterpretations by the model.\n",
    "\n",
    "Conclusion\n",
    "- => Impute housing_situation_label NaNs as 'street'\n",
    "\n",
    "- => Drop housing_situation_id\n",
    "\n",
    "- => one-hot encode housing_situation_label\n",
    "\n",
    "\n",
    "Further improvements\n",
    "- derive more sub-groups: when a group is not housing_situation_label_2 'on the street', impute the request housing_situation_label with its most often matched value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute NaNs with the single value 'street'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # TODO: impute more properly \n",
    "    \n",
    "    # Impute housing_situation_label NaNs as 'street'\n",
    "    obj_train.df.loc[obj_train.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'\n",
    "    obj_test.df.loc[obj_test.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'\n",
    "\n",
    "    # Drop housing_situation_id\n",
    "    obj_train.df.drop('housing_situation_id', axis=1, inplace=True)\n",
    "    obj_test.df.drop('housing_situation_id', axis=1, inplace=True)\n",
    "\n",
    "    # One-hot encoding is applied later-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the mapping of housing_situation_id - housing_situation_label\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_id - housing_situation_label\n",
    "    map_housing_id_label = obj_train.df.loc[:, ['housing_situation_id', 'housing_situation_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index for clarity\n",
    "    map_housing_id_label = map_housing_id_label.sort_values(by='housing_situation_id')\n",
    "    map_housing_id_label.reset_index(drop=True, inplace=True)\n",
    "    map_housing_id_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze relation between housing_situation_label (request) and housing_situation_2_label (indiv)\n",
    "\n",
    "Make a temporary dataframe with columns:\n",
    "\n",
    "| request_id | gr_nb_nights | hous_id | hous_lab | indiv_id | hous_2id | hous2_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # request [gr_nb_nights, hous_id, hous_lab]\n",
    "    rq = obj_train.df.loc[:, ['granted_number_of_nights',\n",
    "                                'housing_situation_id',\n",
    "                                'housing_situation_label']]\n",
    "\n",
    "    # individuals [request_id, indiv_id, hous_2id, hous2_lab]\n",
    "    ind = individuals_train.loc[:, ['request_id',\n",
    "                                    'individual_id',\n",
    "                                    'housing_situation_2_id',\n",
    "                                    'housing_situation_2_label']]\n",
    "    ind.set_index('request_id', inplace=True)\n",
    "\n",
    "    # Merge request and individuals datasets\n",
    "    obj_full_train = pd.merge(rq, ind, on='request_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Nb of indivs (an indiv is considered a new indiv at each request)\n",
    "    nb_indivs = obj_full_train.shape[0]\n",
    "\n",
    "    # ±6% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "    obj_full_train[obj_full_train['housing_situation_label'].isna()]\n",
    "\n",
    "    # ±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "    df_temp = obj_full_train[obj_full_train[\"housing_situation_label\"].isna()]\n",
    "    df_temp['housing_situation_2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect individuals with housing_situation_2_label \"on the street\":\n",
    "\n",
    "- they can have a very diverse housing_situation (17 categories over a total of 21)\n",
    "\n",
    "- => no pattern to derive from this point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    q = obj_full_train.query(\"housing_situation_label.isna() and housing_situation_2_label != 'on the street'\")\n",
    "\n",
    "    # Count number of categories for housing_situation_2_label\n",
    "    n_cat_2 = len(q.loc[:, 'housing_situation_2_label'].unique())\n",
    "\n",
    "    # Total categories for the feature\n",
    "    n_cat_1 = len(obj_train.get_col_uniques('housing_situation_label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if housing_situation_label NA exist when indiv within a group have different housing_situation_2\n",
    "\n",
    "- no divergence\n",
    "\n",
    "- => when group, all indiv have the same housing_situation_2_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # takes ±1min\n",
    "    if False:\n",
    "        # Get request_id along with its group size\n",
    "        rq_id = obj_full_train.index.value_counts()\n",
    "        for i in range(70000):\n",
    "            # Get ith rq_id\n",
    "            rq_id_i = rq_id.index[0]\n",
    "\n",
    "            # Observe if housing_situation_label same for all the group members\n",
    "            n_uni_grp = len(obj_full_train.loc[rq_id_i]['housing_situation_label'].unique())\n",
    "            n_uni_indiv = len(obj_full_train.loc[rq_id_i]['housing_situation_2_label'].unique())\n",
    "\n",
    "            if n_uni_grp > 1 or n_uni_indiv > 1:\n",
    "                print(i)\n",
    "                print(n_uni_grp, n_uni_indiv)\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further improvements: derive the most probable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_label - housing_situation_2_label\n",
    "    obj_full_train_no_na = obj_full_train[~obj_full_train.housing_situation_label.isna()]\n",
    "    map_housing_labels = obj_full_train_no_na.loc[:, ['housing_situation_label', 'housing_situation_2_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index\n",
    "    map_housing_labels = map_housing_labels.sort_values(by='housing_situation_label')\n",
    "    map_housing_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute long_term_housing_request NaNs\n",
    "\n",
    "Nb NaNs: 165556\n",
    "\n",
    "Type: bool\n",
    "\n",
    "It seems to have no direct impact on target\n",
    "\n",
    "=> drop feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    ft = 'long_term_housing_request'\n",
    "    ma_na = obj_train.df[ft].isna()\n",
    "    ma_true = obj_train.df[ft] == 't'\n",
    "\n",
    "    # Is long_term_housing_request true when 'street' only?\n",
    "    # - No\n",
    "    obj_train.df[ma_true]['housing_situation_id'].value_counts()\n",
    "\n",
    "    # Does ft impact target?\n",
    "    # - Not directly\n",
    "    ct_true   = obj_train.df[ma_true][target].value_counts()\n",
    "    ct_false  = obj_train.df[~ma_true][target].value_counts()\n",
    "    ct_na     = obj_train.df[ma_na][target].value_counts()\n",
    "    ct_non_na = obj_train.df[~ma_na][target].value_counts()\n",
    "\n",
    "    if PRINT_ON:\n",
    "        print(\"ratios target when lt_housing true\")\n",
    "        for elem in ct_true:\n",
    "            print(f\"{round(elem/sum(ct_true)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing false\")\n",
    "        for elem in ct_false:\n",
    "            print(f\"{round(elem/sum(ct_false)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing NaN\")\n",
    "        for elem in ct_na:\n",
    "            print(f\"{round(elem/sum(ct_na)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing not NaN\")\n",
    "        for elem in ct_non_na:\n",
    "            print(f\"{round(elem/sum(ct_non_na)*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    obj_train.df.drop('long_term_housing_request', axis=1, inplace=True)\n",
    "    obj_test.df.drop('long_term_housing_request', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute town NaNs\n",
    "\n",
    "Nb NaNs: 159959\n",
    "\n",
    "categorical: cat_many\n",
    "\n",
    "Obs: The distribution is very uneven\n",
    "\n",
    "hyps:\n",
    "- very probable to live in a town, and ask housing in the district of our town\n",
    "\n",
    "- request_backoffice_creator_id: lives and makes requests in the same town, if the missing town is found in another request, all other NaNs with this backoffice_creator can be imputed properly\n",
    "\n",
    "- individual_id: might have missed town info in a request, but not in another (if requests are close, the probability to live in the same town is high)\n",
    "\n",
    "=> attribute the most probable town based on request district\n",
    "\n",
    "- 1 => build mapping of town-district pairs\n",
    "\n",
    "- 2 => attribute the corresponding pair for each NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Check that all values are available for district\n",
    "    # - Yes\n",
    "    sum(obj_full_train.df[ma_na]['district'].isna()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # Build mapping town-distric\n",
    "    mapping_town_district_train = obj_train.get_features_mapping('district', 'town')\n",
    "\n",
    "    # Fill 'town' NaNs with the most frequent occurence\n",
    "    # in the pair feature 'district'. Use the mapping\n",
    "    obj_train.fill_na_most_freq_pair('town', 'district', \n",
    "                                    mapping = mapping_town_district_train,\n",
    "                                    inplace = True)\n",
    "    obj_test.fill_na_most_freq_pair('town', 'district',\n",
    "                                    mapping = mapping_town_district_train,\n",
    "                                    inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute victim_of_violence_type NaNs\n",
    "\n",
    "Nb NaNs: 234175\n",
    "\n",
    "Hyp: is NaN if victim_of_violence is 'f'\n",
    "\n",
    "=> Set a specific value to NaNs where victim_of_violence is 'f', which will later be transformed into a boolean\n",
    "\n",
    "=> Set another specific value to NaNs where victim_of_violence is 't', IDEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Obs: the grand majority of victim_of_violence_type NaNs comes\n",
    "    # from the absence of violence (trivial)\n",
    "    print(\"victim bool distribution\\n\",\n",
    "            obj_train.df['victim_of_violence'].value_counts())\n",
    "    print(\"\\nvictim type NaNs\\n\",\n",
    "            obj_train.df['victim_of_violence_type'].isna().value_counts())\n",
    "\n",
    "    # For the remaining victim_of_violence_type NaNs\n",
    "    # only  half requests are not granted when victim_of_violence 't',\n",
    "    remaining_nans = obj_train.df[obj_train.df['victim_of_violence'] == 't']\\\n",
    "                                [obj_train.df['victim_of_violence_type'].isna()]\n",
    "    \n",
    "    print(\"\\nRemaining Nans\\n\", remaining_nans[target].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    feature = 'victim_of_violence_type'\n",
    "    feature_base = 'victim_of_violence'\n",
    "\n",
    "    # Impute NaNs corresponding to no violence signaled by 'no violence'\n",
    "    idx_na_no_violence_train = obj_train.df[obj_train.df[feature_base] == 'f'][obj_train.df[feature].isna()].index\n",
    "    idx_na_no_violence_test = obj_test.df[obj_test.df[feature_base] == 'f'][obj_test.df[feature].isna()].index\n",
    "    obj_train.df.loc[idx_na_no_violence_train, feature] = 'no violence'\n",
    "    obj_test.df.loc[idx_na_no_violence_test, feature] = 'no violence'\n",
    "\n",
    "    # Impute NaNs corresponding to a lack of specification, but with violence signaled by 'no detail'\n",
    "    idx_na_no_detail_train = obj_train.df[obj_train.df[feature_base] == 't'][obj_train.df[feature].isna()].index\n",
    "    idx_na_no_detail_test = obj_test.df[obj_test.df[feature_base] == 't'][obj_test.df[feature].isna()].index\n",
    "    obj_train.df.loc[idx_na_no_detail_train, feature] = 'no detail'\n",
    "    obj_test.df.loc[idx_na_no_detail_test, feature] = 'no detail'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_situation \n",
    "(hyp: -1 values are NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    ft_child = 'child_situation'\n",
    "    ft_violence = 'victim_of_violence_type'\n",
    "\n",
    "    # child_situation might be linked with:\n",
    "    # - group_composition_id: 58 combinations with ft\n",
    "    # - social_situation_id: no, it is redondant with group_id\n",
    "    # - victim_of_violence_type (if child): 34 combinations with ft (better)\n",
    "    obj_train.df[ft_child].value_counts()\n",
    "\n",
    "    # Get combinations for child_situation and victim_of_violence_type\n",
    "    df_temp = obj_train.df[[ft_child, ft_violence]]\\\n",
    "                            .sort_values(by = ft_violence)\n",
    "    df_temp.drop_duplicates(ignore_index=True)\\\n",
    "                            .sort_values(by = ft_violence)\n",
    "\n",
    "    # victim_of_violence_type\n",
    "    # Obs: only child_situation -1 and 10 (ie. only 10)\n",
    "    ma_child = df_temp[ft_violence] == 'child'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    ft_child = 'child_situation'\n",
    "    ft_violence = 'victim_of_violence_type'\n",
    "\n",
    "    # Hyp: -1 (NaNs) for child_situation should be 10 when victim_of_violence_type 'child'\n",
    "    # => replace child_situation by 10 when victim_of_violence_type 'child'\n",
    "    idx_child_train = obj_train.df[obj_train.df[ft_violence] == 'child'].index\n",
    "    idx_child_test = obj_test.df[obj_test.df[ft_violence] == 'child'].index\n",
    "    obj_train.df.loc[idx_child_train, ft_child] = 10\n",
    "    obj_test.df.loc[idx_child_test, ft_child] = 10\n",
    "\n",
    "    # Idem for 'family'\n",
    "    idx_family_train = obj_train.df[obj_train.df[ft_violence] == 'family'].index\n",
    "    idx_family_test = obj_test.df[obj_test.df[ft_violence] == 'family'].index\n",
    "    obj_train.df.loc[idx_family_train, ft_child] = 10\n",
    "    obj_test.df.loc[idx_family_test, ft_child] = 10\n",
    "\n",
    "    # TODO: impute the rest (majority :( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute remaining test set NaNs\n",
    "(that have no equivalent in train set, and thus can't be studied to build a clever imputation method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # TODO: implement method based on train set logic for any feature\n",
    "    obj_train.set_default_na_vals()\n",
    "\n",
    "    # Transfer default NaNs to test object (no need to copy)\n",
    "    obj_test.default_na_vals = obj_train.default_na_vals\n",
    "\n",
    "    # Impute any remaining NaN based on its default value\n",
    "    obj_test.impute_nans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop answer creation date\n",
    "hyp: the variable is not available at prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of the competition, is it expected to be used?\n",
    "if FUTURE_PRED:\n",
    "    obj_train.df.drop('answer_creation_date', axis=1, inplace=True)\n",
    "    obj_test.df.drop('answer_creation_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete old samples\n",
    "(if it was to predict future requests (> 2020))\n",
    "- Train/test split being done randomly (≠ historically), it is important for this competition to train the model on the whole train set (don't remove old samples)\n",
    "- Delete samples with group_creation_date < 2015, since it is very unlikely that current demands are treated like +5 years ago (social services evolve)\n",
    "- Threshold date: see if later is better, potential gains from domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FUTURE_PRED:\n",
    "    # Drop samples with year < 2015\n",
    "    old_samples = obj_train.df[obj_train.df.group_creation_date.dt.year < 2015]\n",
    "    obj_train.df.drop(old_samples.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender\n",
    "\n",
    "- => Only females are possibly pregnant, thus 30 males have made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Retrieve the individual ids, and correct for male -> pregnancy = 0\n",
    "#obj_train.df['gender'].groupby(obj_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterize large categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make clusters then transform using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dates\n",
    "- into linear numerical features (year, month)\n",
    "\n",
    "- and into categorical features (hot_season, col_season:T/F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features: Dates to year, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns of date type\n",
    "list_date_cols = [\n",
    "    'request_creation_date',\n",
    "    'group_creation_date'\n",
    "]\n",
    "\n",
    "# Don't use the feature if trying to build robust in-production model\n",
    "if not FUTURE_PRED:\n",
    "    list_date_cols.append('answer_creation_date')\n",
    "\n",
    "# Transform date type: string to timestamp\n",
    "for col in list_date_cols:\n",
    "    obj_train.df[col] = pd.to_datetime(obj_train.df[col])\n",
    "    obj_test.df[col] = pd.to_datetime(obj_test.df[col])\n",
    "\n",
    "# Create feature: 'year'\n",
    "for col in list_date_cols:\n",
    "    obj_train.df[col[:-4]+'year'] = obj_train.df[col].dt.year\n",
    "    obj_test.df[col[:-4]+'year'] = obj_test.df[col].dt.year\n",
    "\n",
    "# Create feature: 'month'\n",
    "for col in list_date_cols:\n",
    "    obj_train.df[col[:-4]+'month'] = obj_train.df[col].dt.month\n",
    "    obj_test.df[col[:-4]+'month'] = obj_test.df[col].dt.month\n",
    "\n",
    "# Drop raw features of type date\n",
    "for col in list_date_cols:\n",
    "    obj_train.df.drop(col, axis=1, inplace=True)\n",
    "    obj_test.df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feats: hot_season, cold_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create district_grant_ratio and town_grant_ratio\n",
    "\n",
    "Type:\n",
    "- num (float), can be linearly separable\n",
    "\n",
    "Obs:\n",
    "- district_grant_ratio: has a large impact, with districts granting more nights than there are requests and some refusing way more often\n",
    "\n",
    "- town_grant_ratio: has a large impact, with nights granted more for individuals from a specific towns (eg. Amiens is 4x)\n",
    "\n",
    "Hyp:\n",
    "- it is a sort of district emergency housing capacity measurement against the emergency housing demand\n",
    "\n",
    "- it should be very close, redondant? Yes in part, the correlation is very high (88%), but the discrepancies might come from valuable information\n",
    "\n",
    "- => create ratio of the distance between town and district of a request\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature district_grant_ratio\n",
    "obj_train.create_ft_grant_ratio('district')\n",
    "obj_test.create_ft_grant_ratio('district')\n",
    "\n",
    "# Create new feature town_grant_ratio\n",
    "obj_train.create_ft_grant_ratio('town')\n",
    "obj_test.create_ft_grant_ratio('town')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: distance between town and district\n",
    "or a simpler version: if town is from this district or another\n",
    "\n",
    "- if town in district: 0\n",
    "- else: 1\n",
    "\n",
    "Since there are 1116 towns, doing the mapping would take 3h if 10s by town\n",
    "\n",
    "=> another time, or say, let the model firgure it out <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create town_capacity_left\n",
    "This can be computed on the month or the year. It provides a guess of the number of nights that can be granted at time of request (using past request then)\n",
    "\n",
    "Hyp: it might be the most impactful feature, since the selectivity based on personal criteria is lowered or inexistant when there is a large emergency housing capacity left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Town and District to regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: group_age_max, group_age_min\n",
    "\n",
    "Based on individuals information birth_month, birth_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set current year\n",
    "year_curr = pd.datetime.now().year\n",
    "\n",
    "# Compute age for each sample from birth_year\n",
    "s_age = year_curr - obj_full_train.df['birth_year']\n",
    "\n",
    "# Add the index to the series, and transform it as df\n",
    "df_age = pd.DataFrame(s_age).set_index(obj_full_train.df.request_id)\n",
    "\n",
    "# Compute max age by request_id\n",
    "max_age = df_age.groupby('request_id').max()\n",
    "min_age = df_age.groupby('request_id').min()\n",
    "\n",
    "# Merge min and max age dfs\n",
    "df_age_merged = pd.merge(max_age, min_age, left_index=True, right_index=True)\n",
    "\n",
    "# Rename columns\n",
    "df_age_merged.columns = ['age_max', 'age_min']\n",
    "\n",
    "# Merge with obj_train.df\n",
    "obj_train.df = pd.merge(obj_train.df, df_age_merged, left_index=True, right_index=True)\n",
    "\n",
    "# Control the merge is proper\n",
    "ma = df_temp['age_max'] != df_temp['age_min']\n",
    "#df_temp[ma]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of indivs in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past requests by indivs forming the group of the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Single individual\n",
    "\n",
    "# Get number of ALL requests of indiv with max n_requests\n",
    "#ind_id = obj_full_train['individual_id'].value_counts().index[0]\n",
    "\n",
    "# Watch request made by the same indiv\n",
    "#obj_full_train[obj_full_train['individual_id'] == ind_id]\n",
    "\n",
    "# TODO: Past requests only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past granted request by indivs forming the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop numerical columns\n",
    "(that can't be used properly, or untill transformation methods are implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: transform before drop: request_backoffice_creator_id\n",
    "list_drop = [\n",
    "    'district',  # replaced by district_grant_ratio\n",
    "    'town',      # replace by town_grant_ratio\n",
    "    'group_id',\n",
    "    'group_main_requester_id',\n",
    "    'request_backoffice_creator_id',\n",
    "    'social_situation_id'\n",
    "]\n",
    "\n",
    "for feature in list_drop:\n",
    "    obj_train.df.drop(feature, axis=1, inplace=True)\n",
    "    obj_test.df.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical features\n",
    "Prepare data to feed models\n",
    "\n",
    "- booleans: replace by (1, 0)\n",
    "\n",
    "- 2 < cats < 11: one-hot encoding\n",
    "\n",
    "- No transform on features with more than 11 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show standard data type: True\n",
    "# Show personalized (provide insight on information level)\n",
    "STANDARD = False\n",
    "\n",
    "if ANALYZE_ON:\n",
    "    if STANDARD:\n",
    "        # Display standard data types\n",
    "        print(obj_train.df.dtypes)\n",
    "    else:\n",
    "        # Display col name along its type (bool, cat, num, empty)\n",
    "        for col, col_type in zip(obj_train.df.columns, obj_train.get_cols_type()):\n",
    "            print(col_type, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform all categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traform categorical features:\n",
    "# - booleans: ('t', 't') into (1, 0)\n",
    "# - categorical with few/med classes: one-hot encoding\n",
    "bools_train, failed_train = obj_train.transform_categories(\n",
    "                                        target=obj_train.target)\n",
    "bools_test, failed_test = obj_test.transform_categories(\n",
    "                                        target=obj_test.target)\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "obj_train.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "obj_test.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Export data\n",
    "if EXPORT_DATA:\n",
    "    obj_train.export_data('data/data_train_preprocessed.csv')\n",
    "    obj_test.export_data('data/data_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "If training directly with the criterion weights, the model is rapidly stuck in a bad local optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data, tools, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_PREPROCESSED_DATA:\n",
    "    train_preprocessed = pd.read_csv(filepath_or_buffer='data/data_train_preprocessed.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "    test_preprocessed = pd.read_csv(filepath_or_buffer='data/data_test_preprocessed.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "\n",
    "    # Instanciate data objects\n",
    "    obj_train = cobra.Analysis(train_preprocessed)\n",
    "    obj_test = cobra.Analysis(test_preprocessed)\n",
    "\n",
    "    # Set target\n",
    "    obj_train.target = TARGET\n",
    "    obj_test.target = TARGET\n",
    "\n",
    "    # Set request_id as index\n",
    "    obj_train.df.set_index('request_id', inplace=True)\n",
    "    obj_test.df.set_index('request_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between selecting or dropping columns\n",
    "SELECT = False\n",
    "\n",
    "# Drop only the following features, keep the others\n",
    "# -------------------------------------------------\n",
    "if not SELECT:\n",
    "    drop_features = [\n",
    "        'request_creation_year',\n",
    "        'group_creation_year',\n",
    "        'answer_creation_year'\n",
    "    ]\n",
    "    df_train = obj_train.df.drop(*[drop_features], axis=1, inplace=False)\n",
    "    df_test  = obj_train.df.drop(*[drop_features], axis=1, inplace=False)\n",
    "\n",
    "else:\n",
    "    # Select and keep only the following features\n",
    "    # -------------------------------------------\n",
    "    use_features = [\n",
    "        'district_grant_ratio'\n",
    "    ]\n",
    "    # Append target col to the list of columns to keep\n",
    "    use_cols = use_features + [obj_train.target]\n",
    "    \n",
    "    # Create df with selected cols only\n",
    "    df_train = obj_train.df[use_cols]\n",
    "    df_test  = obj_test.df[use_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and tensorize data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train/cross-validation split:\n",
    "# .8 means 80% of samples in the train set,\n",
    "# and the remaining, 20%, in validation set\n",
    "TRAIN_VAL_SPLIT = .8\n",
    "\n",
    "# Reset the target feature\n",
    "# (in case it has been changed during debugging)\n",
    "target = obj_train.target\n",
    "\n",
    "# Mask - select all features columns but the target\n",
    "ma_ft = df_train.columns != target\n",
    "\n",
    "# Separate target and features\n",
    "X_train_full = df_train.loc[:,ma_ft]\n",
    "X_test       = df_test.loc[:,ma_ft]\n",
    "Y_train_full = df_train.loc[:,target]\n",
    "Y_test       = df_test.loc[:,target]\n",
    "\n",
    "# Split train into: train / cross-val sets\n",
    "n_train = round(X_train_full.shape[0] * TRAIN_VAL_SPLIT)\n",
    "X_train = X_train_full[:n_train]\n",
    "X_val   = X_train_full[n_train:]\n",
    "Y_train = Y_train_full[:n_train]\n",
    "Y_val   = Y_train_full[n_train:]\n",
    "\n",
    "# Transform pandas dataframes into torch tensors\n",
    "X_train = torch.from_numpy(X_train.values)\n",
    "X_val   = torch.from_numpy(X_val.values)\n",
    "X_test  = torch.from_numpy(X_test.values)\n",
    "Y_train = torch.from_numpy(Y_train.values)\n",
    "Y_val   = torch.from_numpy(Y_val.values)\n",
    "Y_test  = torch.from_numpy(Y_test.values)\n",
    "\n",
    "# Cast all to float type\n",
    "X_train = X_train.float()\n",
    "X_val   = X_val.float()\n",
    "X_test  = X_test.float()\n",
    "Y_train = Y_train.float()\n",
    "Y_val   = Y_val.float()\n",
    "Y_test  = Y_test.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate datasets\n",
    "dataset_train = cobra.Dataset(X=X_train, Y=Y_train)\n",
    "dataset_val   = cobra.Dataset(X=X_val,   Y=Y_val)\n",
    "dataset_test  = cobra.Dataset(X=X_test,  Y=Y_test)\n",
    "\n",
    "# Instantiate data loaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size = dataset_train.len)\n",
    "dataloader_val   = torch.utils.data.DataLoader(dataset_val,   batch_size = dataset_val.len)\n",
    "dataloader_test  = torch.utils.data.DataLoader(dataset_test,  batch_size = dataset_test.len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model properties\n",
    "MODEL_LAYERS = [X_train.shape[1], 50, 40, 30, N_TARGET_CLASS]  # [hidden1, ...]\n",
    "LEARNING_RATE= .1\n",
    "MOMENTUM= .8\n",
    "WEIGHT_DECAY = 0\n",
    "DROPOUT_RATIO = 0\n",
    "SEED = 500\n",
    "\n",
    "# Reimport module\n",
    "importlib.reload(cobra)\n",
    "\n",
    "# Initialize model and weights\n",
    "model = cobra.NN(MODEL_LAYERS,\n",
    "                 p=DROPOUT_RATIO,\n",
    "                 seed=SEED)\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                        lr=LEARNING_RATE,\n",
    "                        momentum=MOMENTUM,\n",
    "                        weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Reset performances history\n",
    "monitor_epochs = cobra.Monitoring(sets=SETS,\n",
    "                                  metrics=METRICS)\n",
    "monitor_batchs = cobra.Monitoring(sets=SETS,\n",
    "                                  metrics=METRICS)\n",
    "\n",
    "\n",
    "if PRINT_ON:\n",
    "    # Calculate the number of weights\n",
    "    n_weights = cobra.calculate_n_weights(MODEL_LAYERS)\n",
    "    print('Number of model weights', n_weights)\n",
    "    \n",
    "    # Show storing format\n",
    "    monitor_epochs.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast weights to tensor format\n",
    "CLASS_WEIGHTS = [1, 10, 100, 1000]  # compet standard\n",
    "class_weights = torch.FloatTensor(CLASS_WEIGHTS)\n",
    "CRITERION = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Set monitoring properties\n",
    "SETS = ['train', 'eval', 'test']\n",
    "METRICS = {'accuracy': cobra.compute_accuracy,\n",
    "           'loss_model': CRITERION,\n",
    "           'loss_compet': cobra.competition_scorer} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Train model\n",
    "n_epochs = 20\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # Reset batchs scores\n",
    "    monitor_batchs.reset()\n",
    "\n",
    "    # Training\n",
    "    # --------\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_train):\n",
    "\n",
    "        # Predict\n",
    "        predictions = model(x)\n",
    "\n",
    "        # Evaluate model and store metrics\n",
    "\n",
    "        loss = monitor_batchs.evaluate(predictions, labels, 'train')\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Backpropagate\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    # ----------\n",
    "    with torch.no_grad():\n",
    "        for n_batch, (x, labels) in enumerate(dataloader_val):\n",
    "            \n",
    "            # Predict on the eval set\n",
    "            predictions = model(x)\n",
    "\n",
    "            # Evaluate model and store metrics\n",
    "            monitor_batchs.evaluate(predictions, labels, set_i='eval')\n",
    "\n",
    "\n",
    "    # Compute & store: train and eval losses for the epoch\n",
    "    monitor_epochs.compute(monitor_batchs, ['train', 'eval'])\n",
    "    \n",
    "    # Display scores\n",
    "    monitor_epochs.print_scores(i_epoch=epoch, sets=['train', 'eval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation losses history\n",
    "for metric in monitor_batchs.metrics_info:\n",
    "    print(f\"\\n{metric} plot (blue: train | orange: eval)\")\n",
    "    for set_i in monitor_batchs.sets_names:\n",
    "        plt.plot(monitor_epochs.metrics[set_i][metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Transform logits into probabilities\n",
    "y_pred = F.softmax(predictions)\n",
    "\n",
    "# Transform tensors to numpy arrays\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y = labels.numpy()\n",
    "\n",
    "# Display probas predicted\n",
    "print('\\nProbas predicted:\\n', y_pred)\n",
    "\n",
    "# Display the number of uniques probas (see the diversity of predictions)\n",
    "print(\"\\nQuantity of unique probas:\", \\\n",
    "        len(np.unique(F.softmax(predictions).detach().numpy(), axis=0)))\n",
    "print(\"\\n6 first uniques:\\n\", \\\n",
    "        np.unique(F.softmax(predictions).detach().numpy(), axis=0)[:6])\n",
    "\n",
    "# Transform array of predicted probas into vector of ints\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# Values used\n",
    "print('\\nvalues used for predictions:', *np.unique(y_pred))\n",
    "\n",
    "# Transform arrays into dataframes\n",
    "df_results = pd.DataFrame({'y': y, 'y_pred': y_pred})\n",
    "\n",
    "# Compute accuracy ratio\n",
    "print(f'\\nAccuracy model {round(100 * sum(y_pred == y)/len(y), 4)}%')\n",
    "\n",
    "# Display value counts\n",
    "print('\\n\\nPredictions:')\n",
    "print(df_results['y_pred'].value_counts())\n",
    "print('\\ntarget:')\n",
    "print(df_results['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "On the test set (and no longer validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test set\n",
    "# --------\n",
    "with torch.no_grad():\n",
    "    # Reset batchs scores\n",
    "    monitor_batchs.reset()\n",
    "\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_test):\n",
    "        # Predict on the test set\n",
    "        predictions = model(x)\n",
    "        \n",
    "        # Evaluate model and store metrics\n",
    "        monitor_batchs.evaluate(predictions, labels, set_i='test')\n",
    "\n",
    "# Compute & store: train and eval losses for the epoch\n",
    "monitor_epochs.compute(monitor_batchs, ['test'])\n",
    "\n",
    "# Display scores\n",
    "monitor_epochs.print_scores(i_epoch=epoch, ['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monitor_epochs.metrics['test']['loss_compet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights/weights_new.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with benchmarks preds\n",
    "\n",
    "- Uniform random predictions\n",
    "\n",
    "- Dumb prediction of the best label on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_train = Y_train.shape[0]\n",
    "m_val = Y_val.shape[0]\n",
    "m_test = Y_test.shape[0]\n",
    "\n",
    "# Create numpy copy of target (from tensors)\n",
    "y_train = Y_train.numpy().astype(np.int_)\n",
    "y_val = Y_val.numpy().astype(np.int_)\n",
    "y_test = Y_test.numpy().astype(np.int_)\n",
    "\n",
    "# Random uniform train/test\n",
    "random_preds_train = np.random.uniform(size=(Y_train.shape[0], 4))\n",
    "random_preds_val = np.random.uniform(size=(Y_val.shape[0], 4))\n",
    "random_preds_test = np.random.uniform(size=(Y_test.shape[0], 4))\n",
    "\n",
    "# Create empty benchmark dumb\n",
    "dumb_preds_train = np.zeros((m_train, 4)) + .49\n",
    "dumb_preds_val = np.zeros((m_val, 4)) + .49\n",
    "dumb_preds_test = np.zeros((m_test, 4)) + .49\n",
    "\n",
    "# Benchmark dumb predict always 0 nights (the most )\n",
    "dumb_preds_train[range(m_train), 0] = .5\n",
    "dumb_preds_val[range(m_val), 0] = .5\n",
    "dumb_preds_test[range(m_test), 0] = .5\n",
    "\n",
    "# Evaluate preds\n",
    "# Random\n",
    "random_loss_train = cobra.competition_scorer(random_preds_train, y_train)\n",
    "random_loss_val = cobra.competition_scorer(random_preds_val, y_val)\n",
    "random_loss_test = cobra.competition_scorer(random_preds_test, y_test)\n",
    "# Dumb\n",
    "dumb_loss_train = cobra.competition_scorer(dumb_preds_train, y_train)\n",
    "dumb_loss_val = cobra.competition_scorer(dumb_preds_val, y_val)\n",
    "dumb_loss_test = cobra.competition_scorer(dumb_preds_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Random preds\")\n",
    "print(round(random_loss_train, 4))\n",
    "print(round(random_loss_val, 4))\n",
    "print(round(random_loss_test, 4))\n",
    "\n",
    "print(\"\\nDumb preds\")\n",
    "print(round(dumb_loss_train, 4))\n",
    "print(round(dumb_loss_val, 4))\n",
    "print(round(dumb_loss_test, 4))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}