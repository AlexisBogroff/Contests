{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "#### Goal: Predict the number of nights granted to a request (not to an individual)\n",
    "\n",
    "\n",
    "#### Caracteristics of the model:\n",
    "Accuracy:\n",
    "- if used as a clearing tool removing overburden upfront, and thus only to get rid of obvious cases, the accuracy of such a tool could be its most important caracteristic.\n",
    "\n",
    "Interpretability:\n",
    "- could help families understand the decision (although not as important as in diseases predictions).\n",
    "- can also highlight and thus control biases (racial, sex, age).\n",
    "- since the tool would probably be used in combination with human selection, it could help save time by highlighting the main factors for each decision\n",
    "\n",
    "#### Conclusion:\n",
    "- a model easily interpretable could be prefered (tree).\n",
    "- or a highly accurate model (less interpretable) could also be used upfront (NN).\n",
    "\n",
    "\n",
    "#### Future improvements\n",
    "\n",
    "Imputations:\n",
    "- Build more robust, generalisable imputations (eg. impute future test samples with missing gender based on all easily interpretable categories group_composition_label and group_composition_id)\n",
    "\n",
    "- Automate NaNs imputation for future test samples\n",
    "\n",
    "- Reconstruct some NaNs by training models to predict the feature\n",
    "\n",
    "\n",
    "Feature engineering\n",
    "\n",
    "Datasets handling\n",
    "- I made the choice to keep the train and test sets split. This is to prevent gaining insight from the test set while doing pre-processing, analysis and while training the model. To prevent duplicate code, I thus placed most of the inner workings in the class Analysis, which makes the reading less fluent. To improve, see how to better combine the visual aspect of Jupyter Notebooks, while maintaining code standards like DRY philosophy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "I. Load\n",
    "\n",
    "1. Packages, classes, functions\n",
    "\n",
    "2. Databases (no join)\n",
    "\n",
    "II. Pre-process data 1:\n",
    "\n",
    "1. Impute NaNs\n",
    "\n",
    "2. Remove outliers\n",
    "\n",
    "III. Analyze\n",
    "\n",
    "1. Impact on target\n",
    "\n",
    "2. Correlated features\n",
    "\n",
    "IV. Pre-process data 2:\n",
    "\n",
    "1. Transform categorical features\n",
    "\n",
    "V. Build Model\n",
    "\n",
    "1. Benchmakrs\n",
    "\n",
    "2. Rush model using all data\n",
    "\n",
    "3. Simple using principal components\n",
    "\n",
    "4. More complex using specific features\n",
    "\n",
    "5. Ensemble\n",
    "\n",
    "VI. Predictions\n",
    "\n",
    "1. Train and Predict\n",
    "\n",
    "2. Hyperparameter tunning (split train set)\n",
    "\n",
    "VII. Evaluate methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes, Functions & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import tree\n",
    "\n",
    "#os.chdir('/Users/Pro/Desktop/Git_Contests/Predictions/Emergency_housing/')\n",
    "from cobratools import Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test scorer\n",
    "def competition_scorer(y_true, y_pred):\n",
    "    return log_loss(y_true, y_pred, sample_weight=10**y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to False to only apply data transformations\n",
    "# (rather than derive the whole analysis)\n",
    "ANALYZE_ON = True\n",
    "\n",
    "# Set to True to visualize\n",
    "PRINT_ON = True  # verbose\n",
    "PLOT_ON = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_train = pd.read_csv(filepath_or_buffer='data/requests_train.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "requests_test = pd.read_csv(filepath_or_buffer='data/requests_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "individuals_train = pd.read_csv(filepath_or_buffer='data/individuals_train.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "individuals_test = pd.read_csv(filepath_or_buffer='data/individuals_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index col as request id\n",
    "requests_train.set_index('request_id', inplace=True)\n",
    "requests_test.set_index('request_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join datasets\n",
    "\n",
    "Since there are multiple requests by individuals and multiple individuals by request, the straightfoward approach would be to create columns for each individual' informations. This way, no information would be lost, but the curse of dimensionality is very near and the number of samples might be too low to extract useful information.\n",
    "\n",
    "The chosen approach is rather to only keep the request dataset' columns, and feature engineer additional columns based on the individuals data, eg.:\n",
    "- nb of past requests made by the same individual\n",
    "- nb nights granted in past requests of the same individual(s)/group\n",
    "- gender diversity of the group\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instanciate object analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate analysis object with request data\n",
    "analyze_train = Analysis(requests_train)\n",
    "analyze_test = Analysis(requests_test)\n",
    "\n",
    "# Define properties\n",
    "\n",
    "# - target\n",
    "target = 'granted_number_of_nights' \n",
    "analyze_test.target = target\n",
    "analyze_train.target = target\n",
    "# - shape\n",
    "analyze_train.m = analyze_train.df.shape[0]\n",
    "analyze_test.m = analyze_test.df.shape[0]\n",
    "analyze_train.n = analyze_train.df.shape[1]\n",
    "analyze_test.n = analyze_test.df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data\n",
    "\n",
    "Methodology:\n",
    "\n",
    "- Clean-up request dataset\n",
    "\n",
    "- Feature engineer using indiv dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaNs\n",
    "\n",
    "Methodology:\n",
    "- inspect NaNs on train set\n",
    "\n",
    "- if pattern detected, apply modifications on train and test sets\n",
    "\n",
    "Observations:\n",
    "- reverse engineering: the system seems to derive group_composition_id from group_composition_label, and both are then necessary linked/redondant => drop group_composition_label\n",
    "\n",
    "- there can be multiple individuals by request, and multiple requests by individual\n",
    "\n",
    "Further:\n",
    "- Impute 14 pregnancy NaNs from child_to_come (not useful for the current objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs train summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train: NaNs count by feature\n\n child_to_come                145947\nhousing_situation_label       16748\nlong_term_housing_request    165556\ntown                         159959\nvictim_of_violence_type      234175\ndtype: int64\n"
    }
   ],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get Na counts: by feature, by sample\n",
    "    na_ft_train, na_sp_train = analyze_train.get_na_counts()\n",
    "    na_ft_test, na_sp_test = analyze_test.get_na_counts()\n",
    "    if PRINT_ON:\n",
    "        print('Train: NaNs count by feature\\n\\n', na_ft_train[na_ft_train!=0])\n",
    "        #print('\\n\\nTest: NaNs count by feature\\n\\n', na_ft_test[na_ft_test!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_to_come NaNs\n",
    "\n",
    "Observation\n",
    "- There are 145947 NaNs for child_to_come on the train set (in request)\n",
    "\n",
    "- There are only 14 NaNs for pregnancy in train set (in individuals)\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: child_to_come is True if any indiv of the group is pregnant\n",
    "\n",
    "Conclusion\n",
    "- => Impute child_to_come from the pregnancy in the group of indiv of the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This takes Â±3min\n",
    "# Impute train set\n",
    "analyze_train.impute_child_to_come(df_indiv=individuals_train)\n",
    "# Impute test set\n",
    "analyze_test.impute_child_to_come(df_indiv=individuals_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Amend housing_situation_id\n",
    "\n",
    "The following code cells are organized as follows for clarity:\n",
    "- Imputation steps\n",
    "\n",
    "- Analysis\n",
    "\n",
    "Observations\n",
    "\n",
    "A. Meta numbers\n",
    "- Â±7% (16,748) NaNs for housing_situation_label (request)\n",
    "\n",
    "- 0 NaN for housing_situation_id (request)\n",
    "\n",
    "- 0 NaN for housing_situation_label_2 (individuals)\n",
    "\n",
    "- 0 NaN for housing_situation_id_2 (individuals)\n",
    "\n",
    "- 21 housing_situation_label (request)\n",
    "\n",
    "- 22 housing_situation_id (request)\n",
    "\n",
    "B. Specific ratios\n",
    "- Â±10% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "\n",
    "- Â±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "\n",
    "C. Analysis 1\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n",
    "\n",
    "D. Analysis 2\n",
    "- housing_situation_2_label can be very diverse when housing_situation_label is NaN (17 over 21 cat)\n",
    "\n",
    "- => housing_situation_label NaNs are not produced in a specific housing_situation_2_label situation\n",
    "\n",
    "E. Analysis 3\n",
    "- all individuals of a same request share the same housing_situation_2_label\n",
    "\n",
    "- => NaNs do not come from a problem of aggregating indiv data\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: the housing situation should logically have an impact on the result\n",
    "\n",
    "- Hyp: proba being on the street is significantly high to always impute NaN with 'street'\n",
    "\n",
    "- Hyp: housing_ids are not sorted in any specific order from which a logic could be derived. Thus, having numerical ids is dangereous and could lead to misinterpretations by the model.\n",
    "\n",
    "Conclusion\n",
    "- => Impute housing_situation_label NaNs as 'street'\n",
    "\n",
    "- => one-hot encode housing_situation_label\n",
    "\n",
    "- => Drop housing_situation_label\n",
    "\n",
    "- => Drop housing_situation_id\n",
    "\n",
    "Further improvements\n",
    "- derive more sub-groups: when a group is not housing_situation_label_2 'on the street', impute the request housing_situation_label with its most often matched value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute NaNs with the single value 'street'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_train.df.loc[analyze_train.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'\n",
    "analyze_test.df.loc[analyze_test.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the mapping of housing_situation_id - housing_situation_label\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "    housing_situation_id                      housing_situation_label\n0                     10                          emergency structure\n1                     20                      stabilisation structure\n2                     30                          inclusion structure\n3                     40                  hotel paid by the household\n4                     50           hotel paid by the emergency centre\n5                     60                               police station\n6                     70                                parental home\n7                     80                     personal or marital home\n8                     90                        detoxification center\n9                    100                                     shelters\n10                   110                  mobile or makeshift shelter\n11                   120                accomodation by a third party\n12                   130                              public hospital\n13                   140                         psychiatric hospital\n14                   150                                       prison\n15                   160                                        other\n16                   170                                          NaN\n17                   180                            refused to answer\n18                   190    hotel paid by the regional administration\n19                   200                                       street\n20                   210  religious place (church, mosque, synogogue)\n21                   220                 hotel paid by an association",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>housing_situation_id</th>\n      <th>housing_situation_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10</td>\n      <td>emergency structure</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>20</td>\n      <td>stabilisation structure</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30</td>\n      <td>inclusion structure</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>40</td>\n      <td>hotel paid by the household</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>hotel paid by the emergency centre</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>60</td>\n      <td>police station</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>70</td>\n      <td>parental home</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>80</td>\n      <td>personal or marital home</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>90</td>\n      <td>detoxification center</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>100</td>\n      <td>shelters</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>110</td>\n      <td>mobile or makeshift shelter</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>120</td>\n      <td>accomodation by a third party</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>130</td>\n      <td>public hospital</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>140</td>\n      <td>psychiatric hospital</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>150</td>\n      <td>prison</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>160</td>\n      <td>other</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>170</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>180</td>\n      <td>refused to answer</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>190</td>\n      <td>hotel paid by the regional administration</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>200</td>\n      <td>street</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>210</td>\n      <td>religious place (church, mosque, synogogue)</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>220</td>\n      <td>hotel paid by an association</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 308
    }
   ],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_id - housing_situation_label\n",
    "    map_housing_id_label = analyze_train.df.loc[:, ['housing_situation_id', 'housing_situation_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index for clarity\n",
    "    map_housing_id_label = map_housing_id_label.sort_values(by='housing_situation_id')\n",
    "    map_housing_id_label.reset_index(drop=True, inplace=True)\n",
    "    map_housing_id_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze relation between housing_situation_label (request) and housing_situation_2_label (indiv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a temporary dataframe with columns:\n",
    "\n",
    "| request_id | gr_nb_nights | hous_id | hous_lab | indiv_id | hous_2id | hous2_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # request [gr_nb_nights, hous_id, hous_lab]\n",
    "    rq = analyze_train.df.loc[:, ['granted_number_of_nights', 'housing_situation_id', 'housing_situation_label']]\n",
    "\n",
    "    # individuals [request_id, indiv_id, hous_2id, hous2_lab]\n",
    "    ind = individuals_train.loc[:, ['request_id', 'individual_id', 'housing_situation_2_id', 'housing_situation_2_label']]\n",
    "    ind.set_index('request_id', inplace=True)\n",
    "\n",
    "    # Merge request and individuals datasets\n",
    "    df_full = pd.merge(rq, ind, on='request_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "on the street                                   21185\nday center, social services, associations        1462\nother                                             282\nemergency accomodation                             82\naccomodated by friends or other                    75\npublic instition (hospital, retirement home)       67\nresidential roaming                                40\nhotel not paid by an emergency structure           28\nreception center for asylum seeker                 24\naccomodated by family                              18\nemergency centre for asylum seeker                 12\nwinter plan center                                 11\nmedical centre                                      8\nevicted from public housing rental                  6\nprivate housing rental                              3\nhotel paid by the emergency structure               2\npublic housing rental                               2\ninclusion accomodation                              2\nName: housing_situation_2_label, dtype: int64"
     },
     "metadata": {},
     "execution_count": 290
    }
   ],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Nb of indivs (an indiv is considered a new indiv at each request)\n",
    "    nb_indivs = df_full.shape[0]\n",
    "\n",
    "    # Â±6% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "    df_full[df_full['housing_situation_label'].isna()]\n",
    "\n",
    "    # Â±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "    df_temp = df_full[df_full[\"housing_situation_label\"].isna()]\n",
    "    df_temp['housing_situation_2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect individuals with housing_situation_2_label \"on the street\":\n",
    "\n",
    "- they can have a very diverse housing_situation (17 categories over a total of 21)\n",
    "\n",
    "- => no pattern to derive from this point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    q = df_full.query(\"housing_situation_label.isna() and housing_situation_2_label != 'on the street'\")\n",
    "\n",
    "    # Count number of categories for housing_situation_2_label\n",
    "    n_cat_2 = len(q.loc[:, 'housing_situation_2_label'].unique())\n",
    "\n",
    "    # Total categories for the feature\n",
    "    n_cat_1 = len(analyze_train.get_col_uniques('housing_situation_label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if housing_situation_label NA exist when indiv within a group have different housing_situation_2\n",
    "\n",
    "- no divergence\n",
    "\n",
    "- => when group, all indiv have the same housing_situation_2_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # takes Â±1min\n",
    "    if False:\n",
    "        # Get request_id along with its group size\n",
    "        rq_id = df_full.index.value_counts()\n",
    "        for i in range(70000):\n",
    "            # Get ith rq_id\n",
    "            rq_id_i = rq_id.index[0]\n",
    "\n",
    "            # Observe if housing_situation_label same for all the group members\n",
    "            n_uni_grp = len(df_full.loc[rq_id_i]['housing_situation_label'].unique())\n",
    "            n_uni_indiv = len(df_full.loc[rq_id_i]['housing_situation_2_label'].unique())\n",
    "\n",
    "            if n_uni_grp > 1 or n_uni_indiv > 1:\n",
    "                print(i)\n",
    "                print(n_uni_grp, n_uni_indiv)\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further improvements: derive the most probable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "           housing_situation_label                 housing_situation_2_label\n0    accomodation by a third party                    inclusion accomodation\n1    accomodation by a third party                               house share\n2    accomodation by a third party  hotel not paid by an emergency structure\n3    accomodation by a third party        reception center for asylum seeker\n4    accomodation by a third party                            medical centre\n..                             ...                                       ...\n319                         street                                 detention\n320                         street       evicted from private housing rental\n321                         street                            medical centre\n322                         street                     accomodated by family\n323                         street                             on the street\n\n[324 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>housing_situation_label</th>\n      <th>housing_situation_2_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>accomodation by a third party</td>\n      <td>inclusion accomodation</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>accomodation by a third party</td>\n      <td>house share</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>accomodation by a third party</td>\n      <td>hotel not paid by an emergency structure</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>accomodation by a third party</td>\n      <td>reception center for asylum seeker</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>accomodation by a third party</td>\n      <td>medical centre</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>319</th>\n      <td>street</td>\n      <td>detention</td>\n    </tr>\n    <tr>\n      <th>320</th>\n      <td>street</td>\n      <td>evicted from private housing rental</td>\n    </tr>\n    <tr>\n      <th>321</th>\n      <td>street</td>\n      <td>medical centre</td>\n    </tr>\n    <tr>\n      <th>322</th>\n      <td>street</td>\n      <td>accomodated by family</td>\n    </tr>\n    <tr>\n      <th>323</th>\n      <td>street</td>\n      <td>on the street</td>\n    </tr>\n  </tbody>\n</table>\n<p>324 rows Ã 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 305
    }
   ],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_label - housing_situation_2_label\n",
    "    df_full_no_na = df_full[~df_full.housing_situation_label.isna()]\n",
    "    map_housing_labels = df_full_no_na.loc[:, ['housing_situation_label', 'housing_situation_2_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index for clarity\n",
    "    map_housing_labels = map_housing_labels.sort_values(by='housing_situation_label')\n",
    "    map_housing_labels.reset_index(drop=True, inplace=True)\n",
    "    map_housing_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### victim_of_violence_type\n",
    "\n",
    "is NaN if victim_of_violence is 'f'\n",
    "\n",
    "=> Replace these NaNs by say 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern for missing pregnancy?\n",
    "- Search if missing is treated as pregnant through correlated variables\n",
    "\n",
    "- Pregnancy seems not to have a significative direct correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_train.df['gender'].groupby(analyze_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern with child_situation\n",
    "analyze_train.df[target].groupby(analyze_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests granted (nb_nights > 0)\n",
    "granted = analyze_train.df[target] > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### child_to_come\n",
    "\n",
    "flag indicating whether the group is expecting a baby\n",
    "\n",
    "\n",
    "What does it represent?\n",
    "\n",
    "- hyp: it is the corresponding value of the individual \"pregnancy\"\n",
    "\n",
    "Then?\n",
    "\n",
    "- now that dataframes are joined, it is redondant\n",
    "\n",
    "Conclusion\n",
    "\n",
    "- use it to impute pregnancy NAs\n",
    "\n",
    "- then drop the feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender\n",
    "\n",
    "- => Only females are possibly pregnant, thus 30 males have made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_train.df['gender'].groupby(analyze_train.df['pregnancy']).value_counts()\n",
    "# TODO: Retrieve the individual ids, and correct for male -> pregnancy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Analysis\n",
    "(df_train)\n",
    "\n",
    "General:\n",
    "- Number of requests: 238191\n",
    "\n",
    "- Number of individuals: 384133\n",
    "\n",
    "- Number of features: 39\n",
    "\n",
    "- Requests are made for 1.6 pers on average.\n",
    "\n",
    "\n",
    "Correlations with granted_number_of_nights\n",
    "- housing_situation_id: -0.458581. Strong negative impact. A high value must represent the good quality of the current housing situation.\n",
    "\n",
    "- housing_situation_2_id: 0.283840. Strong positive impact. A higher value must conversely represent a degraded quality.\n",
    "\n",
    "Principal components\n",
    "- housing_situation_2_label: with value \"emergency accomodation\". High probability to get 1 or two nights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyze_df_train = Analysis(df_train)\n",
    "#Analyze_df_train.describe(investigation_level=3)\n",
    "#Analyze.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'granted_number_of_nights'\n",
    "feature = 'animal_presence'\n",
    "mask = df_train[feature] == 't'\n",
    "df_train[mask][[feature, target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA, inf\n",
    "columns_selected = ['animal_presence']\n",
    "df_train[columns_selected].isnull().sum()\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis by features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### housing_situation_2_label\n",
    "- Â±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "\n",
    "- Â±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "\n",
    "- Â±75% (289,870) individuals are \"on the street\"\n",
    "\n",
    "- A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "df_full[df_full['housing_situation_label'] == 'street']\n",
    "\n",
    "# Â±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "df_full.query(\"housing_situation_label == 'street' and housing_situation_2_label == 'on the street'\")\n",
    "\n",
    "# Â±75% (289,870) individuals are \"on the street\"\n",
    "df_full['housing_situation_2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impact on target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of feature on target\n",
    "join_key = 'request_id'\n",
    "target = 'granted_number_of_nights'\n",
    "feature = 'housing_situation_2_label'\n",
    "mask = df_train[feature] == 'emergency accomodation'\n",
    "\n",
    "# Hist: drop duplicate requests (due to indiv data merged)\n",
    "df_train[mask][[join_key, target]].drop_duplicates().hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "- nb of indivs in the group\n",
    "\n",
    "- nb of past requests by indivs forming the group of the request\n",
    "\n",
    "- nb of past granted request by indivs forming //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nb of past requests by an individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of ALL requests of indiv with max n_requests\n",
    "ind_id = df_full['individual_id'].value_counts().index[0]\n",
    "\n",
    "# Watch request made by the same indiv\n",
    "df_full[df_full['individual_id'] == ind_id]\n",
    "\n",
    "# TODO: Past requests only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical features\n",
    "Prepare data to feed models\n",
    "\n",
    "- booleans: replace by (1, 0)\n",
    "\n",
    "- 2 < cats < 11: one-hot encoding\n",
    "\n",
    "- No transform on features with more than 11 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process columns:\n",
    "# booleans: 't', 't' => True, False\n",
    "# Categorical with few classes => one-hot encoding\n",
    "bools_train, failed_train = analyze_train.transform_categories(target=analyze_train.target)\n",
    "bools_test, failed_test = analyze_test.transform_categories(target=analyze_test.target)\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "analyze_train.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "analyze_test.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Export data\n",
    "analyze_train.export_data('data/data_train_preprocessed.csv')\n",
    "analyze_test.export_data('data/data_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random uniform train/test\n",
    "random_preds_train = np.random.uniform(size=(requests_train.shape[0], 4))\n",
    "random_preds_test = np.random.uniform(size=(requests_test.shape[0], 4))\n",
    "\n",
    "# Dumb (always pred 3)\n",
    "dumb_preds_train = np.zeros((requests_train.shape[0], 4))\n",
    "dumb_preds_test = np.zeros((requests_test.shape[0], 4))\n",
    "# Set 10% pred everywhere (if not, log penalyzes hardly)\n",
    "dumb_preds_train[:,:] = .01\n",
    "dumb_preds_test[:,:] = .01\n",
    "# Set 20% pred on class 3\n",
    "dumb_preds_train[:,2] = .02\n",
    "dumb_preds_test[:,2] = .02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed a significant (negative) correlation of housing_situation_id with granted_number_of_nights, let's train a univariate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model' parameters\n",
    "clf = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=2,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=None,\n",
    "    class_weight=None)\n",
    "\n",
    "# Build train/test datasets with housing_situation_id only\n",
    "X_train = np.array(requests_train['housing_situation_id']).reshape(-1, 1)\n",
    "X_test = np.array(requests_test['housing_situation_id'].values).reshape(-1, 1)\n",
    "Y_train = requests_train.granted_number_of_nights.values\n",
    "Y_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Transform categorical target into a one-hot vector\n",
    "Y_train_onehot = to_onehot(Y_train)\n",
    "Y_test_onehot = to_onehot(Y_test)\n",
    "\n",
    "# Train the model\n",
    "clf = clf.fit(X_train, Y_train_onehot)\n",
    "\n",
    "# Yield train/test predictions\n",
    "preds_train_tree_univar = clf.predict(X_train)\n",
    "preds_test_tree_univar = clf.predict(X_test)\n",
    "\n",
    "# Fill predictions to .2 elsewhere\n",
    "preds_train_tree_univar[preds_train_tree_univar == 0] = .2\n",
    "preds_test_tree_univar[preds_test_tree_univar == 0] = .2\n",
    "\n",
    "# Evaluate train/test\n",
    "score_train = competition_scorer(Y_train, preds_train_tree_univar)\n",
    "score_test = competition_scorer(Y_test, preds_test_tree_univar)\n",
    "\n",
    "# Display results\n",
    "print(f'train score: {score_train:.2f}')\n",
    "print(f'test score: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = clf.predict_proba(X_train)\n",
    "v0 = probas[0].max(1)\n",
    "v1 = probas[1].max(1)\n",
    "v2 = probas[2].max(1)\n",
    "v3 = probas[3].max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_test = competition_scorer(y_true_test, random_preds_test)\n",
    "dumb_score_test = competition_scorer(y_true_test, dumb_preds_test)\n",
    "\n",
    "# Display results\n",
    "print(f'test score random: {random_score_test:.2f}')\n",
    "print(f'test score dumb: {dumb_score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_train = requests_train.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_train = competition_scorer(y_true_train, random_preds_train)\n",
    "dumb_score_train = competition_scorer(y_true_train, dumb_preds_train)\n",
    "\n",
    "# Display results\n",
    "print(f'train score random: {random_score_train:.2f}')\n",
    "print(f'train score dumb: {dumb_score_train:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree\n",
    "fn = ['housing_situation_id']\n",
    "cn = ['0', '1', '2', '3']\n",
    "\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True)\n",
    "\n",
    "requests_train['housing_situation_id'].hist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}