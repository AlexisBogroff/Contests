{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "#### Goal: Enhance emergency housing allocation.\n",
    "\n",
    "\n",
    "#### Caracteristics of the model:\n",
    "Accuracy:\n",
    "- if used as a clearing tool removing overburden upfront, and thus only to get rid of obvious cases, the accuracy of such a tool could be its most important caracteristic.\n",
    "\n",
    "Interpretability:\n",
    "- could help families understand the decision (although not as important as in diseases predictions).\n",
    "- can also highlight and thus control biases (racial, sex, age).\n",
    "- since the tool would probably be used in combination with human selection, it could help save time by highlighting the main factors for each decision\n",
    "\n",
    "#### Conclusion:\n",
    "- a model easily interpretable could be prefered (tree).\n",
    "- or a highly accurate model (less interpretable) could also be used upfront (NN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes, Functions & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import tree\n",
    "\n",
    "#os.chdir('/Users/Pro/Desktop/Git_Contests/Predictions/Emergency_housing/')\n",
    "from cobratools import Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the test scorer\n",
    "def competition_scorer(y_true, y_pred):\n",
    "    return log_loss(y_true, y_pred, sample_weight=10**y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General constants\n",
    "USE_PRE_PROCESSED_DATA = False\n",
    "PRINT_ON = False\n",
    "PLOT_ON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRE_PROCESSED_DATA:\n",
    "\n",
    "    requests_train = pd.read_csv(filepath_or_buffer='data/requests_train.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "    requests_test = pd.read_csv(filepath_or_buffer='data/requests_test.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "    individuals_train = pd.read_csv(filepath_or_buffer='data/individuals_train.csv',\n",
    "                                    sep=',',\n",
    "                                    low_memory=False,\n",
    "                                    error_bad_lines=False)\n",
    "\n",
    "    individuals_test = pd.read_csv(filepath_or_buffer='data/individuals_test.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "else:\n",
    "    df_train = pd.read_csv(filepath_or_buffer='data/data_train_preprocessed.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRE_PROCESSED_DATA:\n",
    "    df_train = pd.merge(requests_train, individuals_train, on='request_id', how='outer')\n",
    "    df_test = pd.merge(requests_test, individuals_test, on='request_id', how='outer')\n",
    "    del requests_train, requests_test\n",
    "    del individuals_train, individuals_test\n",
    "\n",
    "    # Set index col as individual id\n",
    "    df_train.set_index('individual_id', inplace=True)\n",
    "    df_test.set_index('individual_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data\n",
    "(while analyzing only train data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciate analysis object\n",
    "analyze_train = Analysis(df_train)\n",
    "analyze_test = Analysis(df_test)\n",
    "del df_train\n",
    "del df_test\n",
    "\n",
    "# Define properties\n",
    "target = 'granted_number_of_nights' \n",
    "analyze_test.target = target\n",
    "analyze_train.target = target\n",
    "n_samples = analyze_train.df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical features\n",
    "- booleans: replace by (1, 0)\n",
    "- 2 < cats < 11: one-hot encoding\n",
    "- No transform on features with more than 11 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Transform Boolean at col animal_presence: True/False=['f' 't']\nTransform Boolean at col child_to_come: True/False=['f' 't']\n\nERROR - Transform Boolean at col group_type not recognized: ['individual' 'group']\n\nTransform Boolean at col long_term_housing_request: True/False=['t' 'f']\nTransform Boolean at col victim_of_violence: True/False=['f' 't']\nTransform Boolean at col childcare_center_supervision: True/False=['t' 'f']\nTransform Boolean at col disabled_worker_certification: True/False=['f' 't']\nTransform Boolean at col gender: True/False=['male' 'female']\nTransform Boolean at col pregnancy: True/False=['f' 't']\nTransform Boolean at col animal_presence: True/False=['f' 't']\nTransform Boolean at col child_to_come: True/False=['f' 't']\n\nERROR - Transform Boolean at col group_type not recognized: ['group' 'individual']\n\nTransform Boolean at col long_term_housing_request: True/False=['f' 't']\nTransform Boolean at col victim_of_violence: True/False=['f' 't']\nTransform Boolean at col childcare_center_supervision: True/False=['f' 't']\nTransform Boolean at col disabled_worker_certification: True/False=['f' 't']\nTransform Boolean at col gender: True/False=['male' 'female']\nTransform Boolean at col pregnancy: True/False=['f' 't']\n"
    }
   ],
   "source": [
    "if not USE_PRE_PROCESSED_DATA:\n",
    "    # Pre-process columns:\n",
    "    # booleans: 't', 't' => True, False\n",
    "    # Categorical with few classes => one-hot encoding\n",
    "    mapping_true_false_train, failed_train = analyze_train.transform_categories()\n",
    "    mapping_true_false_test, failed_test = analyze_test.transform_categories()\n",
    "\n",
    "    # Preprocess specific cat columns\n",
    "    analyze_train.convert_to_bool(col='group_type',\n",
    "                                true_val='group',\n",
    "                                false_val='individual')\n",
    "\n",
    "    # Export data\n",
    "    #analyze_train.export_data('data/data_train_preprocessed.csv')\n",
    "    #analyze_test.export_data('data/data_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaNs: for categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Na counts: by feature, by sample\n",
    "na_ft, na_sp = analyze_train.get_na_counts()\n",
    "if PRINT_ON:\n",
    "    print('NaNs count by feature\\n\\n', na_ft[na_ft!=0])\n",
    "\n",
    "# Analyze Na distribution by sample\n",
    "# ie. when a sample has NaNs, it has 5 NaNs most frequently\n",
    "if PLOT_ON:\n",
    "    na_sp.hist()\n",
    "    _ = plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender NaNs\n",
    "\n",
    "#### Why missing?\n",
    "- hyp1: only 1 entry concerned, thus, it might have been on purpose\n",
    "- hyp2: person not recognizing itself in one of these 2 genders\n",
    "\n",
    "#### Then?\n",
    "- Only 1 nan in the entire df_train, too few to spend time\n",
    "thinking clever imputation\n",
    "\n",
    "#### Conclusion\n",
    "=> Replace by whichever gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not USE_PRE_PROCESSED_DATA:\n",
    "    # Get samples with Gender Nan\n",
    "    gender_na = analyze_train.df[analyze_train.df['gender'].isna()]\n",
    "\n",
    "    # > Replace by whichever gender, say 0\n",
    "    analyze_train.df.loc[gender_na.index[0], 'gender'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pregnancy NaNs\n",
    "\n",
    "#### Why missing?\n",
    "- hyp1: only 14 entries concerned, thus, it might have been mostly on purpose\n",
    "- hyp2: woman has doubts but hasn't verified\n",
    "\n",
    "#### Then?\n",
    "- if hyp2 mostly true, the request could have been treated as if pregnant\n",
    "\n",
    "#### Conclusion\n",
    "=> if true, replace by pregnant: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore impact on target\n",
    "\n",
    "Results: there seems not to have a significative direct correlation with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of target counts:\n",
    "# ± half individuals granted >=1 night(s)\n",
    "# which means < 50% of requests\n",
    "# Rq: still nicely balanced dataset\n",
    "target_counts = analyze_train.df[target].value_counts()\n",
    "\n",
    "if PRINT_ON:\n",
    "    print('Absolute\\n', target_counts)\n",
    "    print('\\n\\nPercentage\\n', target_counts / n_samples * 100)\n",
    "\n",
    "# Filter pregnants\n",
    "mask_pregnant = analyze_train.df['pregnancy'] == True\n",
    "\n",
    "# Count pregnants: 11k+ pregnant\n",
    "n_pregnants = sum(mask_pregnant)\n",
    "\n",
    "# Percentage ± 3%\n",
    "pct_pregnants = n_pregnants/ n_samples * 100\n",
    "\n",
    "\n",
    "# Correlation target & pregnancy: ± -.1% (significant? not)\n",
    "analyze_train.df[[target, 'pregnancy']].corr()\n",
    "\n",
    "# Summary\n",
    "target_pregnancy_counts = analyze_train.df[target].groupby(analyze_train.df['pregnancy']).value_counts()\n",
    "\n",
    "if PRINT_ON:\n",
    "    # Pct pregnants by target\n",
    "    print('\\n\\nN of nights granted for pregnants', target_pregnancy_counts[1] / n_pregnants)\n",
    "    # Pct not pregnants by target\n",
    "    print('\\nN of nights granted for not pregnants', target_pregnancy_counts[0] / (n_samples - n_pregnants))\n",
    "\n",
    "# => Repartitions are similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pattern for missing pregnancy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pregnancy  gender\n0.0        male      233108\n           female    139821\n           0              1\n1.0        female     11159\n           male          30\nName: gender, dtype: int64"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "analyze_train.df['gender'].groupby(analyze_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern with child_situation\n",
    "analyze_train.df[target].groupby(analyze_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requests granted (nb_nights > 0)\n",
    "granted = analyze_train.df[target] > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gender\n",
    "\n",
    "Only females are possibly pregnant, thus 30 males have made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "pregnancy  gender\n0.0        male      233108\n           female    139821\n           0              1\n1.0        female     11159\n           male          30\nName: gender, dtype: int64"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "analyze_train.df['gender'].groupby(analyze_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the individual ids, and correct for male -> pregnancy = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis (df_train)\n",
    "### General:\n",
    "- Number of requests: 238191\n",
    "- Number of individuals: 384133\n",
    "- Number of features: 39\n",
    "\n",
    "Requests are made for 1.6 pers on average.\n",
    "\n",
    "\n",
    "### Correlations with granted_number_of_nights\n",
    "- housing_situation_id: -0.458581. Strong negative impact. A high value must represent the good quality of the current housing situation.\n",
    "- housing_situation_2_id: 0.283840. Strong positive impact. A higher value must conversely represent a degraded quality.\n",
    "\n",
    "### Principal components\n",
    "- housing_situation_2_label: with value \"emergency accomodation\". High probability to get 1 or two nights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyze_df_train = Analysis(df_train)\n",
    "#Analyze_df_train.describe(investigation_level=3)\n",
    "#Analyze.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'granted_number_of_nights'\n",
    "feature = 'animal_presence'\n",
    "mask = df_train[feature] == 't'\n",
    "df_train[mask][[feature, target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA, inf\n",
    "columns_selected = ['animal_presence']\n",
    "df_train[columns_selected].isnull().sum()\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature: housing_situation_2_label\n",
    "- A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of feature on target\n",
    "join_key = 'request_id'\n",
    "target = 'granted_number_of_nights'\n",
    "feature = 'housing_situation_2_label'\n",
    "mask = df_train[feature] == 'emergency accomodation'\n",
    "\n",
    "# Hist: drop duplicate requests (due to indiv data merged)\n",
    "df_train[mask][[join_key, target]].drop_duplicates().hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random uniform train/test\n",
    "random_preds_train = np.random.uniform(size=(requests_train.shape[0], 4))\n",
    "random_preds_test = np.random.uniform(size=(requests_test.shape[0], 4))\n",
    "\n",
    "# Dumb (always pred 3)\n",
    "dumb_preds_train = np.zeros((requests_train.shape[0], 4))\n",
    "dumb_preds_test = np.zeros((requests_test.shape[0], 4))\n",
    "# Set 10% pred everywhere (if not, log penalyzes hardly)\n",
    "dumb_preds_train[:,:] = .01\n",
    "dumb_preds_test[:,:] = .01\n",
    "# Set 20% pred on class 3\n",
    "dumb_preds_train[:,2] = .02\n",
    "dumb_preds_test[:,2] = .02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed a significant (negative) correlation of housing_situation_id with granted_number_of_nights, let's train a univariate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model' parameters\n",
    "clf = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=2,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=None,\n",
    "    class_weight=None)\n",
    "\n",
    "# Build train/test datasets with housing_situation_id only\n",
    "X_train = np.array(requests_train['housing_situation_id']).reshape(-1, 1)\n",
    "X_test = np.array(requests_test['housing_situation_id'].values).reshape(-1, 1)\n",
    "Y_train = requests_train.granted_number_of_nights.values\n",
    "Y_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Transform categorical target into a one-hot vector\n",
    "Y_train_onehot = to_onehot(Y_train)\n",
    "Y_test_onehot = to_onehot(Y_test)\n",
    "\n",
    "# Train the model\n",
    "clf = clf.fit(X_train, Y_train_onehot)\n",
    "\n",
    "# Yield train/test predictions\n",
    "preds_train_tree_univar = clf.predict(X_train)\n",
    "preds_test_tree_univar = clf.predict(X_test)\n",
    "\n",
    "# Fill predictions to .2 elsewhere\n",
    "preds_train_tree_univar[preds_train_tree_univar == 0] = .2\n",
    "preds_test_tree_univar[preds_test_tree_univar == 0] = .2\n",
    "\n",
    "# Evaluate train/test\n",
    "score_train = competition_scorer(Y_train, preds_train_tree_univar)\n",
    "score_test = competition_scorer(Y_test, preds_test_tree_univar)\n",
    "\n",
    "# Display results\n",
    "print(f'train score: {score_train:.2f}')\n",
    "print(f'test score: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = clf.predict_proba(X_train)\n",
    "v0 = probas[0].max(1)\n",
    "v1 = probas[1].max(1)\n",
    "v2 = probas[2].max(1)\n",
    "v3 = probas[3].max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_test = competition_scorer(y_true_test, random_preds_test)\n",
    "dumb_score_test = competition_scorer(y_true_test, dumb_preds_test)\n",
    "\n",
    "# Display results\n",
    "print(f'test score random: {random_score_test:.2f}')\n",
    "print(f'test score dumb: {dumb_score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_train = requests_train.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_train = competition_scorer(y_true_train, random_preds_train)\n",
    "dumb_score_train = competition_scorer(y_true_train, dumb_preds_train)\n",
    "\n",
    "# Display results\n",
    "print(f'train score random: {random_score_train:.2f}')\n",
    "print(f'train score dumb: {dumb_score_train:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree\n",
    "fn = ['housing_situation_id']\n",
    "cn = ['0', '1', '2', '3']\n",
    "\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True)\n",
    "\n",
    "requests_train['housing_situation_id'].hist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}