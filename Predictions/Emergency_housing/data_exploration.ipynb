{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "#### Goal: Predict the number of nights granted to a request (not to an individual)\n",
    "\n",
    "\n",
    "#### Caracteristics of the model:\n",
    "Accuracy:\n",
    "- if used as a clearing tool removing overburden upfront, and thus only to get rid of obvious cases, the accuracy of such a tool could be its most important caracteristic.\n",
    "\n",
    "Interpretability:\n",
    "- could help families understand the decision (although not as important as in diseases predictions).\n",
    "- can also highlight and thus control biases (racial, sex, age).\n",
    "- since the tool would probably be used in combination with human selection, it could help save time by highlighting the main factors for each decision\n",
    "\n",
    "#### Conclusion:\n",
    "- a model easily interpretable could be prefered (tree).\n",
    "- or a highly accurate model (less interpretable) could also be used upfront (NN).\n",
    "\n",
    "\n",
    "#### Future improvements\n",
    "\n",
    "Imputations:\n",
    "- Build more robust, generalisable imputations (eg. impute future test samples with missing gender based on all easily interpretable categories group_composition_label and group_composition_id)\n",
    "\n",
    "- Automate NaNs imputation for future test samples\n",
    "\n",
    "- Reconstruct some NaNs by training models to predict the feature\n",
    "\n",
    "\n",
    "Datasets handling\n",
    "- I made the choice to keep the train and test sets split. This is to prevent gaining insight from the test set while doing pre-processing, analysis and while training the model. To prevent duplicate code, I thus placed most of the inner workings in the class Analysis, which makes the reading less fluent. To improve, see how to better combine the visual aspect of Jupyter Notebooks, while maintaining code standards like DRY philosophy.\n",
    "\n",
    "\n",
    "Pre-processing\n",
    "- impact historical data with the known global crises (financial crisis, immigration waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "I. Initialization\n",
    "\n",
    "1. Import packages, classes, functions\n",
    "\n",
    "2. Global settings\n",
    "\n",
    "2. Load databases\n",
    "\n",
    "3. Instantiate object Analysis\n",
    "\n",
    "\n",
    "II. Analysis\n",
    "\n",
    "1. Overview\n",
    "\n",
    "2. Analysis by features\n",
    "\n",
    "\n",
    "III. Pre-process data\n",
    "\n",
    "1. Impute NaNs\n",
    "\n",
    "2. Remove outliers\n",
    "\n",
    "3. Feature engineer\n",
    "\n",
    "4. Transform categorical features\n",
    "\n",
    "\n",
    "V. Analysis on clean data\n",
    "\n",
    "1. Observe correlations\n",
    "\n",
    "\n",
    "VI. Predict\n",
    "\n",
    "1. Prepare data, tools, model\n",
    "\n",
    "2. Train model\n",
    "\n",
    "3. Test model\n",
    "\n",
    "4. Benchmarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "# Utils\n",
    "import cobratools as cobra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to True to visualize\n",
    "PRINT_ON = True\n",
    "PLOT_ON = True\n",
    "\n",
    "# Project specificities\n",
    "TARGET = 'granted_number_of_nights'\n",
    "N_TARGET_CLASS = 4\n",
    "\n",
    "# Data format\n",
    "PRECISION = 3\n",
    "\n",
    "# False for the competition,\n",
    "# True if predicting new data > year 2020\n",
    "FUTURE_PRED = False  #d:False\n",
    "\n",
    "# Debug\n",
    "RELOAD = False  #d:False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define which cells are run\n",
    "Set the mode to define which cells to run until it reaches the 'Predict' section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values: (default: analyze_and_preprocess)\n",
    "# analyze_only, model_only, \n",
    "# preprocess_only, None (manual)\n",
    "MODE = 'preprocess_only'\n",
    "\n",
    "# MODE notice:\n",
    "#\n",
    "# Just set the mode with one of the values defined below:\n",
    "# - 'analyze_only': this will only run analyze cells\n",
    "#\n",
    "# - 'preprocess_only': this will not analyze but run any other cell\n",
    "#    expect it won't load preprocessed data nor export data\n",
    "#\n",
    "# - 'analyze_and_preprocess': this will run practically all cells\n",
    "#    expect it won't load preprocessed data nor export data\n",
    "#\n",
    "# - 'model_only': this will load preprocessed data\n",
    "#\n",
    "# - 'manual': allow to set manually all constants\n",
    "\n",
    "# Default values (MODE = None)\n",
    "# ------------------------------------------------\n",
    "ANALYZE = False\n",
    "\n",
    "PREPROCESS_DATA = False  # Â±4min (on my laptop/seconds on collab)\n",
    "\n",
    "LOAD_PREPROCESSED_DATA = False\n",
    "\n",
    "EXPORT_DATA = False\n",
    "\n",
    "\n",
    "# Automatic parameters' selection\n",
    "# ------------------------------------------------\n",
    "if MODE is 'analyze_only':\n",
    "    # this will only run analyze cells\n",
    "    ANALYZE = True\n",
    "\n",
    "elif MODE is 'preprocess_only':\n",
    "    # this will not analyze but run any other cell\n",
    "    # expect it won't load preprocessed data\n",
    "    # nor export data\n",
    "    PREPROCESS_DATA = True\n",
    "\n",
    "elif MODE is 'model_only':\n",
    "    # this will load preprocessed data\n",
    "    # Reader should then go to PREDICT section\n",
    "    LOAD_PREPROCESSED_DATA = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug reload\n",
    "Without the need to re-perform data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELOAD:\n",
    "    # Backup data\n",
    "    backup_train = obj_train.df.copy()\n",
    "    backup_test = obj_test.df.copy()\n",
    "    \n",
    "    # Reload updated class and functions\n",
    "    importlib.reload(cobra)\n",
    "\n",
    "    # Re-instanciate obj_train and obj_test\n",
    "    obj_train = cobra.Analysis(backup_train)\n",
    "    obj_test = cobra.Analysis(backup_test)\n",
    "    \n",
    "    # Re-set target variable\n",
    "    obj_train.target = TARGET\n",
    "    obj_test.target = TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_PREPROCESSED_DATA:\n",
    "    requests_train = pd.read_csv(filepath_or_buffer='data/requests_train.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "    requests_test = pd.read_csv(filepath_or_buffer='data/requests_test.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "    individuals_train = pd.read_csv(filepath_or_buffer='data/individuals_train.csv',\n",
    "                                    sep=',',\n",
    "                                    low_memory=False,\n",
    "                                    error_bad_lines=False)\n",
    "\n",
    "    individuals_test = pd.read_csv(filepath_or_buffer='data/individuals_test.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join datasets\n",
    "\n",
    "Since there are multiple requests by individuals and multiple individuals by request, the straightfoward approach would be to create columns for each individual' informations. This way, no information would be lost, but the curse of dimensionality is very near and the number of samples might be too low to extract useful information.\n",
    "\n",
    "The chosen approach is rather to only keep the request dataset' columns, and feature engineer additional columns based on the individuals data, eg.:\n",
    "- nb of past requests made by the same individual\n",
    "- nb nights granted in past requests of the same individual(s)/group\n",
    "- gender diversity of the group\n",
    "- etc.\n",
    "\n",
    "However, for analytics purpose, a dataframe with all the data is also created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_PREPROCESSED_DATA:\n",
    "    # Merge request and individuals datasets, for analytics purpose only\n",
    "    df_full_train = pd.merge(requests_train, individuals_train, on='request_id')\n",
    "    df_full_test = pd.merge(requests_test, individuals_test, on='request_id')\n",
    "\n",
    "    # Set index col as request id\n",
    "    # (not for individuals data set, since there is no pkey currently)\n",
    "    # (hence not for obj_full_train either)\n",
    "    requests_train.set_index('request_id', inplace=True)\n",
    "    requests_test.set_index('request_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate object analysis\n",
    "\n",
    "obj_train and obj_test will be the main dataframes, used for training and testing the model\n",
    "\n",
    "They are primilary built with the request data sets, then features engineered from individuals' data sets are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not LOAD_PREPROCESSED_DATA:\n",
    "    # Instantiate analysis object with request data\n",
    "    obj_train = cobra.Analysis(requests_train)\n",
    "    obj_test = cobra.Analysis(requests_test)\n",
    "    obj_full_train = cobra.Analysis(df_full_train)\n",
    "    obj_full_test = cobra.Analysis(df_full_test)\n",
    "\n",
    "    # Define properties\n",
    "\n",
    "    # - set target (no copy)\n",
    "    obj_train.target = TARGET\n",
    "    obj_test.target = TARGET\n",
    "    obj_full_train.target = TARGET\n",
    "    obj_full_test.target = TARGET\n",
    "\n",
    "    # - set shape\n",
    "    obj_train.m = obj_train.df.shape[0]\n",
    "    obj_test.m = obj_test.df.shape[0]\n",
    "    obj_train.n = obj_train.df.shape[1]\n",
    "    obj_test.n = obj_test.df.shape[1]\n",
    "    obj_full_train.m = obj_full_train.df.shape[0]\n",
    "    obj_full_train.n = obj_full_train.df.shape[1]\n",
    "    obj_full_test.m = obj_full_test.df.shape[0]\n",
    "    obj_full_test.n = obj_full_test.df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "- Number of requests: 238191\n",
    "\n",
    "- Number of individuals: 384133\n",
    "\n",
    "- Number of features: 39\n",
    "\n",
    "- Requests are made for 1.6 pers on average.\n",
    "\n",
    "\n",
    "Principal components\n",
    "- housing_situation_label: with value \"emergency accomodation\". High probability to get 1 or two nights. Logical since the service treats emergency housing\n",
    "- housing_situation_2_label: with value \"emergency accomodation\". High probability to get 1 or two nights.\n",
    "\n",
    "--------------------\n",
    "\n",
    "\n",
    "Analysis by features\n",
    "\n",
    "\n",
    "A. housing_situation_id\n",
    "- correlation target-housing_situation_id: -0.458581. Strong negative impact. Although the linear numerical relation of the housing_situation_id categories is in my opinion flawed, the strong correlation is explainable as the category with the smallest value \"emergency accomodation\" might be correlated with higher granted_number_of_nights than the rest of the categories, which happen to have higher housing_situation_id values.\n",
    "\n",
    "- housing_situation_2_id: 0.283840. Strong positive impact. Same explanation as housing_situation_id.\n",
    "\n",
    "B. pregnancy\n",
    "- Pregnancy seems not to have a significant direct correlation with target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    obj_train.describe(investigation_level=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### housing_situation_2_label\n",
    "\n",
    "- Â±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "\n",
    "- Â±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "\n",
    "- Â±75% (289,870) individuals are \"on the street\"\n",
    "\n",
    "- A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # Â±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "    obj_full_train.df[obj_full_train.df['housing_situation_label'] == 'street']\n",
    "\n",
    "    # Â±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "    obj_full_train.df.query(\"housing_situation_label == 'street' and housing_situation_2_label == 'on the street'\")\n",
    "\n",
    "    # Â±75% (289,870) individuals are \"on the street\"\n",
    "    print(obj_full_train.df['housing_situation_2_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # Obs: A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights.\n",
    "\n",
    "    # Impact of feature on target\n",
    "    feature = 'housing_situation_2_label'\n",
    "    mask = obj_full_train.df[feature] == 'emergency accomodation'\n",
    "\n",
    "    # Hist: drop duplicate requests (due to multiple indivs by request)\n",
    "    obj_full_train.df[mask][['request_id', TARGET]].drop_duplicates().hist()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### child_situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    feature = 'child_situation'\n",
    "\n",
    "    # Display unique values\n",
    "    uniques = obj_train.get_col_uniques(feature)\n",
    "    uniques.sort()\n",
    "    print(\"child_situation possible values:\", *uniques)\n",
    "\n",
    "    # Display distribution\n",
    "    # Obs: Almost any request has child_situation == -1\n",
    "    # hyp: -1 means NaN\n",
    "    dist = obj_train.df[feature].value_counts()\n",
    "    \n",
    "    # Count all non NaNs values\n",
    "    dist_positive = sum(dist[dist.index != -1])\n",
    "    ratio_non_na = dist_positive / obj_train.m\n",
    "    \n",
    "    # Print distribution\n",
    "    print(\"\\nDistribution\\n\", dist)\n",
    "    \n",
    "    # Plot histogram\n",
    "    print(f\"\\n\\nChild_situation non NaN ratio: {round(ratio_non_na * 100, 2)}%\\n\\n\")\n",
    "\n",
    "    # Correlation with target (for non NaNs)\n",
    "    # The proportion of non NaNs is increasing with target values\n",
    "    # The probability of granting more nights is greater when non NaN\n",
    "    dist_grpby = obj_train.df[TARGET].groupby(obj_train.df[feature])\n",
    "    if PLOT_ON:\n",
    "        dist_grpby.hist()\n",
    "        plt.show()\n",
    "\n",
    "    # Study only positive 'child_situation' samples\n",
    "    # TODO: produce a study\n",
    "    mask_pos = obj_train.df['child_situation'] != -1\n",
    "    dist_grpby_pos = obj_train.df[mask_pos][TARGET].groupby(obj_train.df[feature])\n",
    "    if PLOT_ON:\n",
    "        dist_grpby_pos.hist()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### victime_of_violence_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    feature = 'victim_of_violence_type'\n",
    "    feature_base = 'victim_of_violence'\n",
    "\n",
    "    # Inspect a specific group with violence type \"child\"\n",
    "    # ---------------------------------------------------\n",
    "    # TODO: go further this anecdotical impression\n",
    "    # Obs: \n",
    "    # - violence child can counter intuitively be applied on individuals without child, but awaiting a child.\n",
    "    # - requests seem more likely granted when multiple (non granted) requests have been made in the past\n",
    "    # - requests seem less likely granted when a recent request was granted\n",
    "    # => feature engineer measures to represent these observations\n",
    "\n",
    "    # Mask to filter on child violence only\n",
    "    mask_child_violence = obj_train.df[feature] == 'child'\n",
    "\n",
    "    # Mast to filter group1 entries only\n",
    "    mask_group1 = obj_train.df[mask_child_violence]['group_id'] == '8d79d2cd16e886a947158b5f6e2eff43'\n",
    "\n",
    "    # Sort entries by request_creation_date\n",
    "    grp1_sorted_rq_date = obj_train.df[mask_child_violence][mask_group1].sort_values(by='request_creation_date')\n",
    "\n",
    "    # Get dates and housing values along with target\n",
    "    grp1_sorted_rq_date[[TARGET, 'request_creation_date', 'answer_creation_date', 'housing_situation_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### animal_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    feature = 'animal_presence'\n",
    "    mask = obj_train.df[feature] == 't'\n",
    "    obj_train.df[mask][[feature, TARGET]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requester_type along with group_main_requester_id\n",
    "if it is an urgentist, used to bring individuals to the service, its groups might have higher granted rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### request_backoffice_creator_id\n",
    "this might impact since each people has its own biases (as for the predictions of court decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data\n",
    "\n",
    "Methodology:\n",
    "\n",
    "- Clean-up obj_train.df (initially request dataset)\n",
    "\n",
    "- Feature engineer (using indiv dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaNs\n",
    "\n",
    "Methodology:\n",
    "- inspect NaNs on train set\n",
    "\n",
    "- if pattern detected, apply modifications on train and test sets\n",
    "\n",
    "Observations:\n",
    "- reverse engineering: the system seems to derive group_composition_id from group_composition_label, and both are then necessary linked/redondant => drop group_composition_label\n",
    "\n",
    "Further:\n",
    "- Impute 14 pregnancy NaNs from child_to_come (not useful for the current objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs train summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # Get Na counts: by feature, by sample\n",
    "    na_ft_train, na_sp_train = obj_train.get_na_counts()\n",
    "    na_ft_test, na_sp_test = obj_test.get_na_counts()\n",
    "    \n",
    "    if PRINT_ON:\n",
    "        print('Train: NaNs count by feature\\n\\n', na_ft_train[na_ft_train!=0])\n",
    "        #print('\\n\\nTest: NaNs count by feature\\n\\n', na_ft_test[na_ft_test!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_to_come NaNs\n",
    "\n",
    "Observation\n",
    "- There are 145947 NaNs for child_to_come on the train set (in request)\n",
    "\n",
    "- There are only 14 NaNs for pregnancy in train set (in individuals)\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: child_to_come is True if any indiv of the group is pregnant\n",
    "\n",
    "Conclusion\n",
    "- => Impute child_to_come from the pregnancy in the group of indiv of the request\n",
    "\n",
    "Control\n",
    "- Verify that the imputation is not only setting to 'f':\n",
    "- -> successful: from the 145947 requests, 5375 are set to 't'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # Capture the indexes where NaNs\n",
    "    df_train_raw_nas = obj_train.df[obj_train.df['child_to_come'].isna()]\n",
    "    idx_nas = df_train_raw_nas['child_to_come'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    # TODO: refactor (this takes Â±3min on light laptop, seconds on collab)\n",
    "    # Impute train set\n",
    "    obj_train.impute_child_to_come(df_indiv=individuals_train)\n",
    "    # Impute test set\n",
    "    obj_test.impute_child_to_come(df_indiv=individuals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # Get number of NaNs imputed as False and True\n",
    "    obj_train.df.loc[idx_nas]['child_to_come'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute housing_situation_label\n",
    "\n",
    "The following code cells are organized as follows for clarity:\n",
    "- Imputation steps\n",
    "\n",
    "- Analysis\n",
    "\n",
    "Observations\n",
    "\n",
    "A. Meta numbers\n",
    "- Â±7% (16,748) NaNs for housing_situation_label (request)\n",
    "\n",
    "- 0 NaN for housing_situation_id (request)\n",
    "\n",
    "- 0 NaN for housing_situation_label_2 (individuals)\n",
    "\n",
    "- 0 NaN for housing_situation_id_2 (individuals)\n",
    "\n",
    "- 21 housing_situation_label (request)\n",
    "\n",
    "- 22 housing_situation_id (request)\n",
    "\n",
    "B. Specific ratios\n",
    "- Â±10% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "\n",
    "- Â±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "\n",
    "C. Analysis 1\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n",
    "\n",
    "D. Analysis 2\n",
    "- housing_situation_2_label can be very diverse when housing_situation_label is NaN (17 over 21 cat)\n",
    "\n",
    "- => housing_situation_label NaNs are not produced in a specific housing_situation_2_label situation\n",
    "\n",
    "E. Analysis 3\n",
    "- all individuals of a same request share the same housing_situation_2_label\n",
    "\n",
    "- => NaNs do not come from a problem of aggregating indiv data\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: the housing situation should logically have an impact on the result\n",
    "\n",
    "- Hyp: proba being on the street is significantly high to always impute NaN with 'street'\n",
    "\n",
    "- Hyp: housing_ids are not sorted in any specific order from which a logic could be derived. Thus, having numerical ids is dangereous and could lead to misinterpretations by the model.\n",
    "\n",
    "Conclusion\n",
    "- => Impute housing_situation_label NaNs as 'street'\n",
    "\n",
    "- => Drop housing_situation_id\n",
    "\n",
    "- => one-hot encode housing_situation_label\n",
    "\n",
    "\n",
    "Further improvements\n",
    "- derive more sub-groups: when a group is not housing_situation_label_2 'on the street', impute the request housing_situation_label with its most often matched value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the mapping of housing_situation_id - housing_situation_label\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE: \n",
    "    # Get mapping housing_situation_id - housing_situation_label\n",
    "    map_housing_id_label = obj_train.df.loc[:, ['housing_situation_id', 'housing_situation_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index for clarity\n",
    "    map_housing_id_label = map_housing_id_label.sort_values(by='housing_situation_id')\n",
    "    map_housing_id_label.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze relation between housing_situation_label (request) and housing_situation_2_label (indiv)\n",
    "\n",
    "Make a temporary dataframe with columns:\n",
    "\n",
    "| request_id | gr_nb_nights | hous_id | hous_lab | indiv_id | hous_2id | hous2_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # request [gr_nb_nights, hous_id, hous_lab]\n",
    "    rq = obj_train.df.loc[:, ['granted_number_of_nights',\n",
    "                                'housing_situation_id',\n",
    "                                'housing_situation_label']]\n",
    "\n",
    "    # individuals [request_id, indiv_id, hous_2id, hous2_lab]\n",
    "    ind = individuals_train.loc[:, ['request_id',\n",
    "                                    'individual_id',\n",
    "                                    'housing_situation_2_id',\n",
    "                                    'housing_situation_2_label']]\n",
    "    ind.set_index('request_id', inplace=True)\n",
    "\n",
    "    # Merge request and individuals datasets\n",
    "    obj_full_train.df = pd.merge(rq, ind, on='request_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect individuals with housing_situation_2_label \"on the street\":\n",
    "\n",
    "- they can have a very diverse housing_situation (17 categories over a total of 21)\n",
    "\n",
    "- => no pattern to derive from this point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    q = obj_full_train.df.query(\"housing_situation_label.isna() and housing_situation_2_label != 'on the street'\")\n",
    "\n",
    "    # Count number of categories for housing_situation_2_label\n",
    "    n_cat_2 = len(q.loc[:, 'housing_situation_2_label'].unique())\n",
    "\n",
    "    # Total categories for the feature\n",
    "    n_cat_1 = len(obj_train.get_col_uniques('housing_situation_label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # Nb of indivs (an indiv is considered a new indiv at each request)\n",
    "    nb_indivs = obj_full_train.m\n",
    "\n",
    "    # Â±6% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "    obj_full_train.df[obj_full_train.df['housing_situation_label'].isna()]\n",
    "\n",
    "    # Â±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "    df_temp = obj_full_train.df[obj_full_train.df[\"housing_situation_label\"].isna()]\n",
    "    df_temp['housing_situation_2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further improvements: derive the most probable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # Get mapping housing_situation_label - housing_situation_2_label\n",
    "    obj_full_train_no_na = obj_full_train.df[~obj_full_train.df.housing_situation_label.isna()]\n",
    "    map_housing_labels = obj_full_train_no_na\\\n",
    "                .loc[:, ['housing_situation_label', 'housing_situation_2_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index\n",
    "    map_housing_labels = map_housing_labels\\\n",
    "                            .sort_values(by='housing_situation_label')\n",
    "    map_housing_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute long_term_housing_request NaNs\n",
    "\n",
    "Nb NaNs: 165556\n",
    "\n",
    "Type: bool\n",
    "\n",
    "It seems to have no direct impact on target\n",
    "\n",
    "=> drop feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    ft = 'long_term_housing_request'\n",
    "    ma_na = obj_train.df[ft].isna()\n",
    "    ma_true = obj_train.df[ft] == 't'\n",
    "\n",
    "    # Is long_term_housing_request true when 'street' only?\n",
    "    # - No\n",
    "    obj_train.df[ma_true]['housing_situation_id'].value_counts()\n",
    "\n",
    "    # Does ft impact target?\n",
    "    # - Not directly\n",
    "    ct_true   = obj_train.df[ma_true][TARGET].value_counts()\n",
    "    ct_false  = obj_train.df[~ma_true][TARGET].value_counts()\n",
    "    ct_na     = obj_train.df[ma_na][TARGET].value_counts()\n",
    "    ct_non_na = obj_train.df[~ma_na][TARGET].value_counts()\n",
    "\n",
    "    if PRINT_ON:\n",
    "        print(\"ratios TARGET when lt_housing true\")\n",
    "        for elem in ct_true:\n",
    "            print(f\"{round(elem/sum(ct_true)*100)}%\")\n",
    "\n",
    "        print(\"ratios TARGET when lt_housing false\")\n",
    "        for elem in ct_false:\n",
    "            print(f\"{round(elem/sum(ct_false)*100)}%\")\n",
    "\n",
    "        print(\"ratios TARGET when lt_housing NaN\")\n",
    "        for elem in ct_na:\n",
    "            print(f\"{round(elem/sum(ct_na)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing not NaN\")\n",
    "        for elem in ct_non_na:\n",
    "            print(f\"{round(elem/sum(ct_non_na)*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    obj_train.df.drop('long_term_housing_request', axis=1, inplace=True)\n",
    "    obj_test.df.drop('long_term_housing_request', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute town NaNs\n",
    "\n",
    "Nb NaNs: 159959\n",
    "\n",
    "categorical: cat_many\n",
    "\n",
    "Obs: The distribution is very uneven\n",
    "\n",
    "hyps:\n",
    "- very probable to live in a town, and ask housing in the district of our town\n",
    "\n",
    "- request_backoffice_creator_id: lives and makes requests in the same town, if the missing town is found in another request, all other NaNs with this backoffice_creator can be imputed properly\n",
    "\n",
    "- individual_id: might have missed town info in a request, but not in another (if requests are close, the probability to live in the same town is high)\n",
    "\n",
    "=> attribute the most probable town based on request district\n",
    "\n",
    "- 1 => build mapping of town-district pairs\n",
    "\n",
    "- 2 => attribute the corresponding pair for each NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    # Build mapping town-distric\n",
    "    mapping_town_district_train = obj_train.get_features_mapping('district', 'town')\n",
    "\n",
    "    # Fill 'town' NaNs with the most frequent occurence\n",
    "    # in the pair feature 'district'. Use the mapping\n",
    "    obj_train.fill_na_most_freq_pair('town', 'district', \n",
    "                                    mapping = mapping_town_district_train,\n",
    "                                    inplace = True)\n",
    "    obj_test.fill_na_most_freq_pair('town', 'district',\n",
    "                                    mapping = mapping_town_district_train,\n",
    "                                    inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute victim_of_violence_type NaNs\n",
    "\n",
    "Nb NaNs: 234175\n",
    "\n",
    "Hyp: is NaN if victim_of_violence is 'f'\n",
    "\n",
    "=> Set a specific value to NaNs where victim_of_violence is 'f', which will later be transformed into a boolean\n",
    "\n",
    "=> Set another specific value to NaNs where victim_of_violence is 't', IDEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # Obs: the grand majority of victim_of_violence_type NaNs comes\n",
    "    # from the absence of violence (trivial)\n",
    "    print(\"victim bool distribution\\n\",\n",
    "            obj_train.df['victim_of_violence'].value_counts())\n",
    "    print(\"\\nvictim type NaNs\\n\",\n",
    "            obj_train.df['victim_of_violence_type'].isna().value_counts())\n",
    "\n",
    "    # For the remaining victim_of_violence_type NaNs\n",
    "    # only  half requests are not granted when victim_of_violence 't',\n",
    "    remaining_nans = obj_train.df[obj_train.df['victim_of_violence'] == 't']\\\n",
    "                                [obj_train.df['victim_of_violence_type'].isna()]\n",
    "    \n",
    "    print(\"\\nRemaining Nans\\n\", remaining_nans[TARGET].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    feature = 'victim_of_violence_type'\n",
    "    feature_base = 'victim_of_violence'\n",
    "\n",
    "    # Impute NaNs corresponding to no violence signaled by 'no violence'\n",
    "    idx_na_no_violence_train = obj_train.df[obj_train.df[feature_base] == 'f'][obj_train.df[feature].isna()].index\n",
    "    idx_na_no_violence_test = obj_test.df[obj_test.df[feature_base] == 'f'][obj_test.df[feature].isna()].index\n",
    "    obj_train.df.loc[idx_na_no_violence_train, feature] = 'no violence'\n",
    "    obj_test.df.loc[idx_na_no_violence_test, feature] = 'no violence'\n",
    "\n",
    "    # Impute NaNs corresponding to a lack of specification, but with violence signaled by 'no detail'\n",
    "    idx_na_no_detail_train = obj_train.df[obj_train.df[feature_base] == 't'][obj_train.df[feature].isna()].index\n",
    "    idx_na_no_detail_test = obj_test.df[obj_test.df[feature_base] == 't'][obj_test.df[feature].isna()].index\n",
    "    obj_train.df.loc[idx_na_no_detail_train, feature] = 'no detail'\n",
    "    obj_test.df.loc[idx_na_no_detail_test, feature] = 'no detail'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_situation \n",
    "(hyp: -1 values are NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    ft_child = 'child_situation'\n",
    "    ft_violence = 'victim_of_violence_type'\n",
    "\n",
    "    # child_situation might be linked with:\n",
    "    # - group_composition_id: 58 combinations with ft\n",
    "    # - social_situation_id: no, it is redondant with group_id\n",
    "    # - victim_of_violence_type (if child): 34 combinations with ft (better)\n",
    "    obj_train.df[ft_child].value_counts()\n",
    "\n",
    "    # Get combinations for child_situation and victim_of_violence_type\n",
    "    df_temp = obj_train.df[[ft_child, ft_violence]]\\\n",
    "                            .sort_values(by = ft_violence)\n",
    "    df_temp.drop_duplicates(ignore_index=True)\\\n",
    "                            .sort_values(by = ft_violence)\n",
    "\n",
    "    # victim_of_violence_type\n",
    "    # Obs: only child_situation -1 and 10 (ie. only 10)\n",
    "    ma_child = df_temp[ft_violence] == 'child'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    ft_child = 'child_situation'\n",
    "    ft_violence = 'victim_of_violence_type'\n",
    "\n",
    "    # Hyp: -1 (NaNs) for child_situation should be 10 when victim_of_violence_type 'child'\n",
    "    # => replace child_situation by 10 when victim_of_violence_type 'child'\n",
    "    idx_child_train = obj_train.df[obj_train.df[ft_violence] == 'child'].index\n",
    "    idx_child_test = obj_test.df[obj_test.df[ft_violence] == 'child'].index\n",
    "    obj_train.df.loc[idx_child_train, ft_child] = 10\n",
    "    obj_test.df.loc[idx_child_test, ft_child] = 10\n",
    "\n",
    "    # Idem for 'family'\n",
    "    idx_family_train = obj_train.df[obj_train.df[ft_violence] == 'family'].index\n",
    "    idx_family_test = obj_test.df[obj_test.df[ft_violence] == 'family'].index\n",
    "    obj_train.df.loc[idx_family_train, ft_child] = 10\n",
    "    obj_test.df.loc[idx_family_test, ft_child] = 10\n",
    "\n",
    "    # TODO: impute the rest (majority :( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute remaining test set NaNs\n",
    "(that have no equivalent in train set, and thus can't be studied to build a clever imputation method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    # TODO: implement method based on train set logic for any feature\n",
    "    obj_train.set_default_na_vals()\n",
    "\n",
    "    # Transfer default NaNs to test object (no need to copy)\n",
    "    obj_test.default_na_vals = obj_train.default_na_vals\n",
    "\n",
    "    # Impute any remaining NaN based on its default value\n",
    "    obj_test.impute_nans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop answer creation date\n",
    "hyp: the variable is not available at prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    # For the purpose of the competition, is it expected to be used?\n",
    "    if FUTURE_PRED:\n",
    "        obj_train.df.drop('answer_creation_date', axis=1, inplace=True)\n",
    "        obj_test.df.drop('answer_creation_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete old samples\n",
    "(if it was to predict future requests (> 2020))\n",
    "- Train/test split being done randomly (â  historically), it is important for this competition to train the model on the whole train set (don't remove old samples)\n",
    "- Delete samples with group_creation_date < 2015, since it is very unlikely that current demands are treated like +5 years ago (social services evolve)\n",
    "- Threshold date: see if later is better, potential gains from domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    if FUTURE_PRED:\n",
    "        # Drop samples with year < 2015\n",
    "        old_samples = obj_train.df[obj_train.df.group_creation_date.dt.year < 2015]\n",
    "        obj_train.df.drop(old_samples.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender\n",
    "\n",
    "- => Only females are possibly pregnant, thus 30 males have made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Retrieve the individual ids, and correct for male -> pregnancy = 0\n",
    "#obj_train.df['gender'].groupby(obj_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterize large categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make clusters then transform using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dates\n",
    "- into linear numerical features (year, month)\n",
    "\n",
    "- and into categorical features (hot_season, col_season:T/F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features: Dates to year, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    # List of columns of date type\n",
    "    list_date_cols = [\n",
    "        'request_creation_date',\n",
    "        'group_creation_date'\n",
    "    ]\n",
    "\n",
    "    # Don't use the feature if trying to build robust in-production model\n",
    "    if not FUTURE_PRED:\n",
    "        list_date_cols.append('answer_creation_date')\n",
    "\n",
    "    # Transform date type: string to timestamp\n",
    "    for col in list_date_cols:\n",
    "        obj_train.df[col] = pd.to_datetime(obj_train.df[col])\n",
    "        obj_test.df[col] = pd.to_datetime(obj_test.df[col])\n",
    "\n",
    "    # Create feature: 'year'\n",
    "    for col in list_date_cols:\n",
    "        obj_train.df[col[:-4]+'year'] = obj_train.df[col].dt.year\n",
    "        obj_test.df[col[:-4]+'year'] = obj_test.df[col].dt.year\n",
    "\n",
    "    # Create feature: 'month'\n",
    "    for col in list_date_cols:\n",
    "        obj_train.df[col[:-4]+'month'] = obj_train.df[col].dt.month\n",
    "        obj_test.df[col[:-4]+'month'] = obj_test.df[col].dt.month\n",
    "\n",
    "    # Drop raw features of type date\n",
    "    for col in list_date_cols:\n",
    "        obj_train.df.drop(col, axis=1, inplace=True)\n",
    "        obj_test.df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feats: hot_season, cold_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create district_grant_ratio and town_grant_ratio\n",
    "\n",
    "Type:\n",
    "- num (float), can be linearly separable\n",
    "\n",
    "Obs:\n",
    "- district_grant_ratio: has a large impact, with districts granting more nights than there are requests and some refusing way more often\n",
    "\n",
    "- town_grant_ratio: has a large impact, with nights granted more for individuals from a specific towns (eg. Amiens is 4x)\n",
    "\n",
    "Hyp:\n",
    "- it is a sort of district emergency housing capacity measurement against the emergency housing demand\n",
    "\n",
    "- it should be very close, redondant? Yes in part, the correlation is very high (88%), but the discrepancies might come from valuable information\n",
    "\n",
    "- => create ratio of the distance between town and district of a request\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    # Create new feature district_grant_ratio\n",
    "    obj_train.create_ft_grant_ratio('district')\n",
    "    obj_test.create_ft_grant_ratio('district')\n",
    "\n",
    "    # Create new feature town_grant_ratio\n",
    "    obj_train.create_ft_grant_ratio('town')\n",
    "    obj_test.create_ft_grant_ratio('town')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: distance between town and district\n",
    "or a simpler version: if town is from this district or another\n",
    "\n",
    "- if town in district: 0\n",
    "- else: 1\n",
    "\n",
    "Since there are 1116 towns, doing the mapping would take 3h if 10s by town\n",
    "\n",
    "=> another time, or say, let the model firgure it out <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create town_capacity_left\n",
    "This can be computed on the month or the year. It provides a guess of the number of nights that can be granted at time of request (using past request then)\n",
    "\n",
    "Hyp: it might be the most impactful feature, since the selectivity based on personal criteria is lowered or inexistant when there is a large emergency housing capacity left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Town and District to regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: group_age_max, group_age_min\n",
    "\n",
    "Based on individuals information birth_month, birth_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    obj_train.create_ft_group_age_bounds(obj_full_train)\n",
    "    obj_test.create_ft_group_age_bounds(obj_full_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of indivs in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past requests by indivs forming the group of the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Single individual\n",
    "\n",
    "# Get number of ALL requests of indiv with max n_requests\n",
    "#ind_id = obj_full_train['individual_id'].value_counts().index[0]\n",
    "\n",
    "# Watch request made by the same indiv\n",
    "#obj_full_train[obj_full_train['individual_id'] == ind_id]\n",
    "\n",
    "# TODO: Past requests only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past granted request by indivs forming the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop numerical columns\n",
    "(that can't be used properly, or untill transformation methods are implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    # TODO: transform before drop: request_backoffice_creator_id\n",
    "    list_drop = [\n",
    "        'district',  # replaced by district_grant_ratio\n",
    "        'town',      # replace by town_grant_ratio\n",
    "        'group_id',\n",
    "        'group_main_requester_id',\n",
    "        'request_backoffice_creator_id',\n",
    "        'social_situation_id'\n",
    "    ]\n",
    "\n",
    "    for feature in list_drop:\n",
    "        obj_train.df.drop(feature, axis=1, inplace=True)\n",
    "        obj_test.df.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical features\n",
    "Prepare data to feed models\n",
    "\n",
    "- booleans: replace by (1, 0)\n",
    "\n",
    "- 2 < cats < 11: one-hot encoding\n",
    "\n",
    "- No transform on features with more than 11 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE:\n",
    "    # Show standard data type: True\n",
    "    # Show personalized (provide insight on information level)\n",
    "    STANDARD = False\n",
    "    \n",
    "    if STANDARD:\n",
    "        # Display standard data types\n",
    "        print(obj_train.df.dtypes)\n",
    "    else:\n",
    "        # Display col name along its type (bool, cat, num, empty)\n",
    "        for col, col_type in zip(obj_train.df.columns, obj_train.get_cols_type()):\n",
    "            print(col_type, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform all categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    # Traform categorical features:\n",
    "    # - booleans: ('t', 't') into (1, 0)\n",
    "    # - categorical with few/med classes: one-hot encoding\n",
    "    bools_train, failed_train = obj_train.transform_categories(\n",
    "                                            target=obj_train.target)\n",
    "    bools_test, failed_test = obj_test.transform_categories(\n",
    "                                            target=obj_test.target)\n",
    "\n",
    "    # Preprocess specific cat columns\n",
    "    obj_train.convert_to_bool(col='group_type',\n",
    "                                true_val='group',\n",
    "                                false_val='individual')\n",
    "\n",
    "    # Preprocess specific cat columns\n",
    "    obj_test.convert_to_bool(col='group_type',\n",
    "                                true_val='group',\n",
    "                                false_val='individual')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort features by name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    obj_train.df.sort_index(axis=1, inplace=True)\n",
    "    obj_test.df.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT_DATA:\n",
    "    obj_train.export_data('data/data_train_preprocessed.csv')\n",
    "    obj_test.export_data('data/data_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis on clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations with target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "100.0    - granted_number_of_nights\n46.8    - district_grant_ratio\n44.44    - town_grant_ratio\n35.85    - housing_situation_label_cat_hotel paid by the emergency centre\n25.46    - housing_situation_label_cat_emergency structure\n11.87    - group_creation_month\n8.85    - group_composition_label_cat_single mother with child(ren)\n4.96    - housing_situation_label_cat_hotel paid by the regional administration\n4.64    - victim_of_violence\n-4.02    - group_composition_label_cat_group of adults\n-4.38    - answer_creation_month\n-4.43    - request_creation_month\n-4.62    - group_composition_label_cat_couple without whildren\n-4.64    - victim_of_violence_type_cat_no violence\n-4.84    - housing_situation_label_cat_mobile or makeshift shelter\n-6.09    - group_composition_label_cat_man alone\n-8.58    - housing_situation_label_cat_accomodation by a third party\n-8.64    - group_creation_year\n-35.06    - housing_situation_label_cat_street\n-40.3    - housing_situation_id\n"
    }
   ],
   "source": [
    "if PREPROCESS_DATA:\n",
    "    corrs_TARGET = obj_train.df.corr()[TARGET].sort_values(ascending=False)\n",
    "\n",
    "    if PRINT_ON:\n",
    "        for ft, corr in zip(corrs_TARGET.index, corrs_TARGET):\n",
    "            if abs(corr*100) > 4:\n",
    "                print(f'{round(corr*100, 2)}    - {ft}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "If training directly with the criterion weights, the model is rapidly stuck in a bad local optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data, tools, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pre-processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOAD_PREPROCESSED_DATA:\n",
    "    train_preprocessed = pd.read_csv(filepath_or_buffer='data/data_train_preprocessed.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "    test_preprocessed = pd.read_csv(filepath_or_buffer='data/data_test_preprocessed.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "\n",
    "    # Instanciate data objects\n",
    "    obj_train = cobra.Analysis(train_preprocessed)\n",
    "    obj_test = cobra.Analysis(test_preprocessed)\n",
    "\n",
    "    # Set TARGET\n",
    "    obj_train.target = TARGET\n",
    "    obj_test.target = TARGET\n",
    "\n",
    "    # Set request_id as index\n",
    "    obj_train.df.set_index('request_id', inplace=True)\n",
    "    obj_test.df.set_index('request_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between selecting or dropping columns\n",
    "SELECT = True\n",
    "\n",
    "# Drop only the following features, keep the others\n",
    "# -------------------------------------------------\n",
    "if not SELECT:\n",
    "    drop_features = [\n",
    "        'request_creation_year',\n",
    "        'group_creation_year',\n",
    "        'answer_creation_year'\n",
    "    ]\n",
    "    df_train = obj_train.df.drop(*[drop_features], axis=1, inplace=False)\n",
    "    df_test  = obj_train.df.drop(*[drop_features], axis=1, inplace=False)\n",
    "\n",
    "else:\n",
    "    # Select and keep only the following features\n",
    "    # -------------------------------------------\n",
    "    use_features = [\n",
    "        # Positive\n",
    "        'district_grant_ratio',\n",
    "        'housing_situation_label_cat_hotel paid by the emergency centre',\n",
    "        'housing_situation_label_cat_emergency structure',\n",
    "        'group_creation_month',  # risk of overfitting\n",
    "        'group_composition_label_cat_single mother with child(ren)',\n",
    "        'housing_situation_label_cat_hotel paid by the regional administration',\n",
    "        'victim_of_violence',\n",
    "        # Negative\n",
    "        'group_composition_label_cat_group of adults',\n",
    "        'request_creation_month',  # risk of overfit\n",
    "        'group_composition_label_cat_couple without whildren',\n",
    "        'victim_of_violence_type_cat_no violence',\n",
    "        'housing_situation_label_cat_mobile or makeshift shelter',\n",
    "        'group_composition_label_cat_man alone',\n",
    "        'housing_situation_label_cat_accomodation by a third party',\n",
    "        'group_creation_year',\n",
    "        'housing_situation_label_cat_street',\n",
    "    ]\n",
    "    # Append TARGET col to the list of columns to keep\n",
    "    use_cols = use_features + [obj_train.target]\n",
    "    \n",
    "    # Create df with selected cols only\n",
    "    df_train = obj_train.df[use_cols]\n",
    "    df_test  = obj_test.df[use_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and tensorize data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train/cross-validation split:\n",
    "# .8 means 80% of samples in the train set,\n",
    "# and the remaining, 20%, in validation set\n",
    "TRAIN_VAL_SPLIT = .8\n",
    "\n",
    "# Reset the TARGET feature\n",
    "# (in case it has been changed during debugging)\n",
    "TARGET = obj_train.target\n",
    "\n",
    "# Mask - select all features columns but the TARGET\n",
    "ma_ft = df_train.columns != TARGET\n",
    "\n",
    "# Separate TARGET and features\n",
    "X_train_full = df_train.loc[:,ma_ft]\n",
    "X_test       = df_test.loc[:,ma_ft]\n",
    "Y_train_full = df_train.loc[:,TARGET]\n",
    "Y_test       = df_test.loc[:,TARGET]\n",
    "\n",
    "# Split train into: train / cross-val sets\n",
    "n_train = round(X_train_full.shape[0] * TRAIN_VAL_SPLIT)\n",
    "X_train = X_train_full[:n_train]\n",
    "X_val   = X_train_full[n_train:]\n",
    "Y_train = Y_train_full[:n_train]\n",
    "Y_val   = Y_train_full[n_train:]\n",
    "\n",
    "# Transform pandas dataframes into torch tensors\n",
    "X_train = torch.from_numpy(X_train.values)\n",
    "X_val   = torch.from_numpy(X_val.values)\n",
    "X_test  = torch.from_numpy(X_test.values)\n",
    "Y_train = torch.from_numpy(Y_train.values)\n",
    "Y_val   = torch.from_numpy(Y_val.values)\n",
    "Y_test  = torch.from_numpy(Y_test.values)\n",
    "\n",
    "# Cast all to float type\n",
    "X_train = X_train.float()\n",
    "X_val   = X_val.float()\n",
    "X_test  = X_test.float()\n",
    "Y_train = Y_train.float()\n",
    "Y_val   = Y_val.float()\n",
    "Y_test  = Y_test.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate datasets\n",
    "dataset_train = cobra.Dataset(X=X_train, Y=Y_train)\n",
    "dataset_val   = cobra.Dataset(X=X_val,   Y=Y_val)\n",
    "dataset_test  = cobra.Dataset(X=X_test,  Y=Y_test)\n",
    "\n",
    "# Instantiate data loaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size = dataset_train.len)\n",
    "dataloader_val   = torch.utils.data.DataLoader(dataset_val,   batch_size = dataset_val.len)\n",
    "dataloader_test  = torch.utils.data.DataLoader(dataset_test,  batch_size = dataset_test.len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build NN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Number of model weights 19804\n"
    }
   ],
   "source": [
    "# Set model properties\n",
    "MODEL_LAYERS = [X_train.shape[1], 200, 80, N_TARGET_CLASS]  # [hidden1, ...]\n",
    "LEARNING_RATE= .09\n",
    "MOMENTUM= .8\n",
    "WEIGHT_DECAY = 0\n",
    "DROPOUT_RATIO = 0\n",
    "SEED = 400\n",
    "\n",
    "# Reimport module\n",
    "importlib.reload(cobra)\n",
    "\n",
    "# Initialize model and weights\n",
    "model = cobra.NN(MODEL_LAYERS,\n",
    "                 p=DROPOUT_RATIO,\n",
    "                 seed=SEED)\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                        lr=LEARNING_RATE,\n",
    "                        momentum=MOMENTUM,\n",
    "                        weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Reset performances history\n",
    "monitor_epochs = cobra.Monitoring(sets=SETS,\n",
    "                                  metrics=METRICS)\n",
    "monitor_batchs = cobra.Monitoring(sets=SETS,\n",
    "                                  metrics=METRICS)\n",
    "\n",
    "\n",
    "if PRINT_ON:\n",
    "    # Calculate the number of weights\n",
    "    n_weights = cobra.calculate_n_weights(MODEL_LAYERS)\n",
    "    print('Number of model weights', n_weights)\n",
    "    \n",
    "    # Show storing format\n",
    "    monitor_epochs.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast weights to tensor format\n",
    "CLASS_WEIGHTS = [1, 10, 100, 1000]  # compet standard\n",
    "class_weights = torch.FloatTensor(CLASS_WEIGHTS)\n",
    "CRITERION = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Set monitoring properties\n",
    "SETS = ['train', 'eval', 'test']\n",
    "METRICS = {'accuracy': cobra.compute_accuracy,\n",
    "           'loss_model': CRITERION,\n",
    "           'loss_compet': cobra.competition_scorer} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0 train/val: mod_loss 0.8104, 0.8354, comp_loss 0.8104, 0.8354, acc 14.3514, 14.5304\nEpoch 10 train/val: mod_loss 0.8057, 0.8358, comp_loss 0.8057, 0.8359, acc 15.1606, 14.6018\nEpoch 20 train/val: mod_loss 0.7953, 0.8389, comp_loss 0.7953, 0.8389, acc 14.7885, 15.4436\nEpoch 30 train/val: mod_loss 0.795, 0.8461, comp_loss 0.795, 0.8461, acc 14.8725, 15.5023\nEpoch 40 train/val: mod_loss 0.7947, 0.8385, comp_loss 0.7947, 0.8385, acc 14.4228, 14.6606\nEpoch 50 train/val: mod_loss 0.7921, 0.8302, comp_loss 0.7921, 0.8302, acc 15.4408, 15.3218\nEpoch 60 train/val: mod_loss 0.7901, 0.8447, comp_loss 0.7901, 0.8447, acc 15.0158, 15.0426\nEpoch 70 train/val: mod_loss 0.7858, 0.8415, comp_loss 0.7858, 0.8415, acc 15.8176, 14.7928\nEpoch 80 train/val: mod_loss 0.8101, 0.8405, comp_loss 0.8101, 0.8405, acc 15.7106, 15.9746\nEpoch 90 train/val: mod_loss 0.7822, 0.834, comp_loss 0.7822, 0.834, acc 14.935, 14.7634\n"
    }
   ],
   "source": [
    "# Train model\n",
    "n_epochs = 100\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # Reset batchs scores\n",
    "    monitor_batchs.reset()\n",
    "\n",
    "    # Training\n",
    "    # --------\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_train):\n",
    "\n",
    "        # Predict\n",
    "        predictions = model(x)\n",
    "\n",
    "        # Evaluate model and store metrics\n",
    "\n",
    "        loss = monitor_batchs.evaluate(predictions, labels, 'train')\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Backpropagate\n",
    "        optimizer.step()\n",
    "        \n",
    "    # Validation\n",
    "    # ----------\n",
    "    with torch.no_grad():\n",
    "        for n_batch, (x, labels) in enumerate(dataloader_val):\n",
    "            \n",
    "            # Predict on the eval set\n",
    "            predictions = model(x)\n",
    "\n",
    "            # Evaluate model and store metrics\n",
    "            monitor_batchs.evaluate(predictions, labels, set_i='eval')\n",
    "\n",
    "\n",
    "    # Compute & store: train and eval losses for the epoch\n",
    "    monitor_epochs.compute(monitor_batchs, ['train', 'eval'])\n",
    "\n",
    "    # Save weights if improved eval loss\n",
    "    if epoch == 0:\n",
    "        best_weights['iter'] = 1\n",
    "        best_weights['loss'] = monitor_epochs.metrics['eval']['loss_model'][0]\n",
    "        best_weights['weights'] = model.state_dict()\n",
    "    else:\n",
    "        # If current eval loss is the new best, save its parameters\n",
    "        curr_loss = monitor_epochs.metrics['eval']['loss_model'][-1]\n",
    "        \n",
    "        if curr_loss < best_weights['loss']:\n",
    "            best_weights['iter'] = epoch\n",
    "            best_weights['loss'] = curr_loss\n",
    "            best_weights['weights'] = model.state_dict()\n",
    "\n",
    "    # Display scores (each 1 or 10 epoch %1 / %10)\n",
    "    if epoch % 5 == 0:\n",
    "        monitor_epochs.print_scores(i_epoch=epoch, sets=['train', 'eval'])\n",
    "\n",
    "    # Stop training if cross-val loss is worsening, and save best weights\n",
    "    if epoch > 21:\n",
    "        # Compute the average of the last 10 and prev 10 eval losses\n",
    "        last_10_val_loss = monitor_epochs.metrics['eval']['loss_model'][-11:-1]\n",
    "        last_prev_10_val_loss = monitor_epochs.metrics['eval']['loss_model'][-21:-11]\n",
    "        avg_lasts_val_loss = np.array(last_10_val_loss).mean()\n",
    "        avg_prevs_val_loss = np.array(last_prev_10_val_loss).mean()\n",
    "\n",
    "        # If loss is worsening\n",
    "        if avg_lasts_val_loss > avg_prevs_val_loss:\n",
    "            # Save weights with minimal loss\n",
    "            f_name = 'weights/weights_{}.pt'.format(best_weights['loss'])\n",
    "            torch.save(best_weights['weights'], f_name)\n",
    "            \n",
    "            # Stop training\n",
    "            print(\"\\nStop training\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot metrics history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\naccuracy plot (blue: train | orange: eval)\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 378.465625 248.518125 \nL 378.465625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"ma2d2da7918\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#ma2d2da7918\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(48.502557 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"102.580736\" xlink:href=\"#ma2d2da7918\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(96.218236 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"153.477665\" xlink:href=\"#ma2d2da7918\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(143.933915 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"204.374594\" xlink:href=\"#ma2d2da7918\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(194.830844 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"255.271523\" xlink:href=\"#ma2d2da7918\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(245.727773 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"306.168453\" xlink:href=\"#ma2d2da7918\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(296.624703 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"357.065382\" xlink:href=\"#ma2d2da7918\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(347.521632 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m85c3c20eda\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m85c3c20eda\" y=\"201.893243\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 12.5 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 205.692462)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m85c3c20eda\" y=\"176.136094\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 15.0 -->\n      <g transform=\"translate(7.2 179.935313)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m85c3c20eda\" y=\"150.378945\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 17.5 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(7.2 154.178163)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m85c3c20eda\" y=\"124.621795\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20.0 -->\n      <g transform=\"translate(7.2 128.421014)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m85c3c20eda\" y=\"98.864646\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 22.5 -->\n      <g transform=\"translate(7.2 102.663865)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m85c3c20eda\" y=\"73.107497\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 25.0 -->\n      <g transform=\"translate(7.2 76.906715)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m85c3c20eda\" y=\"47.350347\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 27.5 -->\n      <g transform=\"translate(7.2 51.149566)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m85c3c20eda\" y=\"21.593198\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 30.0 -->\n      <g transform=\"translate(7.2 25.392417)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p3fb623f15e)\" d=\"M 51.683807 180.131543 \nL 52.701745 109.016054 \nL 53.719684 134.729931 \nL 54.737623 110.789176 \nL 55.755561 104.776427 \nL 56.7735 17.083636 \nL 57.791438 40.376342 \nL 58.809377 41.138753 \nL 59.827315 52.124693 \nL 60.845254 70.303058 \nL 61.863193 76.574409 \nL 63.89907 83.263026 \nL 64.917008 101.083882 \nL 65.934947 102.002897 \nL 66.952886 96.823649 \nL 67.970824 110.151429 \nL 68.988763 118.504988 \nL 70.006701 118.504988 \nL 71.02464 115.082378 \nL 72.042578 120.824161 \nL 73.060517 116.800895 \nL 74.078456 127.253146 \nL 75.096394 128.090768 \nL 76.114333 126.111589 \nL 77.132271 132.540573 \nL 78.15021 123.905747 \nL 79.168149 129.815467 \nL 80.186087 131.669982 \nL 81.204026 131.378411 \nL 82.221964 133.53583 \nL 83.239903 131.323806 \nL 84.257841 135.308952 \nL 85.27578 136.184695 \nL 86.293719 134.481632 \nL 87.311657 138.991194 \nL 88.329596 140.223416 \nL 89.347534 140.499532 \nL 90.365473 132.437545 \nL 91.383412 143.105126 \nL 92.40135 143.835598 \nL 93.419289 143.73257 \nL 94.437227 145.684962 \nL 95.455166 146.236165 \nL 96.473104 143.522391 \nL 97.491043 136.677171 \nL 98.508982 141.813147 \nL 99.52692 141.343337 \nL 100.544859 140.158508 \nL 101.562797 120.461501 \nL 102.580736 157.63937 \nL 103.598675 165.322212 \nL 104.616613 166.565768 \nL 105.634552 164.651496 \nL 106.65249 166.171168 \nL 107.670429 165.841477 \nL 108.688367 166.144381 \nL 109.706306 164.754525 \nL 110.724245 160.9538 \nL 111.742183 154.048823 \nL 112.760122 193.923981 \nL 113.77806 180.44475 \nL 114.795999 198.465482 \nL 115.813938 212.880213 \nL 116.831876 208.636465 \nL 117.849815 209.139245 \nL 118.867753 213.415962 \nL 120.90363 206.202929 \nL 121.921569 200.823806 \nL 122.939508 198.63857 \nL 123.957446 187.825719 \nL 124.975385 188.030746 \nL 125.993323 196.097885 \nL 127.011262 188.998184 \nL 128.029201 187.025186 \nL 129.047139 194.411307 \nL 130.065078 192.788606 \nL 131.083016 189.079577 \nL 132.100955 186.782039 \nL 133.118893 192.51352 \nL 134.136832 188.122441 \nL 135.154771 183.104948 \nL 136.172709 183.359429 \nL 137.190648 182.640289 \nL 138.208586 174.253761 \nL 139.226525 174.459819 \nL 140.244464 179.807003 \nL 141.262402 179.612279 \nL 142.280341 177.244682 \nL 144.316218 173.800436 \nL 145.334156 173.794254 \nL 146.352095 176.460634 \nL 147.370034 173.897283 \nL 148.387972 178.168848 \nL 149.405911 181.142253 \nL 150.423849 173.967342 \nL 151.441788 174.57315 \nL 152.459727 173.27602 \nL 153.477665 177.395103 \nL 154.495604 172.713484 \nL 155.513542 173.118386 \nL 156.531481 172.702151 \nL 157.549419 176.465785 \nL 158.567358 174.24861 \nL 159.585297 182.483686 \nL 160.603235 175.00587 \nL 161.621174 176.773841 \nL 162.639112 180.039848 \nL 163.657051 170.183102 \nL 164.67499 173.048327 \nL 165.692928 179.763731 \nL 166.710867 176.670812 \nL 167.728805 173.216264 \nL 168.746744 168.258527 \nL 169.764682 174.188853 \nL 170.782621 170.918726 \nL 172.818498 174.627755 \nL 173.836437 175.633314 \nL 174.854375 174.811146 \nL 175.872314 171.551321 \nL 177.908191 177.103532 \nL 178.92613 172.19422 \nL 179.944068 174.578302 \nL 180.962007 177.341529 \nL 181.979945 178.914775 \nL 182.997884 173.572742 \nL 184.015823 170.264494 \nL 185.033761 170.447885 \nL 186.0517 169.647353 \nL 187.069638 167.506419 \nL 188.087577 173.416139 \nL 189.105516 173.757164 \nL 190.123454 172.297248 \nL 191.141393 181.20201 \nL 192.159331 183.624212 \nL 193.17727 183.840572 \nL 194.195208 181.153587 \nL 195.213147 183.959055 \nL 196.231086 179.936819 \nL 197.249024 181.558489 \nL 198.266963 181.148435 \nL 199.284901 183.715908 \nL 200.30284 182.640289 \nL 201.320779 180.882621 \nL 202.338717 190.831063 \nL 203.356656 177.179774 \nL 204.374594 174.708118 \nL 205.392533 187.241546 \nL 206.410471 181.580125 \nL 207.42841 182.916406 \nL 208.446349 174.340306 \nL 209.464287 174.854418 \nL 210.482226 176.222638 \nL 211.500164 174.443334 \nL 212.518103 177.714492 \nL 213.536042 175.665253 \nL 214.55398 179.18574 \nL 215.571919 177.639281 \nL 216.589857 177.428073 \nL 217.607796 179.980091 \nL 218.625734 180.845531 \nL 219.643673 176.66051 \nL 220.661612 177.141653 \nL 221.67955 176.638874 \nL 222.697489 173.113235 \nL 223.715427 174.135279 \nL 224.733366 175.989793 \nL 225.751305 172.62694 \nL 226.769243 176.649176 \nL 227.787182 179.196043 \nL 228.80512 175.924885 \nL 229.823059 181.521399 \nL 230.840997 177.389952 \nL 231.858936 178.471752 \nL 232.876875 177.281772 \nL 233.894813 174.308367 \nL 234.912752 176.930444 \nL 235.93069 182.402293 \nL 236.948629 181.70479 \nL 237.966568 173.610863 \nL 238.984506 183.50573 \nL 240.002445 172.588819 \nL 241.020383 169.020939 \nL 242.038322 185.137702 \nL 244.074199 172.097373 \nL 245.092138 182.218902 \nL 246.110076 175.708525 \nL 247.128015 174.027099 \nL 248.145953 180.752805 \nL 249.163892 180.023363 \nL 250.181831 180.023363 \nL 251.199769 180.148028 \nL 252.217708 175.140838 \nL 253.235646 173.459411 \nL 254.253585 182.721682 \nL 255.271523 182.818529 \nL 256.289462 179.352647 \nL 257.307401 173.394503 \nL 258.325339 172.4487 \nL 259.343278 175.422106 \nL 260.361216 173.161658 \nL 261.379155 178.904472 \nL 262.397094 175.270654 \nL 263.415032 183.429488 \nL 264.432971 177.065412 \nL 265.450909 174.481455 \nL 266.468848 178.811747 \nL 267.486786 175.210897 \nL 268.504725 167.663022 \nL 269.522664 170.918726 \nL 270.540602 181.283403 \nL 271.558541 179.558704 \nL 272.576479 180.617838 \nL 273.594418 177.725825 \nL 274.612357 178.676779 \nL 275.630295 178.315149 \nL 276.648234 169.803956 \nL 277.666172 182.212721 \nL 278.684111 176.497724 \nL 279.702049 180.850683 \nL 280.719988 180.650807 \nL 281.737927 170.041952 \nL 282.755865 175.232533 \nL 283.773804 174.864721 \nL 284.791742 176.292697 \nL 285.809681 177.449709 \nL 286.82762 169.572142 \nL 287.845558 180.774441 \nL 288.863497 177.968973 \nL 289.881435 177.584676 \nL 290.899374 179.164104 \nL 291.917312 174.702966 \nL 292.935251 174.870903 \nL 293.95319 176.114458 \nL 294.971128 175.00587 \nL 295.989067 182.082905 \nL 297.007005 178.839564 \nL 298.024944 172.767059 \nL 299.042883 174.811146 \nL 301.07876 174.638058 \nL 302.096698 174.784359 \nL 303.114637 182.981314 \nL 304.132575 180.694079 \nL 305.150514 183.743726 \nL 306.168453 171.594593 \nL 307.186391 172.420883 \nL 308.20433 180.098574 \nL 309.222268 166.57607 \nL 310.240207 180.526142 \nL 311.258146 176.016581 \nL 312.276084 174.368123 \nL 313.294023 171.421505 \nL 314.311961 172.756756 \nL 315.3299 174.497939 \nL 316.347838 175.973309 \nL 317.365777 174.946114 \nL 318.383716 171.15054 \nL 319.401654 183.159553 \nL 320.419593 173.302808 \nL 321.437531 170.582853 \nL 322.45547 176.071186 \nL 323.473409 167.354967 \nL 324.491347 177.190077 \nL 325.509286 173.038024 \nL 326.527224 167.712476 \nL 327.545163 176.978868 \nL 328.563101 177.498132 \nL 329.58104 180.001727 \nL 330.598979 169.717412 \nL 331.616917 173.340928 \nL 332.634856 178.64484 \nL 333.652794 157.661006 \nL 334.670733 178.601568 \nL 335.688672 179.931667 \nL 336.70661 168.814882 \nL 337.724549 162.500259 \nL 338.742487 165.933172 \nL 339.760426 170.46437 \nL 340.778364 166.241227 \nL 341.796303 171.989193 \nL 342.814242 181.002135 \nL 343.83218 180.882621 \nL 344.850119 179.807003 \nL 345.868057 173.99516 \nL 346.885996 176.80578 \nL 347.903935 176.51936 \nL 348.921873 171.242236 \nL 349.939812 168.944698 \nL 350.95775 170.431401 \nL 351.975689 177.114866 \nL 352.993627 169.96159 \nL 354.011566 184.364988 \nL 356.047443 166.474072 \nL 356.047443 166.474072 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#p3fb623f15e)\" d=\"M 51.683807 110.057673 \nL 52.701745 139.492943 \nL 53.719684 112.112063 \nL 54.737623 106.576337 \nL 55.755561 18.487916 \nL 56.7735 41.218085 \nL 57.791438 43.79174 \nL 58.809377 53.134373 \nL 59.827315 72.880834 \nL 60.845254 79.628177 \nL 61.863193 82.028743 \nL 62.881131 86.764968 \nL 63.89907 102.704522 \nL 64.917008 102.87761 \nL 65.934947 97.016313 \nL 66.952886 108.262915 \nL 67.970824 118.18972 \nL 68.988763 118.94698 \nL 70.006701 114.793897 \nL 71.02464 120.200838 \nL 72.042578 116.524778 \nL 73.060517 125.953955 \nL 74.078456 127.035755 \nL 75.096394 124.397193 \nL 76.114333 132.074884 \nL 77.132271 123.423573 \nL 78.15021 129.436322 \nL 79.168149 130.408912 \nL 80.186087 131.728708 \nL 81.204026 133.523466 \nL 82.221964 131.166172 \nL 83.239903 134.58363 \nL 84.257841 136.162029 \nL 85.27578 134.518722 \nL 86.293719 138.692411 \nL 87.311657 140.163659 \nL 88.329596 139.947299 \nL 89.347534 132.485968 \nL 90.365473 142.823858 \nL 91.383412 143.62336 \nL 92.40135 143.601724 \nL 93.419289 145.807566 \nL 94.437227 145.527328 \nL 95.455166 144.229168 \nL 96.473104 138.108239 \nL 97.491043 141.482425 \nL 98.508982 141.568969 \nL 99.52692 140.530441 \nL 100.544859 121.953355 \nL 101.562797 155.519041 \nL 102.580736 162.958736 \nL 103.598675 166.483345 \nL 104.616613 164.904947 \nL 105.634552 165.835295 \nL 106.65249 165.705479 \nL 107.670429 166.203107 \nL 108.688367 164.428954 \nL 110.724245 153.334835 \nL 111.742183 196.351335 \nL 112.760122 182.639259 \nL 113.77806 204.418474 \nL 114.795999 214.756364 \nL 115.813938 209.544147 \nL 116.831876 210.085047 \nL 117.849815 213.350023 \nL 118.867753 210.927821 \nL 119.885692 207.943082 \nL 120.90363 201.455372 \nL 121.921569 199.617342 \nL 122.939508 189.689506 \nL 123.957446 189.840958 \nL 124.975385 197.475377 \nL 125.993323 190.598218 \nL 127.011262 187.28894 \nL 128.029201 194.318581 \nL 129.047139 193.496413 \nL 130.065078 191.918014 \nL 131.083016 187.678388 \nL 132.100955 192.91224 \nL 133.118893 190.814578 \nL 134.136832 184.563833 \nL 135.154771 184.305231 \nL 136.172709 183.396519 \nL 137.190648 178.14103 \nL 138.208586 176.41118 \nL 139.226525 180.238693 \nL 140.244464 180.714685 \nL 141.262402 177.967942 \nL 143.298279 174.269216 \nL 144.316218 174.745208 \nL 145.334156 177.05923 \nL 146.352095 174.78848 \nL 148.387972 182.033451 \nL 149.405911 174.35576 \nL 150.423849 174.766844 \nL 151.441788 173.772618 \nL 152.459727 177.773218 \nL 153.477665 173.556258 \nL 154.495604 173.664438 \nL 155.513542 174.010614 \nL 156.531481 177.362134 \nL 157.549419 175.697192 \nL 158.567358 183.612879 \nL 159.585297 175.956824 \nL 160.603235 178.638659 \nL 161.621174 180.909409 \nL 162.639112 171.134056 \nL 163.657051 173.49135 \nL 164.67499 180.411781 \nL 165.692928 177.080866 \nL 166.710867 174.225944 \nL 167.728805 168.776761 \nL 168.746744 173.210082 \nL 169.764682 171.522473 \nL 170.782621 173.642802 \nL 171.80056 174.831752 \nL 172.818498 176.19482 \nL 173.836437 175.351016 \nL 174.854375 171.587381 \nL 175.872314 175.156292 \nL 176.890253 177.015958 \nL 177.908191 172.279734 \nL 179.944068 178.054486 \nL 180.962007 179.524705 \nL 181.979945 173.556258 \nL 182.997884 169.706079 \nL 184.015823 170.809515 \nL 185.033761 170.614791 \nL 186.0517 168.365677 \nL 187.069638 172.95045 \nL 188.087577 174.225944 \nL 189.105516 173.534622 \nL 190.123454 181.990179 \nL 191.141393 184.628741 \nL 192.159331 184.542197 \nL 193.17727 182.747439 \nL 194.195208 185.559089 \nL 195.213147 182.184903 \nL 196.231086 182.747439 \nL 197.249024 182.682531 \nL 198.266963 185.256185 \nL 199.284901 183.374883 \nL 200.30284 183.288339 \nL 201.320779 192.004559 \nL 202.338717 177.448678 \nL 203.356656 174.875024 \nL 204.374594 188.414012 \nL 205.392533 183.612879 \nL 206.410471 184.153779 \nL 207.42841 175.524104 \nL 208.446349 175.2212 \nL 209.464287 175.65392 \nL 210.482226 175.827008 \nL 211.500164 178.422299 \nL 212.518103 176.000096 \nL 213.536042 179.481433 \nL 214.55398 178.487207 \nL 215.571919 177.838126 \nL 216.589857 180.130513 \nL 217.607796 182.963799 \nL 218.625734 177.340498 \nL 219.643673 178.314118 \nL 220.661612 177.751582 \nL 221.67955 172.907178 \nL 223.715427 177.145774 \nL 224.733366 173.512986 \nL 225.751305 177.665038 \nL 226.769243 180.303601 \nL 227.787182 176.562632 \nL 228.80512 182.898891 \nL 229.823059 177.989578 \nL 230.840997 178.768475 \nL 231.858936 178.638659 \nL 232.876875 176.864506 \nL 233.894813 177.81649 \nL 234.912752 184.088871 \nL 235.93069 183.180159 \nL 236.948629 174.550484 \nL 237.966568 185.277821 \nL 238.984506 173.16681 \nL 240.002445 170.463339 \nL 241.020383 185.148005 \nL 243.05626 174.46394 \nL 244.074199 184.045599 \nL 245.092138 177.124138 \nL 246.110076 174.420668 \nL 247.128015 182.055087 \nL 248.145953 181.407037 \nL 249.163892 180.909409 \nL 250.181831 180.887773 \nL 251.199769 176.821234 \nL 252.217708 174.182672 \nL 253.235646 184.563833 \nL 254.253585 184.110507 \nL 255.271523 180.974317 \nL 256.289462 174.658664 \nL 257.307401 173.188446 \nL 258.325339 175.480832 \nL 259.343278 174.918296 \nL 260.361216 180.325237 \nL 261.379155 176.19482 \nL 262.397094 184.498925 \nL 263.415032 178.552115 \nL 264.432971 175.783736 \nL 265.450909 180.238693 \nL 266.468848 175.740464 \nL 267.486786 168.927183 \nL 268.504725 172.431186 \nL 269.522664 182.098359 \nL 270.540602 181.515217 \nL 271.558541 181.645033 \nL 272.576479 179.373252 \nL 273.594418 180.757957 \nL 274.612357 179.914153 \nL 275.630295 171.565745 \nL 276.648234 183.288339 \nL 277.666172 177.232318 \nL 278.684111 181.925271 \nL 279.702049 181.925271 \nL 280.719988 171.911921 \nL 281.737927 176.281364 \nL 282.755865 175.65392 \nL 283.773804 177.470314 \nL 284.791742 178.119394 \nL 285.809681 170.960968 \nL 286.82762 181.385401 \nL 288.863497 178.768475 \nL 289.881435 181.428673 \nL 290.899374 175.891916 \nL 291.917312 176.367908 \nL 292.935251 177.015958 \nL 293.95319 176.19482 \nL 294.971128 183.093615 \nL 295.989067 179.632885 \nL 297.007005 173.794254 \nL 298.024944 175.264472 \nL 299.042883 175.199564 \nL 300.060821 175.7621 \nL 301.07876 176.108276 \nL 302.096698 183.677787 \nL 303.114637 181.946907 \nL 304.132575 185.299457 \nL 305.150514 173.036994 \nL 306.168453 172.820634 \nL 307.186391 181.060861 \nL 308.20433 168.408949 \nL 309.222268 182.184903 \nL 310.240207 176.929414 \nL 312.276084 172.972086 \nL 313.294023 173.642802 \nL 314.311961 176.065004 \nL 315.3299 177.556858 \nL 316.347838 175.697192 \nL 317.365777 171.890285 \nL 318.383716 185.364365 \nL 319.401654 175.286108 \nL 320.419593 175.264472 \nL 321.437531 176.972686 \nL 322.45547 169.814259 \nL 323.473409 176.73469 \nL 324.491347 175.307744 \nL 325.509286 169.035363 \nL 326.527224 178.270846 \nL 327.545163 178.746839 \nL 328.563101 180.801229 \nL 329.58104 171.565745 \nL 330.598979 174.615392 \nL 331.616917 179.524705 \nL 332.634856 160.66635 \nL 333.652794 179.654521 \nL 334.670733 180.195421 \nL 335.688672 172.106646 \nL 336.70661 166.094927 \nL 337.724549 166.569889 \nL 338.742487 171.976829 \nL 339.760426 166.872793 \nL 340.778364 173.210082 \nL 341.796303 182.271447 \nL 342.814242 182.660895 \nL 343.83218 182.011815 \nL 344.850119 175.048112 \nL 345.868057 177.427042 \nL 346.885996 178.573751 \nL 347.903935 173.404806 \nL 348.921873 170.528247 \nL 349.939812 172.928814 \nL 350.95775 179.32998 \nL 351.975689 172.452822 \nL 352.993627 185.688905 \nL 354.011566 178.162666 \nL 355.029505 168.517129 \nL 356.047443 181.688305 \nL 356.047443 181.688305 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p3fb623f15e\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOzdd5hU5fXA8e+507b3wjZYYKkWUBdQURGwYDea2GKLGFM0UdN+pseoSYxRoyaxxJqYIMYeoygWRFSk975L2977zszO3Pf3x50tLLMFtsHs+3keHmZum3eW5cyZ85YrSik0TdO00GUMdQM0TdO0gaUDvaZpWojTgV7TNC3E6UCvaZoW4nSg1zRNC3H2oW5AMElJSSo7O3uom6FpmnbUWL16dYVSKjnYviMy0GdnZ7Nq1aqhboamadpRQ0T2drVPl240TdNCnA70mqZpIU4Hek3TtBCnA72maVqI04Fe0zQtxOlAr2maFuJ0oNc0TQtxIR/oP8+rYFdZw1A3Q9M0bcgckROm+o1SXPP35YCw5w8XDHVrNE3ThkRoZ/R3x/Gs44GhboWmadqQ6jHQi0iYiKwQkfUisllE7g5sHy0iX4rILhFZKCLOLs7/aeCY7SJybn+/gZ7Msa0b7JfUNE07ovQmo/cAc5RSU4CpwDwRORm4H3hYKZUDVAPzO58oIpOBq4BjgHnA30TE1l+N1zRN03rWY6BXltbeTEfgjwLmAK8Etr8AXBrk9EuAl5RSHqXUbmAXML3PrdY0TdN6rVc1ehGxicg6oAxYDOQBNUopX+CQAiAjyKkZwP4Oz7s6DhG5RURWiciq8vLy3rZf0zRN60GvAr1Syq+UmgpkYmXkE/u7IUqpp5RSuUqp3OTkoEsqa5qmaYfhkEbdKKVqgI+BU4A4EWkdnpkJFAY5pRDI6vC8q+M0TdO0AdKbUTfJIhIXeBwOnA1sxQr4Xw0cdgPwZpDT3wKuEhGXiIwGxgEr+qPhh0opNRQvq2maNuR6M2EqDXghMFrGAF5WSr0tIluAl0TkXmAt8AyAiFwM5CqlfqWU2iwiLwNbAB9wq1LKPyDvpAfuFpNwpx7wo2na8NNjoFdKbQBOCLI9nyAjaJRSb2Fl8q3P7wPu61sz+8bApMnr04Fe07RhKXRnxnYo1UTgpsk7JF8kNE3ThlzoBnqzPbBH4KG5RQd6TdOGp9AN9B26AiJEZ/Sapg1foRvoO2X0TV5fNwdrmqaFrtAN9B0zetw0eXRGr2na8BS6gb5jRi8emnSNXtO0YSp0A70y2x5G4KFZl240TRumQjfQm51KN7ozVtO0YSp0A73qVLrRgV7TtGEqdAN9p4y+WQd6TdOGqdAN9B0y+kjx0Khr9JqmDVOhG+g7ZPTheHRGr2nasBW6gb7DqJtI3Hy0rYzNRbVD2CBN07ShMSwC/Wnx1bT4TR79cOcQNkjTNG1ohG6gD5RutppZjKpfw5zURkrrPEPcKE3TtMEXuoE+0Bm70D8bU2zM835ARYMO9JqmDT893nhERLKAfwCpgAKeUko9IiILgQmBw+KAmsANxDufvweoB/yATymV209t714goy9WidTHTWSML4/yeg9KKURkUJqgaZp2JOjNrQR9wA+VUmtEJBpYLSKLlVJXth4gIg8C3fV0zlZKVfSxrYcmkNH7MfBEpBFXsxePz6Te4yMmzDGoTdE0TRtKPZZulFLFSqk1gcf1WDcGz2jdL1Z6fAWwYKAaeVhMqzPWj4E3IpVobykA5fW6fKNp2vBySDV6EcnGun/slx02nw6UKqW6GtKigPdFZLWI3HI4jTwsgYzexMAbkYazpY5w3FToQK9p2jDTm9INACISBbwK3KGUquuw62q6z+ZPU0oVikgKsFhEtimllga5/i3ALQAjR47sbbO6ZraXbryRyQCMkGrKdYespmnDTK8yehFxYAX5fymlXuuw3Q5cBizs6lylVGHg7zLgdWB6F8c9pZTKVUrlJicn9/4ddPnC7YHeF5EGwAip0qUbTdOGnR4DfaAG/wywVSn1UKfdZwHblFIFXZwbGejARUQigXOATX1rci8FMnpTGbREWYE+w9CBXtO04ac3Gf1M4DpgjoisC/w5P7DvKjqVbUQkXUTeCTxNBZaJyHpgBfA/pdSifmp799oyesEfCPRjXLV6LL2macNOjzV6pdQyIOjAc6XUjUG2FQHnBx7nA1P61sTDFBh1Y2IgjnAIT2CkWcPqBu+QNEfTNG2ohPzMWD8GNkMgKpUUaqj36OWKNU0bXkI30HcYdWMTAVc0UdJMg1sHek3ThpfQDfQdxtEbBuCKIhI39Z6WoW2XpmnaIAvdQG92Kt24oglXOqPXNG34Cd1ArzqVbpzRhKkmGjw+lFJD3DhN07TBE7qBvsOoG8MQcEXh8jfR4ld4fGYPJ2uapoWO0A30B2X0UTj8TYCiXpdvNE0bRkI30B9Uo4/CwCQcD/Vu3SGradrwEbqBPpDRKyVW6cYZBUAUbhr0WHpN04aR0A30B42jjwEgUo+l1zRtmAndQK/abzzSOo4eIBI3dTrQa5o2jIR8oDc7dMaCLt1omjb8hG6gD9IZCxAlTTTozlhN04aR0A30ByyBYE2YAqt0o4dXapo2nIRuoA+yqBlAnM2jSzeapg0roRvoOy9THCjdJDi8ujNW07RhJXQDvdmhdCMCjkgA4nVGr2naMNObe8ZmicjHIrJFRDaLyO2B7b8RkcIgtxfsfP48EdkuIrtE5K7+fgNd6ji8UgDDAGcUcXYP1Y36LlOapg0fPd5KEPABP1RKrQnc6Hu1iCwO7HtYKfWnrk4UERvwV+BsoABYKSJvKaW29LXhPeo86gbAGUWKzUt+ecOAv7ymadqRoseMXilVrJRaE3hcD2wFMnp5/enALqVUvlLKC7wEXHK4jT0kyo9CELH+AOCKIsnZQlGtHkuvadrwcUg1ehHJBk4Avgxsuk1ENojIsyISH+SUDGB/h+cFdPEhISK3iMgqEVlVXl5+KM0KzvRjSmDETauoVJLMSgDyynRWr2na8NDrQC8iUcCrwB1KqTrgcWAsMBUoBh7sS0OUUk8ppXKVUrnJycl9uVTggn4UNmsMfavEscQ07QVglw70mqYNE70K9CLiwAry/1JKvQaglCpVSvmVUibwd6wyTWeFQFaH55mBbQMvWEafOA5bcyWJtkZ26kCvadow0ZtRNwI8A2xVSj3UYXtah8O+AmwKcvpKYJyIjBYRJ3AV8FbfmtxLykR17IgFSBoHwMy4araX1A1KMzRN04ZabzL6mcB1wJxOQyn/KCIbRWQDMBu4E0BE0kXkHQCllA+4DXgPqxP3ZaXU5oF4Iwcx/Zhio2OcJzEHgFmJdSzPr8Ld4h+Upmiapg2lHodXKqWWARJk1ztdHF8EnN/h+TtdHTuglN9aubJjpI/PBsNObnQlzS1+Ps+rYM7E1EFvmqZp2mAK6ZmxSjoFepsD4rPJ9O4m0mlj8ZayoWufpmnaIAndQB/I6A3p9GVk3DnY8j7gorEGH24txTTV0LRP0zRtkIRuoDfNg0s3ANNuBtPH9c4llNV72FhYOyTN0zRNGyyhG+iVNbzyoIw+cSxkn8746k8wBD7YWjo07dM0TRskoRvozSCdsa2yZmAv38q0zDC+3F01+G3TNE0bRKEb6IONummVmQvKz0n2vdQ169sKapoW2kI40JuBztgg+zJyAZho7tS3FdQ0LeSFbqBvXQIhWKSPSoa4kYz1bKNe3yhc07QQF7qBvi2jD5bSAwljifeV0eDxoZQeYqlpWugK3UDfXWcsQFgs4WYDpoJGr14KQdO00BW6gV75D7y7VGfhcYT56gFo0HV6TdNCWOgGetOPia3r0k1YLM5AoNd1ek3TQlnoBvqeMvqwOGymFxde6nRGr2laCAvdQG/6MZEDbzzSUVgsADE06vvHapoW0kI30CsTPwZGV++wNdBLky7daJoW0kI30Pc06iY8DoBYGnVnrKZpIS10A73y41fdjKMPswJ9jDTq2bGapoW03twzNktEPhaRLSKyWURuD2x/QES2icgGEXldROK6OH9P4JaD60RkVX+/gS6ZPXXGWqWbWGkiumwln723kGeW7R605mmapg2W3mT0PuCHSqnJwMnArSIyGVgMHKuUOh7YAfy0m2vMVkpNVUrl9rnFvdU66qaHjD7Z7mbm7kdI/Owe7nl7y6A1T9M0bbD0GOiVUsVKqTWBx/VYN/nOUEq9H7j5N8ByIHPgmnkYzNbO2K4CfQwAKfYmkpvzSZaaQWycpmna4DmkGr2IZAMnAF922nUT8G4XpyngfRFZLSK3dHPtW0RklYisKi8vP5RmdfGqVo2+y4ze7gJ7OBOMfYSZzcTTgA0/Pr/Z99fWNE07gvQ60ItIFPAqcIdSqq7D9p9jlXf+1cWppymlTgTOwyr7nBHsIKXUU0qpXKVUbnJycq/fQJdMP36k6xo9QHgcx/utco0higTqqNXr02uaFmJ6FehFxIEV5P+llHqtw/YbgQuBr6suloBUShUG/i4DXgem97HNvROo0XdZugEIiyXerG57miy1VDfpQK9pWmjpzagbAZ4BtiqlHuqwfR7wE+BipVRTF+dGikh062PgHGBTfzS8R6YfUwm2buJ8a4dsKyvQewe2XZqmaYOsNxn9TOA6YE5giOQ6ETkf+AsQDSwObHsCQETSReSdwLmpwDIRWQ+sAP6nlFrU/28jCOXH11NGf+r3IOdsyL0JgCRqqWrUgV7TtNBi7+kApdQyIFi0fCfINpRSRcD5gcf5wJS+NPCwmWb3nbEAky60/njqYdWzJEktNTqj1zQtxITszFil/DT5FIlRrp4Pdkah7OEkSS1VjbpGr2laaAnZQO9v8dJiGkwYEdXzwSIQlUKKUaczek3TQk5oBvrmGuzuSvarFMalRPfqFIlKIc1Wp2v0mqaFnJAL9G9vKKJgu7WkzjZGkpPSi4weICpVj7rRNC0k9dgZe1T56F5e+QBWSSm/cUB97ETCHLbenRs9giT1iR5Hr2layAmtQL/8cWYaZxBDEzUSQ0LqyN6fGz2CaFVPbV39wLVP0zRtCIRW6cYeRhheJhl72aZGkRYX3vtzo9MAMOtKMM2gk3w1TdOOSqEV6B3hhOFllJSS508j3HkIX1gCgT7BrKC8wTNADdQ0TRt8IRXolT2MMPEShpd65SLC2cv6PLQF+lSpoaC6eYBaqGmaNvhCKtBjdxGOB5f4aFbOQwz0IwBIlWrUhpep/O+v+GRHPyyXrGmaNsRCKtArexhx0giAGyfhhxLow+NRNhcpUs3IHc8TveZxbv/3SpSp16fXNO3oFnqBngYAmjnEjF4EiUljkr2YpPptOJWXf5g/w/2Hsfz+na0D1GJN07SBF1KB3rSHESdWoHfjJLy3Y+hbRacxi9UYWFn88cZuwr1V/H3pLrpYbl/TNO2IF1KBXtnaM3q3ch3aqBuA1GPaHnqUo+1xErXU6IlUmqYdpUJqwpRpC8MpVjbuxnFopRuAc+6lrkUoqHYzqnE9rooNAIyQKsrqPcRHOvu7yUF5fH6cNgPpbollTdO0XgqpjN60tS9J3Izr0Es3jnBiLv0Tk7/xFyInzG7bnCZVlNW7+6uZ3Wry+si99wPe21w6KK+naVroC61Abw9re+w+1OGVnc39DV9cugwIZPR1gzCJSim8Hz9AuLucguqgd2fUNE07ZL25Z2yWiHwsIltEZLOI3B7YniAii0VkZ+Dv+C7OvyFwzE4RuaG/30BHptEe6K1RN32oTBkGpxx/DMrmZIRUtc+WNf3grutjS7tQu5+4L/7AObZVeHx6WKemaf2jNxm9D/ihUmoycDJwq4hMBu4CPlRKjQM+DDw/gIgkAL8GZgDTgV939YHQH/wdSjeHPI4+GMNAotPItFVTUdsITVXw5ZP4/jyVRxdv7f+ROB5rQTUXXrw60Gua1k96DPRKqWKl1JrA43pgK5ABXAK8EDjsBeDSIKefCyxWSlUppaqBxcC8/mh4MAcG+kNcAqErMelk2mr4yrYfwR9HQ8kG7O5K3vzo0/5fE6ct0Pvw+nWg1zStfxxSjV5EsoETgC+BVKVUcWBXCZAa5JQMYH+H5wWBbcGufYuIrBKRVeXlh7f0gN/WXrrxGU4ctn7ogohJJ4sSjmn6EoCG3dZNTcZJITtKGvp+/Y5aA7206Ixe07R+0+tIKCJRwKvAHUqpA4rUyqph9KmOoZR6SimVq5TKTU5OPqxr+I32jF45IvrSnHbZp5NkVrQ9jarbCcAE2c/20n5eu95j/Vhd6ECvaVr/6VWgFxEHVpD/l1LqtcDmUhFJC+xPA8qCnFoIZHV4nhnYNiB8HQK9zXEIa9F356QbWZ55E4Uq8YDN44wCtpf0c6esrtFrmjYAejPqRoBngK1KqYc67HoLaB1FcwPwZpDT3wPOEZH4QCfsOYFtA6I10HuVDZfL1cPRvSTC1Bv+xF8mLzhg83gpYHvpAJVuaNE1ek3T+k1vMvqZwHXAHBFZF/hzPvAH4GwR2QmcFXiOiOSKyNMASqkq4B5gZeDPbwPbBkRr6eaw1rnpRpjDxu+vnIGKspYy3mRmM9YoIrX00/7NvAOB3ik+ndFrmtZvehxorpRaBnQ1F39ukONXATd3eP4s8OzhNvBQtLQF+n4acdOJxGdDQwn3+b7Ow3Gv8FjjA/z33WM4dfoMUqrXsCfxNMYmRx3+C3Qo3ehx9Jqm9ZeQmhnbWrpxK0ffx9AHE58NwGYzG+/Vr1JnT2DGqjtY+tdbsL10Jd95+F/BZ7T6fTR4fD1fv2NnrC7daJrWT0Iq0Ldm9M0DlNEzdjb7o46n0YgkNS0d3yVPkikVXGl8DMAcWcPnuyoPPKdwDeZ9aVxw94vsKuuhpt+xRu/z93/7NU0blkIq0PvEWl3S3dflD7oy5SrCv/0BL3xjBi67jbTj58AxlwFQqaI5y7aWL/IrwfTjbgkE6sLVGKaXMRSQV967QO9E1+g1Tes/IRXovdLeGRvWj52xHSVFuThtXFL7hgsfovGyf1I9+TpONHYydfsj+O9J5fRfLqCophmq8gHrXrRl9T3MpG2bMOXVpRtN0/pNSAX6lkCgT4yL5ZrpIwfnRcPjiTz+YnLm3YbfHs4N5mvYVAszjc18kVcJVbsBSKGG8t4Gej1hStO0fhRSgd4bKN2kJsZzXGbs4L54bAa28/5Aky0GgOnGNtbsq4bqQKCXasqDrGlf29zCJX/9jM1FtTrQa5o2IEIy0GPvp+UPDpFx0vVE/HwP5rhzOTNsB2v2VEL1HgBSJEhGrxRlnz7P9v2lLN5SqgO9pmkDIqQCvV9stCgbOMJ6PnigGDaM7Jmk+wqIKV8FPiuLtzL6ToG+cDXjPv8R19g+YnNBNaptwpQeXqlpWv8JqUDv8yvqiECFxQ1tQ469HL8jmkcdjwFQpuJIlZqDO2PLtgAw11jDrsIyJLAunIsWPWFK07R+E1KB3m8qbvD+H0253xnahsRmYrvwQVKklh1mBh/4TyBZaqlsaMY0OyzyWb4dsOr5Uxo/B6BGRRKmlynWNK0fhVagV4pNagxGVMpQNwWmXIn8ohRu/ZITTjoVO36i/PXUNLe0H1O2lWbCcIifPzv/xlZzJBsTzgnMjPX3/x2sNE0blgZgVtHQ8QeyZZvR1dI8g8zuYnyqC8aPg/VwnLGb4tpmEiKtTmNVtpX3/Cehxp+Hvbmclslf5RLfImTJ69iUH5+pcNiOkPeiadpRK6Qyep//CAv0rUadhi8qnRec95P91Hi+/+Bz5O0vQuqL2GFmYk7+Chfd8lsuO+14bE5rHX098kbTtP4SUoHeVEdooI9Kxv6dZRSd+AMw7FxU9282vPYAAJsZw+njO8y0Ddz3Vgd6TdP6S0iVbnyB0o3dOAI/vyITSb/41xBpcPanf4LqFbytTsOeM4eU6A7DQe0dAr0eYqlpWj8IqUDfWqM/EuN8m1NuxVe1l7dL4vm/wlN5/JRRB+63W0HfJfp2gpqm9Y8eA72IPAtcCJQppY4NbFsITAgcEgfUKKWmBjl3D1AP+AGfUiq3n9odlP9IzuhbRSRg/9rTXArMcbcQE+Y4cH8go3fi02PpNU3rF73J6J8H/gL8o3WDUurK1sci8iBQ2835s5VSFYfbwEPRWro50kr0XTkoyMOBpRsd6DVN6we9uZXgUhHJDrYvcOPwK4A5/dusw+M3TWyGYDXrKNUW6PVSxZqm9Y++1jhOB0qVUju72K+A90VktYjc0sfX6pHPVEfeiJtD1Vaj1xm9pmn9o6+dsVcDC7rZf5pSqlBEUoDFIrJNKbU02IGBD4JbAEaOPLy15E1TYT/qA70u3Wia1r8OO6MXETtwGbCwq2OUUoWBv8uA14Hp3Rz7lFIqVymVm5ycfFht8pkK29FctoG2cfROfHj93dw3tr4EvI2D1ChN045mfSndnAVsU0oVBNspIpEiEt36GDgH2NSH1+uR31TYjvYlA1pLN3QzvFIpeGo2u1+7m11l9YPYOE3TjkY9BnoRWQB8AUwQkQIRmR/YdRWdyjYiki4i7wSepgLLRGQ9sAL4n1JqUf81/WD+UCrdSDdLFdcWQH0Ryzft4Nw/fzqIjdM07WjUm1E3V3ex/cYg24qA8wOP84EpfWzfIfGbCuNoL904rLVuwrvL6EutL0ZO8bXNHdA0TevKETyz6ND5QiGjD09A2VykS0XXwytLrEDvwEdseJCx+JqmaR2EVKA3Q6FGbxiYsSMZJWV4WrrK6DcCVqDPjA8fxMZpmnbjcyt4f3PJUDfjkIRUoA+JUTeAkTiGbKOU0np38AM6ZPSJUa5BbJmmDW8en58l28tZuadqqJtySEIq0PtDYcIUIAmjGSVl7K8MMnzS2whV+YA1BNOnZ89q2qBp8lhDnhu93Qx9PgKFXKA/ohc066340YTjpq6y6OB9pVsgcBNxB35adKDXtMGhFOEvX8FsYy2NHt9Qt+aQhEBUbBcSSyAAJIwGQKr3HLwvUJ/fY6biEJ+ePatpg6WlibC9HzPN2E6jpz2jN02FeYSPfgupQN+6qNlRL94K9EneImqbWg7cV7KJFnsU+SqNcMOP139k/4JpWsjwWJMTo2imydue0Z/3yKc8/MGOoWpVr4RWoFdH4G0ED0d8Nj5bOFONXeyrajpwX+kmCl1j8BsOYpwKr+/oqhVq2lGrNdBLc1vppraphe2l9byxrhCljtykK7QCvWke/ePoAexOmjNnMsdYh+Pju7n70Sd4eeV+aKxAFW9gpTuLmMhInPho0Rm9pg0OTx0A0TS3dcbuKreC//6qZvLKG4asaT0JqUDv8yuMUAj0gHPiPLKMcibmPcNPK39G7tvnUPTIHEyfhyeaziQrORa70jV6TRs0gYw+kvaMvmHTu5xibAYUH2wtI6+8gfJ6z2FdvrzeQ0XD4Z3bk5AK9KYKgZmxAa5J8wBY4p/CsoizKDDSSfQW8bx5PmecOpP0hBjstOhRN72klNLLRQwDS3eUM/tPS3C3HHpJs7CmufvyS+fSjd/HrJXfZYHzPu6K/YDYtU/w6JOPc8/bWw6r7Y98uIO5D35yWOf2JKRuDu4zFWGO0Aj0xGWhrn8TX206J4wbRXSYA4fp5kabC8Mw4H9O7Cr016zPL28gPsJJfKTz8C/S0sxv/rOcd3f7WfHzs/qvccNMvbuFrz3xBb+95Fimj04Y6uYczDTZlr+P3RWNlNa5GZUY2etT91Y2MvtPS3j2xmlMH53AzS+s4mfnT+LYjNj2gzp0xjZ6/aiqPFqjzbm21WRUbyHFPI77iqYdVvOLa9ykxw3MTPeQyuhDZcJUKxlzJmedMJ7EKBdOu4E4I7DZbNatEm1ObMoX0rcbVO/exROPP8z9i7b16Tru127l29tvoqzePWBfjYfKpsJaFm0qHvgX8rdQ99ZdVJbs4/aX1g786x2OjS9zw4oLCcdNdefRaj3IK2/AVJBX1kDJB4+xKW8fy3Z1utW1x6rBR0szflPRUrwZgL1hExjdtAGn+MiRQvZUNHb7jWLJ9jLeWFvYaeP93FnwfdJjww6p3b0VcoE+VEo3PbI5sKkWvH7ziO7tPxQrdldR0+S1nngb4csnuKTlXTYVdXfv+S6sehbPS99gzeovcWx9nTSpYrSUsKM0hNbv9/u49LElfPvFNQP/WoVryNjyNNfYPqK41h20DKaU4ldvbmLF7gOXB3hv88E/9+8tWNvnD/CDVOzEZTaRLLVUt/4e9YangTFLvs8IKpGSDYxZ8RsutC2npNZagsRvKm56fiV7iqwP1Eis7S3FWzCVkJ86r+1SWVKOQ3nZVRa8Y9bt9fGDheu48+V1fJlfyYrdVby1vggKVzPGl0danA70PQq1jL5bNic204dSVsnqaOfbtojvPrmICx5dZm0o3YKgmGrsYk9pDc8vy+fDraW9v+C7d+Ha9hoT37oIG9a3nhNkJztKQifQ+585l+Wu2wbnxSp3ATDbtg6ANfuqDzqkrtnHP77Yy3udFvz68X/W8+eO48w3vUrzjiWs3nPwNfqkycrA42g4YP5JQ6dZrH5T8e7GYkxTsbuike898CTZJYuYY1uHvcpqZ5pUUlzbDEBpnZuPtpXx7mrr1tgR4sGGn5bizexVKTSlnNh2bUMUY6WIrcV1QZtY8vx1PNxyD9EuO79/dxt/W7KLP7yzFbOuiAg8ZEYNTPwKqUAfMjNje8PmxMCPgXn0d8i2uLG/dCWLXT+msKbZ+tpbsgGASPGwyX4tvkU/40f/WU+dO/Af+NVvsuThG7lz4TqoL2H/np3sbM0a64rA72GDGsvG6NPYN/dxlCuGU5x5bC9toNnr7zLjOmo012ArWkWSWAHF3eJnf1UTn+woP6zL9dh5GQj0x0s+idSyubDTtyzTj+vvp3Kx8TlVje3ZdMtnf2W8ZxObCtsDn7noZ1zje4Pyfiqj/W9DMbn3Lqaq3FoyJF4a2jL6RZuKOeG37/PRtkCS0FTFlqdv5of/+pz3Npfw0op9xDbvByBbSoiqywMgTaqsjL7FzYjHsvm67QOiaG57zUiasVVuY6fKxEg7BhB84dYtUCc5itkeLKForCSz6D1m2TZw26QmdpVUsb+8hprmFlStVcoZFdHFQsnWJgkAACAASURBVIZ9FFKB3jQVtlBY66Y3bNY69A6O3CGWSinW7qumptHN1574nDteWsuFj316cDZYb30ljpcGUqnio21lULKRFtrX2r/B9j4RTUU8viQPPA2oza9zUs0i3lm/D+/L81EvfpVrn15ufejlWyMX7vLOx3Pxk4w8/Rok40ROtu9ge3EtZzzwMWc99MnQjcL55AE2fL6IvZWNoBQ3PbeCpz/NP7RrbH697aFgUu/28dhHO/nOi6t7LOV1nNWpWtz8c8GLHH/3e2wusur9QafzV+6kBTuGKGbat1LWeQhhfTFh1TuYYuRR2RrolcKx+Ge84vot+6qarCzb24jRUEKK1FDRy2GIb64r5BdvbAz+virzSF/yA37s/gu79+4DII56q0ZfV0TL+3cT76/izoXrKa1zw6K7OK7oFWYb62jw+HhtbSHZYn0DGS3FJDTvBmAElRTXuqFmH4bfzX2OZ4mS9kAfK41ENOxll8ogPi4Bpl6Dfc5PQQxOiihnd8XBCxKam1/Hjh8/NubUv8n/qee5p/7X+LxubG6r3JXhHKJALyLPikiZiGzqsO03IlIoIusCf87v4tx5IrJdRHaJyF392fBgQuLGI71ls0ahOBj4Dtlmr59Pd5ZT1nHZZL+PgnUfcO2Ty7j6qeXsKqvnF29spN7dgqdsJ/98/b9sffgi7nn8ecL+lM0zxZdz1ua7KCws4LU1BWwoqGnPIuvbOxMvt33KZ7sqMEs2skaNo8oxgvXmGBDhkeS3eHZZPpVbPkLMFqKlmRPZhlG4kpG+PSQ27GDRphLY8ykNtjgKnGM4eUyideFJF5Hl28tjZdfzD88dgDrs8c4d7alobFtBtM7d0nN/SVMVfHwvzkU/4swHPqL+4elMyXucV9cUdnlKeb3ngLY+8sFO1n/yRtvzaJqpa3Kzp7SaJq+fuiY3+fuLWLhy34EX8jayYMHzTP7Ve9Q2W9+MChd8j+u238oZ5ioueHQZ335xDZ/sPPBbgcfnh8o81slEACa4qiit6/Szq7Gy4kSppaoxsK+5/QNdMNlcVAtVViBNkRrqPb6ev0ls+A9Vr9zJi8v38kVe5cH71/2LE6re4Ur7EnKw3m+8NFDb5MXz7s+5qG4BH0X8lGhvOfe/uw21/8u2Uz/dWUF5vYcxtjIARksJWT7rGtmOGsobPPhq2/9dsqW9dDhWirApP/tUCsnRLrj0bzBtPsSNIscopqi2/f/KR9tK+WRHOZ6Nb7DTzKAw7Swyq1dyorGTHKOIFGn/OaXag6xY2w96k/4+D8wLsv1hpdTUwJ93Ou8UERvwV+A8YDJwtYhM7ktjexIStxLsrY6BfoAz+oUr93HdMys49fcftXWWqk8fJPONy7mvaD7u3cspeeJS/rd8E6u+WILrb7lct/5aJtd9yh8dTxGmmllqTuEC+wruHvEZr60p5OK/fMZfP97Fc5/tprxod9trnRBWRElZGRRvYL1/NBsu/YDfJP+ZZenfILf+Q26Wt1j90Wt4ceDDxo8i38VuWoHlYtvn/POLvVCykW3GWKaMTMBpD/yK586nZeIlZEglk4z9xNBIUW3zQe+1S/Wl1C78Ntf85YO2D7zde/K496EHmXXP67y2poCT7llsfdB0p9DqOJ1o7Oc7treIrtvBOcYqthbXUd0YvAPx5hdWcv2zK6wPkfd+Tu7KO/E3tAedGGkk4os/cV+5Va+XV+cz5plJ/N+rGw5YZdHzwmVcvf12Eqllf1UT7P2CzPyXMZXwi4jX+aX9n4ThIa+sgfX7a1BKsa2kjuN/vQh/xS7WtIzCY4tklKP2wA99gFor0CdRS1VD4H10+AAfK0Vc8/SXrFizCoBEajEwD/oAm/fnpfxtyS6W7ijnnY3F8PYdfMP+Hj+z/5vnXnyB6fcuJvfexfxgodVXQGP7h1KsWMuFxEsDYdXbcW59nf/6TybSrOf+7FW8uXZf20KB8VKPY+9STjE2M8lpBfoco4ixRjGmElKpRClFfdnetuufYOxqezxJrPdboJJJ6nhPiNhMUqWqrb5P/hLeePNVfvKfddhL1vGlORFX+rG4GgsZK0XEU08a7Z3XCRK8tt9XPQZ6pdRS4HBW2Z8O7FJK5SulvMBLwCWHcZ1eG26jbqB1qeKBLUHsLm8gkVp8prJqrfWl+D99mLVmDiOllBfD7uc0cxXn2lZRkW8NvfvcPxmf4SLHKKJKRfFk8k+RrBnM8n7CC/ySk2Q7ozb/jeff/ogn3v4MgPXmWCY6ysgu+wjD9PKhnMzJ49N55dYzmDX/j3DMZfzQtpBT6hbxmX8yZYnTOKnFCpxbzZFcFfYla/aUYZZvZ517BMekdxgDLYLjiufhkr8BkCkVFNUcQqB/dT6xWxfgLFpudSJW5jHqhRk87XyQj9S3yHrjK2SaRVS/fz/XPvIWy/ODZJ8ARWswEYpI4keOVwCYIPuJpYEvd1eycOU+lmwvazs8v7yB9QW1bC2uY31BLez9jBzPFmL9NXgCpa04GnDuXcpYVUAYHmLy/wdAMrXtJQR/C67C5QCMkCqrLLHvcwD+6bqCbF8+8+3vMtPYxPL3XuKSvy7jkzVb4N9XMsXcis30slul0RIxgjSj5uBvQzVWQEyUOiobvfhNhaprD/QfuH7Cd21v8MkXVhtsokiktm24q9rwH2I//x3uqgIWvvcJdz/3Ot/912rMQEJzi/1//J3f8orjl1wTuYrX1hZa3wYaK/F3CmNx1DNz/1M0qDCWjvspMv5cTq15m8vi8tqOmWus4UH3r1jgvI+0lv1UqJi2fevUWBymmxgaaSq33lcDEQBUqygAJhpW5l8qKcSEdZiOFJNBgq+MmqYWmr1++MclPNr8UyIb9uBoqWcro0nIPhZBESYtOMRPjtH+rcHhqQn6a9NXfSlo3yYiGwKlnfgg+zOA/R2eFwS2BSUit4jIKhFZVV5+eB1KvlC4lWBvBf4DOAdhqeKT9jzJZ2G3k0Adm4tq8X54H/i9PJn4Exh/LpHKyqTOcmzAXZqHicF35OfYcm8AYKU5kakjE2HCecQ27WOasYNv2d/mq7XP86bzl4yQapqVk5328aS0FDDb+zH7GUHUmJMJc9iwGYJhM+DiRzGSx6Pis4m47DHSL7m7rY3PG5cS5yvnq7ZPMfwetpmZTE6POfCNGAakWOWHDKmguKaX9VB/C+z5FLBu2t7k9UPZFgzVwl0tN7N/3LUcK3t4MewBrql/jmnlr/HK6gKUUpTWuTFNhb+2mK8/+Snrv/yQfJXBJ6k3YGDiFSeGKE5z7CD73euo+O+veXxJHg0e699176LHuNn+P1x2YeHK/ajaAuJVDUlSS56ZDkCC1BNVux1DFFfalrQ1e6SUtq+/svP9tu0pUkNJbTOU76BMElmRNR/zK38H4OeRb/G0/X5myDZcm19iYt3n/MSxEIDtaiSuhEySqTy4Rh8o3SRJHTn+fObe9yafrN5wwCE/dr3OmfaNB7SjIpD9+9//FTear7HY8UM+cf2Al5z3kEQdRnMV97Rcy+fnvw8XPMRIVyO31z+MYFJY0wxNFWyTsQe8zkxjM2f4l/O073zuvHgGnPxdpLGMP/j+SI0Rh0I4wb4HgCZlZeMb7ccC4FEO3gm38tE0qaKudC/1RixbHMcAUKKsiWITAhl9S1SGNa+lVWwGkd4KDEyKqts7ZO+0Wx/q9fHH4kiddEB7J0qHElvTwNy56nAD/ePAWGAqUAw82NeGKKWeUkrlKqVyk5OTD+saftMMiVsJ9kqH0s2Ajrqp2s28mpcIw8sFUTso370R+7oXedE3l29fdi5yxo9RcaOoGXEqp9s2E9e8hwojifTEWGT0GQCsMCcybXQCTLgAAnMJpzoLAIiTRsZJISUqnuqIUbj8jZxm28wbvpM5+5gRB7bFFQ3f+pSY73/OjBOmwMiTIfcmliRejW3SBeCI4GeulwHYYWZyTOdADxA7EoDR9qrel272LGt7GC8N1qiSWqv9S20zGPv1h3FOuZwMZZVt5hhr2b11NYvvvYSbfv80L3yyBdvDE3m46FqyGzewN3wi0y69FRLH4Tz9drC5mB+3iomNKzmVDaQWf8hjf32Yy37zNGfk3c8v7P/iweR3WbWrEGksxyl+YqWJfJUGWCNhXKb1XjoG+lFGWXtGv3Nx2/Y0o4biWjdm2Ta2+9PJGRGPMeUKiB/NmJadgXNLyNhr9QPkGjtwKweOjCk44jKI91VQ1ejF6zPx+Pzc/MIqivdZ5yVQx6vOX/N1z0KKC/YAcJ79abh9A2JzMk21dfWRIjU899luzrp/EVJfzOv+mTRnnApAstQx2bDO36JGkZVznFUDn3kHNtNDKtUUVDdDYwV7/Ek02du/veUYRZhKWJJwuTXTdMwsmPp1bL4m4s77JRI3kjhljRq6Lfx3kDmN2d96mIbcW5nteZDTp1vDJXPjGinan88+XxxFEVZwrgtk9hON/ZSoeGKjO82+jcnAUH5SqKa6sP0bxEU265vMzZefDwljQNpD7yRjH83KSZMRCU1dfBPso8MK9EqpUqWUXyllAn/HKtN0VghkdXieGdg2YIbXOPr2UTeegczo1y/Ahg+3EcHZYduYXPgyLRgsz5rP1Kw4yMxF7thA3BnfweVvZI6xll0tSYxOioCcs2DGt/naN+7kwuPSICkHvrscMqeT4m+vMZ9pW08Z8dSEj2zb9oGaxjmdAz2A3Wll5q0ufJgzv/cEv7vyZDj2cmJM6z/wTpXB6GBT4COTwB5OTlhN70s39e119zjqrVEltQV4xUVEbAoigi33GwDUuNI5ztjDq+adnOP/hLsjXmH5cuuDIkVqiIyJZ+71vyAnLRFuWwlzfgE5Z3Fi/RIAxkohj/IAP627lwW2X9FABO606cx0L8FXXXBAs/ICgX6msblt22RjL5vNUSiEY8KryS+3Ar0vfymf+q2sdXRYAyU1TaiKHewy0xmfGm2dnHZ823XmGmsZ6d9Hg7Im8KxXYzltYgbEpBHZUomBSUWDh883bOeDrSU0lVn9LDaxShK5xg7MumIaJBpb7AiIHwVXL4C4kdROuAKAVKnm1L1/43b349hEscg/jYgb/gMX/yXQBqsst9eWTUbr0gCBm/KMlDIKqptQjeWUmTE0hFnfbtzK+n+Rr9KYOKpD+Dn/AbjiH3DijRBhZeVNykV97CS4+QNImUjUhb9j6X3XMevkk8Eezr3mn5lrW0uxSqAqzvrZJdE+rHR/5/o8QGym9aOUKppKrDH5D/mvtPY5ozg+OxXsrrZ7TgBMkn2UqHiaHfFHVqAXkbQOT78CbApy2EpgnIiMFhEncBXw1uG8Xm8Nqxq93foFc+Cj0TNw945tKVhLnplOccIMpnpXM8u7lMX+E7n89BMOPHDMLJTYiBQP+1SKtc6IIxzOu5+JOTntq4qmTLQyGsCnDHZKNgClKp7ltXEAFKsEorNzSTjU9W3O/m3bwxtmHRN8JVMRiM0k2xYYPtfB3spG7l+07eBSWPOBoyKqGj1Qs48ySSYj3srwGDkD5n9A3I1WmaNSxbJx5HXk+tcyo/EjAG5z3oP9+2sg/YT2tgCceF3b9WMCQ/gKVSKlmefS9JV/EjZuFnHugrZhgK3yTeu/4UnGDkzV/l63qSyawlKZ4KrkrfVFPPzaJ9ir81hqHo/PFUeWow5v1T5sviZ2qkwmjAgE+hHHtV3jTJtVdnlDZls/gtST+FpuJkSnYSg/idRy1f0LOOWtWTwS/jSj7FU0hbV/ME+WPaSrUgr9sSS3BsMxs+COjcR+7a8AfNP2P26zv8lFagkAKeNOwm4zIDEHgHNtqyhXMYzKGtn+bxmfDcBoWxlFlXWIp44qFY03yqoK71ZWGzapbI7P6tBH44yEyZeAzQ7hVqAvVXGkxB64tozdZljJwPz3EJd1folKYL1pBebItPGowLfSYpV4cJIVY33gpEklZoX1LWd14oXwjXfh+g7hL/0EiEwBrCUV9qlUfK4hDPQisgD4ApggIgUiMh/4o4hsFJENwGzgzsCx6SLyDoBSygfcBrwHbAVeVkptDvoi/WR4TZiyMhcXLVz/7Ar++N72gXmd4vVsUqOpHXUOMd5SEqUe50lfZ+7ElAOPC4tFsqwvdvtUCgkR3QTp+FEAFKlEFsVa2U6Ws4GbL5wFzigqs87mznMmHHpbIxLg1hXwzY+467yJXR8Xm0kaFRQFavS1TS18uLWUf3+5j8eX5PH7d7fyzsZilFLsr2riw7XbUQjFKoF0ZzNVjS1QW0CBmXDgIlRZ06ys+Kb3iP7JRo676rcom4sb7O9bmfGoU8ERZIp7ztkQm4UKfAAC3O6/k8wbnyVtylxInogok5nGgflUsUrEtIfjFB9b1UhaxPqd2GOOwBc7ilGqkCttH3P6+h8DsMU1BSN6BGlGLRG1VlmhOiKbscmBbz5ZM6y/w+Nx4cWjHKxIuBgMO2eefxVpseEQbX24jJQy5tveIQwvl6iPseMnYnr7B5ZLfMy2radUxZMS3ek9250QnsBYo5itppV1K2cUv73hAmt/INCPkGpWmhM555jUDv92WSA2JodV8dqy9QBUEYM/xrqOx2EF503maI7ruCBZRxHWkNsy4hkR08WSA2lTYObtAKRG2bly1olw/VuMuOF55Jx7AHCPOInrThl14Hkx1gfOWFcNe3ZspF6FM+ekY61/+8yT2o+78GGY/17b030qxWpX88DU6HtcvVIpdXWQzc90cWwRcH6H5+8ABw29HCjrfnUOw2W+VHuN3hqHHGyCRp81lOFoKmWzeRZjplwN47KheD3nnPF1CPaBmjMX9n3BfpXChTlJXV83zvrPsU+lUJw5DzJ3cULuTZCdCWkfcWxMulWPPxzJvfiAiMsicf96Kho87Kts4pll+fzni+3Mi9yBnck899kenvtsD/++eQbffnE1P/QVUu+IopZYkmwNrN1XTYUvj93+E8mMD7La4MiTaf2YkwnnYdvyBpUROXzzjJzg7bHZ4VtLEXctPDqVFuyEZR1PmMNm7U8aD8As48DOzUpiIDwe6pvZbGaTEeEjzl3IbpWGM1HIKv0P9zu24I/LRqVdxAuXzcdY8C5JzeWMaVxLi83GiPG57Z2Jo8+A29fDx7+DDQvZpdJxpR0Dt+yGsEB/R4wV6F91WR3he9PPIyUzh/DJ86xAtfQBqlQUCWJ1AofFp3P9qZ2CIUB8Ng0SScHcV5j0xXVIZAoYgfcbmQSuWPDU8rE5ldsndwj0NgfEZnJO/WfE2qxKcIWKwTdqCjSsY6phhwK46Ky5HJ8ZF/znHdGa0ceTGuMKfgzASTdC5S7OnjYfkpOAWdb2U78HJ3+XK8Ro/1bWKjweHBHMjKknono/zRHZ3HTa6M5Xtn6ermgQGyg/e1UqtigPlOcdfGw/CKllisOdtqFuwuAJBPq/OB/hEd/l7HJf2a+XL61zs+mTxcwFNqvRfDs+AkaeDxODzo2zHHMZbHyVR6+5BYkP0hHaKpDR7yeF7JRYOOPZ9n29CdR9lXosEWv+wSRbAUvf+Tdz8v5Nij2DW/1vcU9kLN6IVC6q/xkvvPoGOZ564uyNVJmRNNpjSKCBhsYGksJqKVKJjIzuJlAAHH8lbHmDUZOnMSqri8ADVvAJjwdXLL7okdxzeW77vqRxgDDOsDqtk2zN2E03TY54jIgEqC9is8pmbmQDuAtpiskmbPKJULYB5v4K28QLQMT6zx6dRmzRds41KvjCnMypxxw4YoX4bCtrBrarLHJSotqDPEDiOIgfjSfpGJwjJjIq9xttdWkarbLDl+YkMhJjON5RyPTZ10J6kMz6in8Q5Qjn7MgkGPvqAZ2TiEDiWChag3/s2WS2lsdaxaSTVvMFl9qsJQ+qVAzOSfNg5mWw6jkoWMmU6Wd2/bMO7xjou1lEzO6E8/8YfJ/RRawRgcQcTi4JzFw+6f8O/jDoeGxEAjSWs0+lYM/JgZS04Mf2UUgF+mElULpJljqmGdtZ12nhpr56efFn5K77Cy2GjdwZZ1iz/3qSOBZuXU6PxbNAnfW0adNImBEk2xtox34V3vs5P0taxuhdn5MpFcwIDPtryjqd5D1vszDifjKatoIL9pnJVKkY3I44st1L2R52IwBRKdmcMjax+9fKOcsqzUzuxRQSETjlu4THZjE6qUNHsiMcsOZKxI4+EXttHv7qfUTEJEKY9eGxxRyFLa4GKlfz+Pe/hkTEwrGXHfwaUalEuYuJMmBl6te5eFyQb15xVqDfYWZyalqnD+ywGLh9HUF/G8LjITyBs0+9EGPm7cG/9XV6DevxyIP358yFmHQeuuqcrq8RUEV0e39O7jfgxOu7DsTQltFXGwnMDjYyq6+ufQ02vWJ9AE68sPtjIxKhsZxCSSV6ehfflPuBDvRHK1t7DTwCN/Xufgz0q5/nextvx2ezUTn3QX50+oz+uzZY/wG+8iRZOWeDawh+BSMTYeL5nL7lTRDwiosw5WFB7M185et/hOfmklG0Fp/hwm56GGmUk+9PRznjEHf75LRvXf1V6JxtdmZ3wrWv9L5tZ3axUsgpt0HhGsK/9hS8dA14GnnsmlxYagX6rWokEROTwXDjiuiiNg1tNWTs4Vxx3XfBESQgBvoKLj9/HjnBPgi6YhjwvdXYXTF9D1hzftH1vgsegv3L4e07AbhmzolEdvw96i7IQ1ug/8nXZkPKYZYIuxOVDCd/p3fHBvoLJGH0gPYv6kB/tOoQ6CNx09CPgd7c8xmVKo5/T36C208/r9+ue4ApVw3MdXtr7q8heSKkTcGZvwRWPMXV137LCnzTb4G3vo/9yn/AAqskVkskkS5rXmCFiuEn2a/ybMqkbl6gn517X/vj5AnYDLs1ISxtCkXFhUwakYFz2qkw7frurzPlSnBFwfh5bQHvINmnwzUvMy7n7K7LDl3p6pr9KXWy9WfXh7DtbebPPbHnczoK9BHRofN7yEQkYEam8Mw3zxzQl9GB/mhla1/ZMULc1B9q6aapiq17C8lvSeKC46264OItpXy0rZRfF29hszmKjJzjerjIUSxxLMz+mfV45CmQfRokW52eTLkaxp0L4XFg2MH0UaMiiYiwAv1uNYLUAboTUK+c9wCYgX/vWT8hfdZP+E9vzw2LhanXdH+MCIw/ty8tHBxfex6aazjkERiZuXDryvZ/76E08w6M44q67yvoB8NljEroOSCj97TNUuzO62sL+OY/VvG/DcWY/72DsAWXc+u/16CUwly3AHPBNSxcsRd71U52qgyOz+ymBBBKIhIOrKGLWOUdw9Y2LrqGKMKc1s98n0rl/OMGptOsVxxhVlY+3NkcVpnkcBwJQR6sD53JFw/4y+iM/mjVsUYv1njwBrcPV1TX9cmXVxbwRX4luwrLOdf3PqONZsLwWGt3f/4859pWMcWXh930sM/IZGyyDibEZkHNPmpVFEa0NXfggq9cS9i4wwwwmjYEdKA/WnUo3bTew7Le7SOx85TsVp8+xP0lT7PAdjo7GzKxO6wZmKOklH1l1Uwut1advNhmrWhoS504fCafdSfQeVmjImkccwGcdAJhGSf1cJKmHVl06eZo1WnUDRx8b8wDbH+XkWYh19vf50xZ27Y5W0qoyV+FU1mrEX7VvhSAlDFTBqDRR6HAGPEaooiPcoEO8tpRSAf6o1WHQO8UPw587fdTDUIFbgKRKtVMMfLYZGYD1l11Kjd9CIDXEUM0zWw0szkuZwjGtx+JAoH+xAmjOTbYxB9NOwroQH+0Mg6sukV0N8RSKagvoVglYKA4RvaywRxNszOBU5z5nFn1MivMCdhd1pjwx/1f4YSRwW4xMAxlnw7pJ3LbFRcMr5nXWkjRgf5o1Wl8cyTurks3TZWI2cIq0xppYIhit0pDhScyS60gmib+m/kjjIsewT35a9xw061EDcVEpiNR8ni45WNr1qemHaV0oA8REdLN7NhA2WaF2b6i426VhhptLdJ0Z8ut3PLVC2HCPMKueJoZY/WIEk0LJTptCxHdZvSBG2dsNrNR9nDE10yhkU74eT+i9vSf8AMzkqyEHqbya5p21NKBPkTE2r1dd8bWWav8lap4VPwoVPkOxoyfjOGKINYVge5i1LTQpks3R7Mf7oAbreX+Ex0tXXfGBjJ6b3gyRtI4jMQx/PX6UwerlZqmDTGd0R/NolPBY91pPsHhpbybGn2dEUdcVBTM+wN4GgaxkZqmDbUeA72IPAtcCJQppY4NbHsAuAjwAnnAN5RSNUHO3QPUA37Ap5TK7XyM1kdOa93yBEcLu5qDl27cpTso8MUya3xy+00iNE0bNnpTunkemNdp22LgWKXU8cAO4KfdnD9bKTVVB/kBEgj08fYWaoIF+r1fEFbwGe+r6cw/PcgtzTRNC3k9Bnql1FKgqtO29wM3/wZYDug0cagEAn2c3Uttk/fg/Z/9mUpJYNvo662bO2uaNuz0R2fsTcC7XexTwPsislpEbunuIiJyi4isEpFV5eXl/dCsYcKwgT2cGCOwCmUnZvEGPvFNZnzWiCFonKZpR4I+BXoR+Tnw/+3dfYwVZxXH8e9vF3bBvVsBIVveqqwWKUZtkTRtRP6othYSxRcSMY3WpIlGa6ImxmBqmvqnGjUxNWJNG2uDfRfbxGpEJbGaCraW1xLKglShtEhbKI3yusc/5lm4Xfcu3HVh7jz7+ySbO/eZWeacPXcPd56ZvXMSWN1gk0URsQBYAtwsaXGjfysi7oiIhRGxcNo0/8FOUzq6qLUd49WjJzjVf+ZWdxw7QtuR5+nrn8H8wff+NLMxY8SNXtJnKE7S3hARMdQ2EbEvPR4A1gBXjnR/NozOGjX+U3ykTf219C/1AbArZvKO83ETZDOrhBE1eknXA18DPhwR/26wTZek7oFl4Dpg60gDtWF0TaP75CsAHKqfvjm4E4AXOmYza7Ln583GqrM2ekn3Ak8Ab5e0V9JNwO1AN7BW0kZJq9K2MyQ9wLwyAgAABdhJREFUlr61B/iTpE3ABuBXEfGb85LFWFfroet4cV7jdVfeHHyWU7Rx0Yy5qNmbPJtZNs56HX1EfHKI4TsbbPs8sDQt7wZ894oLoftiJhx9HIBDdVfeHN2/nX39PVw9t8T7m5pZ6fwRCDnovphxxw/TyXE+d89TfOLHT7Bt70H03J/ZEnOKP5QyszHLjT4HteLSyV923MpjbV/h+J71PPzgz+k8/gqPd7zPV9yYjXH+rJscdBeN/rK2fwDwnYk/5emXL+FI+0TGzb3W8/NmY5wbfQ5qPacXN/X38m52M6ttL4+cfC+L5s0sMTAzawWeuslB95m/ev3+yeUATNAJVvd/gEVvm1pWVGbWItzoc/CGqaB2jrXX+NDHPgU97+SZcZfRMfs9TO7qKDs6MyuZp25y0NYGtR46p/Ty8YWXwLw1THrtBLdPnFJ2ZGbWAtzoc3HNN+CidL18bRozauWGY2atw40+F1fcUHYEZtaiPEdvZpY5N3ozs8y50ZuZZc6N3swsc270ZmaZc6M3M8ucG72ZWebc6M3MMqcG9/UulaR/Ac+N8NunAgdHMZwyOZfWk0se4Fxa1UhzeXNEDHmXoZZs9P8PSU9GxMKy4xgNzqX15JIHOJdWdT5y8dSNmVnm3OjNzDKXY6O/o+wARpFzaT255AHOpVWNei7ZzdGbmdnr5fiO3szM6rjRm5llLptGL+l6STsk9UlaWXY8zZK0R9IWSRslPZnGpkhaK2lnepxcdpxDkXSXpAOSttaNDRm7Cj9IddosaUF5kf+vBrncJmlfqs1GSUvr1n095bJD0gfLiXpokmZLWifpGUnbJH0pjVeuNsPkUrnaSJogaYOkTSmXb6bxOZLWp5jvl9SRxjvT8760/i1N7zQiKv8FtAO7gF6gA9gEzC87riZz2ANMHTT2bWBlWl4JfKvsOBvEvhhYAGw9W+zAUuDXgICrgPVlx38OudwGfHWIbeen11onMCe9BtvLzqEuvunAgrTcDTybYq5cbYbJpXK1ST/fWloeD6xPP+8HgBVpfBXw+bT8BWBVWl4B3N/sPnN5R38l0BcRuyPiOHAfsKzkmEbDMuDutHw38JESY2koIv4IvDxouFHsy4CfReEvwCRJ0y9MpGfXIJdGlgH3RcSxiPg70EfxWmwJEbE/Iv6Wlo8A24GZVLA2w+TSSMvWJv18X0tPx6evAK4BHkrjg+syUK+HgPdLUjP7zKXRzwT+Wfd8L8O/CFpRAL+V9JSkz6axnojYn5ZfAHrKCW1EGsVe1Vp9MU1n3FU3hVaZXNLh/hUU7x4rXZtBuUAFayOpXdJG4ACwluKI41BEnEyb1Md7Ope0/jDwpmb2l0ujz8GiiFgALAFulrS4fmUUx22VvBa2yrEnPwLeClwO7Ae+W244zZFUAx4GvhwRr9avq1pthsilkrWJiFMRcTkwi+JIY9753F8ujX4fMLvu+aw0VhkRsS89HgDWUBT/xYFD5/R4oLwIm9Yo9srVKiJeTL+Y/cBPODMF0PK5SBpP0RhXR8Qv0nAlazNULlWuDUBEHALWAVdTTJWNS6vq4z2dS1r/RuClZvaTS6P/K3BpOmvdQXHC4tGSYzpnkrokdQ8sA9cBWylyuDFtdiPwSDkRjkij2B8FPp2u8LgKOFw3jdCSBs1Tf5SiNlDksiJdFTEHuBTYcKHjayTN494JbI+I79WtqlxtGuVSxdpImiZpUlqeCFxLcc5hHbA8bTa4LgP1Wg78IR2Jnbuyz0CP4pnspRRn4ncBt5QdT5Ox91JcIbAJ2DYQP8U83O+BncDvgCllx9og/nspDptPUMwt3tQodoorDn6Y6rQFWFh2/OeQyz0p1s3pl2563fa3pFx2AEvKjn9QLosopmU2AxvT19Iq1maYXCpXG+BdwNMp5q3ArWm8l+I/oz7gQaAzjU9Iz/vS+t5m9+mPQDAzy1wuUzdmZtaAG72ZWebc6M3MMudGb2aWOTd6M7PMudGbmWXOjd7MLHP/Bc/Snwi2z/w3AAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nloss_model plot (blue: train | orange: eval)\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"ma4fd9b6a9f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#ma4fd9b6a9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"96.218236\" xlink:href=\"#ma4fd9b6a9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(89.855736 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.115165\" xlink:href=\"#ma4fd9b6a9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(137.571415 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"198.012094\" xlink:href=\"#ma4fd9b6a9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(188.468344 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.909023\" xlink:href=\"#ma4fd9b6a9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(239.365273 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"299.805953\" xlink:href=\"#ma4fd9b6a9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(290.262203 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.702882\" xlink:href=\"#ma4fd9b6a9f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(341.159132 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m5e44690a98\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5e44690a98\" y=\"210.743923\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(7.2 214.543142)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5e44690a98\" y=\"176.449556\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 180.248775)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5e44690a98\" y=\"142.15519\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.2 -->\n      <g transform=\"translate(7.2 145.954409)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5e44690a98\" y=\"107.860824\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(7.2 111.660043)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5e44690a98\" y=\"73.566458\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 77.365676)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m5e44690a98\" y=\"39.272091\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.8 -->\n      <g transform=\"translate(7.2 43.07131)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#pbcf63343fd)\" d=\"M 45.321307 17.083636 \nL 46.339245 77.716076 \nL 47.357184 102.870994 \nL 48.375123 117.103156 \nL 50.411 136.856711 \nL 51.428938 143.475523 \nL 52.446877 148.362471 \nL 54.482754 156.370205 \nL 55.500693 159.50814 \nL 57.53657 164.600853 \nL 59.572447 167.550168 \nL 60.590386 168.767618 \nL 62.626263 170.773839 \nL 66.698017 173.56883 \nL 71.78771 175.849405 \nL 72.805649 176.072318 \nL 74.841526 176.981119 \nL 76.877403 178.232864 \nL 77.895341 179.073076 \nL 78.91328 180.119054 \nL 79.931219 180.530586 \nL 80.949157 181.593711 \nL 81.967096 181.165032 \nL 82.985034 181.387945 \nL 84.002973 178.232864 \nL 85.020912 181.267915 \nL 87.056789 180.736352 \nL 88.074727 181.319357 \nL 90.110604 183.274135 \nL 93.16442 185.07459 \nL 94.182359 184.268672 \nL 95.200297 178.267158 \nL 96.218236 179.65608 \nL 97.236175 184.320114 \nL 98.254113 180.924971 \nL 99.272052 182.451071 \nL 100.28999 182.502512 \nL 101.307929 183.051222 \nL 103.343806 184.388702 \nL 104.361745 185.931949 \nL 105.379683 186.29204 \nL 106.397622 186.772161 \nL 107.41556 186.755014 \nL 108.433499 186.909338 \nL 109.451438 187.715256 \nL 110.469376 187.012221 \nL 111.487315 187.115104 \nL 112.505253 187.389459 \nL 113.523192 188.692645 \nL 114.54113 188.898411 \nL 115.559069 188.812676 \nL 116.577008 189.189914 \nL 117.594946 189.807212 \nL 118.612885 190.818896 \nL 119.630823 190.047273 \nL 120.648762 190.990368 \nL 121.666701 190.030126 \nL 122.684639 190.938926 \nL 123.702578 191.504783 \nL 124.720516 192.996588 \nL 125.738455 192.996588 \nL 126.756393 191.299017 \nL 127.774332 192.259259 \nL 128.792271 194.899926 \nL 129.810209 195.17428 \nL 130.828148 195.17428 \nL 131.846086 196.631791 \nL 132.864025 196.443172 \nL 134.899902 198.620864 \nL 135.917841 198.020713 \nL 136.935779 199.392488 \nL 137.953718 200.421319 \nL 138.971656 200.438466 \nL 139.989595 200.987176 \nL 141.007534 201.398708 \nL 142.025472 201.535885 \nL 143.043411 202.11889 \nL 144.061349 201.227236 \nL 145.079288 201.655916 \nL 146.097227 202.496128 \nL 147.115165 202.736188 \nL 148.133104 203.507811 \nL 150.168981 203.662136 \nL 151.186919 204.330876 \nL 152.204858 204.313729 \nL 153.222797 202.976249 \nL 154.240735 204.502348 \nL 155.258674 204.759556 \nL 156.276612 204.639526 \nL 157.294551 205.291119 \nL 158.31249 205.736945 \nL 160.348367 204.810997 \nL 161.366305 204.896733 \nL 162.384244 204.536642 \nL 164.420121 204.896733 \nL 165.43806 206.422833 \nL 166.455998 206.508569 \nL 167.473937 206.371391 \nL 168.491875 205.874123 \nL 169.509814 204.79385 \nL 170.527753 205.754092 \nL 171.545691 205.959859 \nL 172.56363 205.119647 \nL 173.581568 206.748629 \nL 174.599507 205.205383 \nL 175.617445 204.00508 \nL 176.635384 206.045595 \nL 177.653323 204.142257 \nL 178.671261 206.079889 \nL 179.6892 205.685504 \nL 180.707138 206.114183 \nL 181.725077 207.331633 \nL 182.743016 207.297339 \nL 183.760954 206.851512 \nL 184.778893 207.160162 \nL 185.796831 207.160162 \nL 190.886524 208.103257 \nL 192.922401 206.43998 \nL 193.94034 205.256824 \nL 194.958279 206.491421 \nL 195.976217 202.547569 \nL 196.994156 205.085352 \nL 198.012094 204.313729 \nL 199.030033 203.164868 \nL 200.047971 206.885807 \nL 201.06591 204.176552 \nL 202.083849 206.971542 \nL 203.101787 205.616915 \nL 205.137664 207.828902 \nL 206.155603 207.966079 \nL 207.173542 208.240434 \nL 208.19148 208.034668 \nL 209.209419 208.051815 \nL 210.227357 208.32617 \nL 211.245296 208.99491 \nL 212.263234 208.703408 \nL 213.281173 208.789144 \nL 214.299112 209.097793 \nL 215.31705 209.11494 \nL 216.334989 209.732239 \nL 217.352927 209.646503 \nL 218.370866 209.800828 \nL 219.388805 209.54362 \nL 220.406743 209.955152 \nL 221.424682 209.646503 \nL 222.44262 208.789144 \nL 223.460559 209.440737 \nL 224.478497 209.200676 \nL 226.514375 209.595062 \nL 227.532313 209.509326 \nL 228.550252 208.120404 \nL 229.56819 209.097793 \nL 230.586129 208.103257 \nL 231.604068 207.743166 \nL 232.622006 203.422076 \nL 233.639945 207.314486 \nL 234.657883 207.605988 \nL 235.675822 206.217066 \nL 236.69376 207.77746 \nL 237.711699 208.583378 \nL 238.729638 208.171845 \nL 240.765515 209.629356 \nL 241.783453 209.612209 \nL 242.801392 210.195213 \nL 244.837269 210.349538 \nL 245.855208 210.435273 \nL 246.873146 210.726776 \nL 247.891085 209.766533 \nL 248.909023 208.960616 \nL 251.962839 210.675334 \nL 252.980778 210.949689 \nL 253.998716 210.778217 \nL 255.016655 211.155455 \nL 256.034594 210.863953 \nL 257.052532 209.526473 \nL 258.070471 210.726776 \nL 259.088409 209.766533 \nL 261.124286 210.366685 \nL 262.142225 209.886564 \nL 263.160164 209.955152 \nL 264.178102 210.743923 \nL 265.196041 210.76107 \nL 267.231918 211.515546 \nL 268.249857 211.326927 \nL 269.267795 211.54984 \nL 270.285734 210.983983 \nL 271.303672 209.989447 \nL 272.321611 210.075183 \nL 273.339549 211.224044 \nL 274.357488 211.412663 \nL 275.375427 211.035425 \nL 276.393365 211.42981 \nL 277.411304 211.292633 \nL 278.429242 211.601282 \nL 279.447181 211.601282 \nL 280.46512 210.521009 \nL 281.483058 205.959859 \nL 282.500997 209.372148 \nL 283.518935 210.023741 \nL 284.536874 210.075183 \nL 285.554812 210.366685 \nL 287.59069 212.081403 \nL 288.608628 211.652723 \nL 289.626567 211.652723 \nL 290.644505 211.412663 \nL 291.662444 212.270022 \nL 292.680383 212.149992 \nL 293.698321 212.887321 \nL 295.734198 212.52723 \nL 296.752137 211.481252 \nL 297.770075 210.795364 \nL 298.788014 211.155455 \nL 299.805953 212.09855 \nL 300.823891 212.612966 \nL 301.84183 212.4072 \nL 302.859768 212.475788 \nL 303.877707 212.921615 \nL 305.913584 213.333147 \nL 306.931523 212.990204 \nL 307.949461 213.796121 \nL 308.9674 213.230264 \nL 309.985338 212.441494 \nL 311.003277 211.326927 \nL 312.021216 211.412663 \nL 313.039154 212.870173 \nL 314.057093 213.264559 \nL 315.075031 213.041645 \nL 316.09297 211.446957 \nL 317.110909 212.149992 \nL 318.128847 212.475788 \nL 319.146786 211.789901 \nL 320.164724 213.178823 \nL 321.182663 212.218581 \nL 323.21854 213.110234 \nL 324.236479 213.384589 \nL 325.254417 213.247412 \nL 326.272356 209.646503 \nL 327.290294 211.001131 \nL 328.308233 212.612966 \nL 329.326172 207.77746 \nL 330.34411 209.012057 \nL 331.362049 211.944226 \nL 332.379987 210.09233 \nL 333.397926 213.333147 \nL 334.415864 211.892784 \nL 335.433803 213.298853 \nL 336.451742 213.607502 \nL 337.46968 213.778974 \nL 338.487619 212.578671 \nL 339.505557 213.881857 \nL 340.523496 213.796121 \nL 341.541435 214.379126 \nL 344.59525 214.756364 \nL 345.613189 214.584892 \nL 347.649066 212.424347 \nL 348.667005 213.641797 \nL 349.684943 213.350295 \nL 349.684943 213.350295 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#pbcf63343fd)\" d=\"M 45.321307 77.527457 \nL 46.339245 101.636396 \nL 47.357184 116.657329 \nL 49.393061 137.28539 \nL 50.411 143.612701 \nL 51.428938 148.482501 \nL 53.464815 156.370205 \nL 54.482754 159.542434 \nL 56.518631 164.206468 \nL 58.554508 167.498727 \nL 60.590386 169.419211 \nL 61.608324 170.276571 \nL 63.644201 171.665492 \nL 66.698017 173.448799 \nL 68.733894 174.254717 \nL 69.751833 174.820574 \nL 70.769771 175.146371 \nL 71.78771 175.180665 \nL 73.823587 176.072318 \nL 74.841526 176.67247 \nL 75.859464 177.118297 \nL 76.877403 177.992803 \nL 77.895341 179.021634 \nL 78.91328 179.124517 \nL 79.931219 180.016171 \nL 80.949157 179.244547 \nL 81.967096 179.433166 \nL 82.985034 175.060635 \nL 84.002973 179.090223 \nL 86.03885 178.387188 \nL 87.056789 179.021634 \nL 89.092666 181.559417 \nL 90.110604 182.193863 \nL 91.128543 183.051222 \nL 92.146482 183.719962 \nL 93.16442 182.571101 \nL 94.182359 173.928921 \nL 95.200297 175.45502 \nL 96.218236 182.245304 \nL 97.236175 178.421483 \nL 98.254113 180.187642 \nL 99.272052 180.479145 \nL 101.307929 181.525123 \nL 102.325867 182.468218 \nL 103.343806 183.942876 \nL 105.379683 184.440144 \nL 106.397622 183.960023 \nL 107.41556 184.011464 \nL 108.433499 184.903118 \nL 109.451438 184.491585 \nL 110.469376 184.440144 \nL 111.487315 184.868823 \nL 112.505253 186.377776 \nL 113.523192 186.326334 \nL 114.54113 185.726183 \nL 115.559069 186.051979 \nL 116.577008 187.355165 \nL 117.594946 188.17823 \nL 118.612885 187.440901 \nL 119.630823 188.29826 \nL 120.648762 187.303723 \nL 121.666701 188.29826 \nL 122.684639 188.829823 \nL 123.702578 190.493099 \nL 124.720516 189.961537 \nL 125.738455 188.075347 \nL 126.756393 189.412827 \nL 127.774332 192.430731 \nL 129.810209 191.967757 \nL 130.828148 193.579592 \nL 131.846086 193.991125 \nL 132.864025 194.762748 \nL 133.881964 195.945904 \nL 134.899902 196.185964 \nL 136.935779 198.226479 \nL 137.953718 198.020713 \nL 138.971656 198.843778 \nL 139.989595 199.512518 \nL 141.007534 199.118133 \nL 142.025472 200.04408 \nL 144.061349 198.860925 \nL 145.079288 200.026933 \nL 146.097227 200.284141 \nL 147.115165 200.35273 \nL 148.133104 200.59279 \nL 149.151042 201.587327 \nL 151.186919 201.072911 \nL 152.204858 200.558496 \nL 153.222797 200.712821 \nL 154.240735 201.278678 \nL 155.258674 202.290361 \nL 156.276612 202.35895 \nL 157.294551 201.930271 \nL 158.31249 201.775946 \nL 159.330428 201.741652 \nL 160.348367 202.084595 \nL 161.366305 201.158647 \nL 163.402182 201.707357 \nL 164.420121 202.684747 \nL 165.43806 202.444686 \nL 166.455998 203.284898 \nL 167.473937 202.804777 \nL 168.491875 200.507054 \nL 169.509814 203.096279 \nL 170.527753 203.284898 \nL 171.545691 201.467297 \nL 172.56363 202.941954 \nL 173.581568 201.707357 \nL 174.599507 199.323899 \nL 175.617445 201.621621 \nL 176.635384 199.512518 \nL 177.653323 202.170331 \nL 178.671261 201.107206 \nL 179.6892 201.604474 \nL 180.707138 202.959102 \nL 181.725077 203.233457 \nL 182.743016 202.35895 \nL 183.760954 202.136037 \nL 184.778893 202.839071 \nL 185.796831 202.684747 \nL 186.81477 202.770483 \nL 187.832708 204.296582 \nL 188.850647 203.182015 \nL 189.868586 203.130573 \nL 190.886524 202.256067 \nL 191.904463 202.050301 \nL 192.922401 199.872609 \nL 193.94034 202.410392 \nL 194.958279 199.238163 \nL 195.976217 201.090059 \nL 196.994156 199.735431 \nL 198.012094 198.912366 \nL 199.030033 201.844535 \nL 200.047971 199.838314 \nL 201.06591 201.69021 \nL 202.083849 200.712821 \nL 203.101787 202.6676 \nL 204.119726 203.473517 \nL 205.137664 202.736188 \nL 206.155603 202.941954 \nL 207.173542 203.422076 \nL 208.19148 203.490664 \nL 209.209419 203.044838 \nL 210.227357 203.730725 \nL 211.245296 203.88505 \nL 212.263234 203.250604 \nL 213.281173 204.227993 \nL 215.31705 203.799314 \nL 217.352927 204.519495 \nL 218.370866 203.473517 \nL 219.388805 203.730725 \nL 220.406743 204.313729 \nL 221.424682 202.684747 \nL 222.44262 203.987933 \nL 224.478497 203.867902 \nL 225.496436 204.450907 \nL 226.514375 204.12511 \nL 227.532313 201.655916 \nL 228.550252 202.753335 \nL 229.56819 202.084595 \nL 230.586129 202.633305 \nL 231.604068 199.306752 \nL 232.622006 203.061985 \nL 233.639945 202.753335 \nL 234.657883 201.278678 \nL 235.675822 202.530422 \nL 236.69376 204.570937 \nL 238.729638 203.164868 \nL 239.747576 204.022227 \nL 241.783453 204.24514 \nL 242.801392 204.210846 \nL 244.837269 204.570937 \nL 245.855208 205.068205 \nL 246.873146 204.502348 \nL 247.891085 204.330876 \nL 248.909023 204.67382 \nL 249.926962 204.708114 \nL 250.944901 205.325413 \nL 251.962839 205.479738 \nL 252.980778 205.051058 \nL 253.998716 205.273971 \nL 255.016655 204.742409 \nL 256.034594 203.88505 \nL 257.052532 204.639526 \nL 258.070471 204.330876 \nL 259.088409 204.605231 \nL 260.106348 204.570937 \nL 261.124286 203.627842 \nL 262.142225 203.679283 \nL 263.160164 204.725261 \nL 265.196041 205.119647 \nL 266.213979 204.913881 \nL 267.231918 203.987933 \nL 268.249857 204.279435 \nL 270.285734 203.919344 \nL 271.303672 203.902197 \nL 272.321611 205.308266 \nL 273.339549 205.548326 \nL 274.357488 203.850755 \nL 277.411304 205.376854 \nL 278.429242 204.862439 \nL 279.447181 202.839071 \nL 280.46512 199.598254 \nL 281.483058 202.753335 \nL 283.518935 203.302045 \nL 284.536874 203.782166 \nL 285.554812 204.896733 \nL 286.572751 204.776703 \nL 287.59069 204.00508 \nL 288.608628 205.359707 \nL 289.626567 204.142257 \nL 291.662444 203.88505 \nL 292.680383 205.153941 \nL 293.698321 206.062742 \nL 294.71626 205.325413 \nL 295.734198 203.953638 \nL 296.752137 203.061985 \nL 298.788014 204.690967 \nL 299.805953 205.565473 \nL 300.823891 204.605231 \nL 301.84183 203.45637 \nL 302.859768 204.090816 \nL 303.877707 204.313729 \nL 304.895646 204.931028 \nL 305.913584 205.068205 \nL 306.931523 205.34256 \nL 307.949461 204.159404 \nL 308.9674 204.073669 \nL 309.985338 203.079132 \nL 311.003277 202.941954 \nL 312.021216 204.742409 \nL 313.039154 205.942712 \nL 314.057093 205.548326 \nL 315.075031 202.839071 \nL 316.09297 201.930271 \nL 317.110909 203.559253 \nL 318.128847 204.090816 \nL 319.146786 204.913881 \nL 320.164724 203.627842 \nL 321.182663 204.485201 \nL 322.200601 204.845292 \nL 323.21854 203.422076 \nL 324.236479 203.010543 \nL 325.254417 202.256067 \nL 326.272356 202.839071 \nL 327.290294 204.296582 \nL 328.308233 199.529665 \nL 329.326172 201.090059 \nL 330.34411 203.799314 \nL 331.362049 202.290361 \nL 332.379987 204.913881 \nL 333.397926 203.662136 \nL 334.415864 203.422076 \nL 335.433803 203.542106 \nL 336.451742 204.159404 \nL 337.46968 203.113426 \nL 338.487619 203.422076 \nL 339.505557 203.079132 \nL 340.523496 204.913881 \nL 341.541435 205.89127 \nL 343.577312 204.107963 \nL 344.59525 203.765019 \nL 345.613189 203.044838 \nL 348.667005 204.536642 \nL 349.684943 204.022227 \nL 349.684943 204.022227 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pbcf63343fd\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nloss_compet plot (blue: train | orange: eval)\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m4b820c7b63\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m4b820c7b63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"96.218236\" xlink:href=\"#m4b820c7b63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(89.855736 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.115165\" xlink:href=\"#m4b820c7b63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(137.571415 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"198.012094\" xlink:href=\"#m4b820c7b63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 150 -->\n      <g transform=\"translate(188.468344 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"248.909023\" xlink:href=\"#m4b820c7b63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 200 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(239.365273 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"299.805953\" xlink:href=\"#m4b820c7b63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 250 -->\n      <g transform=\"translate(290.262203 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"350.702882\" xlink:href=\"#m4b820c7b63\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 300 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(341.159132 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m96317acb11\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m96317acb11\" y=\"210.745662\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.8 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(7.2 214.544881)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m96317acb11\" y=\"176.466164\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 180.265383)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m96317acb11\" y=\"142.186666\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.2 -->\n      <g transform=\"translate(7.2 145.985884)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m96317acb11\" y=\"107.907167\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(7.2 111.706386)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m96317acb11\" y=\"73.627669\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(7.2 77.426888)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m96317acb11\" y=\"39.348171\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.8 -->\n      <g transform=\"translate(7.2 43.147389)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_14\">\n    <path clip-path=\"url(#p132245bb2a)\" d=\"M 45.321307 17.083636 \nL 46.339245 77.826907 \nL 47.357184 103.022339 \nL 48.375123 117.094073 \nL 50.411 136.959042 \nL 51.428938 143.506426 \nL 52.446877 148.305556 \nL 54.482754 156.361238 \nL 55.500693 159.583511 \nL 57.53657 164.674017 \nL 60.590386 168.736137 \nL 62.626263 170.775767 \nL 64.66214 172.335484 \nL 68.733894 174.580792 \nL 71.78771 175.883413 \nL 72.805649 176.140509 \nL 75.859464 177.631667 \nL 76.877403 178.197279 \nL 77.895341 179.071406 \nL 78.91328 180.16835 \nL 79.931219 180.511145 \nL 80.949157 181.590949 \nL 81.967096 181.213874 \nL 82.985034 181.368132 \nL 84.002973 178.282977 \nL 85.020912 181.299573 \nL 87.056789 180.751101 \nL 88.074727 181.333853 \nL 90.110604 183.304924 \nL 93.16442 185.087458 \nL 94.182359 184.28189 \nL 95.200297 178.265838 \nL 96.218236 179.671297 \nL 97.236175 184.350449 \nL 98.254113 180.939639 \nL 99.272052 182.465076 \nL 100.28999 182.516495 \nL 101.307929 183.082107 \nL 102.325867 183.801977 \nL 103.343806 184.384728 \nL 104.361745 185.944445 \nL 105.379683 186.30438 \nL 106.397622 186.784293 \nL 107.41556 186.767153 \nL 108.433499 186.921411 \nL 109.451438 187.726979 \nL 110.469376 187.024249 \nL 111.487315 187.127088 \nL 112.505253 187.401324 \nL 113.523192 188.703945 \nL 114.54113 188.909622 \nL 115.559069 188.806783 \nL 116.577008 189.183858 \nL 117.594946 189.818029 \nL 118.612885 190.829274 \nL 119.630823 190.057985 \nL 120.648762 191.000671 \nL 121.666701 190.040845 \nL 122.684639 190.949252 \nL 123.702578 191.514864 \nL 124.720516 193.006022 \nL 125.738455 192.988882 \nL 126.756393 191.309187 \nL 127.774332 192.286152 \nL 128.792271 194.908534 \nL 129.810209 195.18277 \nL 130.828148 195.18277 \nL 131.846086 196.639649 \nL 132.864025 196.451112 \nL 134.899902 198.62786 \nL 135.917841 198.027968 \nL 136.935779 199.416288 \nL 137.953718 200.410394 \nL 138.971656 200.444673 \nL 139.989595 200.993145 \nL 141.007534 201.404499 \nL 142.025472 201.541617 \nL 143.043411 202.124368 \nL 144.061349 201.233102 \nL 145.079288 201.661595 \nL 146.097227 202.501443 \nL 147.115165 202.741399 \nL 148.133104 203.512688 \nL 150.168981 203.666946 \nL 151.186919 204.318256 \nL 152.204858 204.318256 \nL 153.222797 202.981356 \nL 154.240735 204.506794 \nL 155.258674 204.76389 \nL 156.276612 204.643912 \nL 157.294551 205.278082 \nL 158.31249 205.757995 \nL 160.348367 204.815309 \nL 161.366305 204.901008 \nL 162.384244 204.541073 \nL 164.420121 204.901008 \nL 165.43806 206.426446 \nL 166.455998 206.529284 \nL 167.473937 206.375026 \nL 168.491875 205.877974 \nL 169.509814 204.798169 \nL 170.527753 205.757995 \nL 171.545691 205.963672 \nL 172.56363 205.123825 \nL 173.581568 206.752101 \nL 174.599507 205.209523 \nL 175.617445 204.009741 \nL 176.635384 206.049371 \nL 177.653323 204.146859 \nL 178.671261 206.083651 \nL 179.6892 205.706576 \nL 180.707138 206.11793 \nL 181.725077 207.351992 \nL 182.743016 207.317712 \nL 183.760954 206.872079 \nL 184.778893 207.163455 \nL 185.796831 207.163455 \nL 190.886524 208.123281 \nL 192.922401 206.460725 \nL 193.94034 205.260943 \nL 194.958279 206.495005 \nL 195.976217 202.552862 \nL 196.994156 205.089545 \nL 198.012094 204.318256 \nL 199.030033 203.187033 \nL 200.047971 206.889219 \nL 201.06591 204.181138 \nL 202.083849 206.974918 \nL 203.101787 205.638017 \nL 205.137664 207.849045 \nL 206.155603 207.986163 \nL 207.173542 208.260399 \nL 208.19148 208.054722 \nL 209.209419 208.054722 \nL 210.227357 208.328958 \nL 211.245296 209.014548 \nL 212.263234 208.723172 \nL 213.281173 208.808871 \nL 214.299112 209.117386 \nL 215.31705 209.117386 \nL 216.334989 209.751557 \nL 217.352927 209.665858 \nL 218.370866 209.820116 \nL 219.388805 209.54588 \nL 220.406743 209.974374 \nL 221.424682 209.665858 \nL 222.44262 208.791731 \nL 223.460559 209.460181 \nL 224.478497 209.220225 \nL 226.514375 209.597299 \nL 227.532313 209.52874 \nL 228.550252 208.14042 \nL 229.56819 209.100246 \nL 230.586129 208.123281 \nL 231.604068 207.763346 \nL 232.622006 203.444129 \nL 233.639945 207.334852 \nL 234.657883 207.626228 \nL 235.675822 206.237908 \nL 236.69376 207.797625 \nL 237.711699 208.586054 \nL 238.729638 208.19184 \nL 240.765515 209.648718 \nL 241.783453 209.631579 \nL 242.801392 210.21433 \nL 244.837269 210.368588 \nL 245.855208 210.454287 \nL 246.873146 210.728523 \nL 247.891085 209.768697 \nL 248.909023 208.963128 \nL 251.962839 210.694243 \nL 252.980778 210.951339 \nL 253.998716 210.797082 \nL 255.016655 211.174156 \nL 256.034594 210.865641 \nL 257.052532 209.52874 \nL 258.070471 210.745662 \nL 259.088409 209.768697 \nL 261.124286 210.368588 \nL 262.142225 209.888675 \nL 263.160164 209.957234 \nL 264.178102 210.745662 \nL 265.196041 210.745662 \nL 267.231918 211.516951 \nL 268.249857 211.328414 \nL 269.267795 211.551231 \nL 270.285734 210.985619 \nL 271.303672 209.991513 \nL 272.321611 210.077212 \nL 273.339549 211.225575 \nL 274.357488 211.414113 \nL 275.375427 211.037038 \nL 276.393365 211.431252 \nL 277.411304 211.294134 \nL 278.429242 211.60265 \nL 279.447181 211.60265 \nL 280.46512 210.522846 \nL 281.483058 205.963672 \nL 282.500997 209.374482 \nL 283.518935 210.025793 \nL 284.536874 210.077212 \nL 285.554812 210.368588 \nL 287.59069 212.082563 \nL 288.608628 211.654069 \nL 289.626567 211.654069 \nL 290.644505 211.414113 \nL 291.662444 212.2711 \nL 292.680383 212.151122 \nL 293.698321 212.888131 \nL 295.734198 212.528196 \nL 296.752137 211.482672 \nL 297.770075 210.797082 \nL 298.788014 211.174156 \nL 299.805953 212.099703 \nL 300.823891 212.613895 \nL 301.84183 212.425358 \nL 302.859768 212.476777 \nL 303.877707 212.92241 \nL 305.913584 213.316625 \nL 306.931523 212.990969 \nL 307.949461 213.796538 \nL 308.9674 213.230926 \nL 309.985338 212.442497 \nL 311.003277 211.328414 \nL 312.021216 211.414113 \nL 313.039154 212.870991 \nL 314.057093 213.265205 \nL 315.075031 213.042389 \nL 316.09297 211.448392 \nL 317.110909 212.151122 \nL 318.128847 212.476777 \nL 319.146786 211.791187 \nL 320.164724 213.179507 \nL 321.182663 212.219681 \nL 323.21854 213.110948 \nL 324.236479 213.385184 \nL 325.254417 213.248066 \nL 326.272356 209.648718 \nL 327.290294 211.002759 \nL 328.308233 212.613895 \nL 329.326172 207.780486 \nL 330.34411 209.014548 \nL 331.362049 211.945445 \nL 332.379987 210.111492 \nL 333.397926 213.333764 \nL 334.415864 211.894026 \nL 335.433803 213.299485 \nL 336.451742 213.608 \nL 337.46968 213.779398 \nL 338.487619 212.579615 \nL 339.505557 213.882236 \nL 340.523496 213.796538 \nL 341.541435 214.379289 \nL 344.59525 214.756364 \nL 345.613189 214.584966 \nL 347.649066 212.425358 \nL 348.667005 213.65942 \nL 349.684943 213.350904 \nL 349.684943 213.350904 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_15\">\n    <path clip-path=\"url(#p132245bb2a)\" d=\"M 45.321307 77.569811 \nL 46.339245 101.685438 \nL 47.357184 116.699859 \nL 49.393061 137.318977 \nL 50.411 143.626405 \nL 51.428938 148.494093 \nL 53.464815 156.412657 \nL 54.482754 159.566371 \nL 56.518631 164.211243 \nL 58.554508 167.519215 \nL 60.590386 169.438867 \nL 62.626263 170.981444 \nL 64.66214 172.266925 \nL 66.698017 173.466708 \nL 70.769771 175.180683 \nL 71.78771 175.197823 \nL 72.805649 175.574897 \nL 75.859464 177.117474 \nL 77.895341 179.019987 \nL 78.91328 179.139965 \nL 79.931219 180.031232 \nL 80.949157 179.259943 \nL 81.967096 179.46562 \nL 82.985034 175.060705 \nL 84.002973 179.105685 \nL 86.03885 178.402956 \nL 87.056789 179.037126 \nL 89.092666 181.573809 \nL 90.110604 182.20798 \nL 91.128543 183.064967 \nL 92.146482 183.733418 \nL 93.16442 182.585054 \nL 94.182359 173.946621 \nL 95.200297 175.472059 \nL 96.218236 182.259399 \nL 97.236175 178.437235 \nL 98.254113 180.202629 \nL 99.272052 180.494005 \nL 101.307929 181.53953 \nL 102.325867 182.482216 \nL 103.343806 183.956234 \nL 105.379683 184.453287 \nL 106.397622 183.973374 \nL 107.41556 184.024793 \nL 108.433499 184.91606 \nL 109.451438 184.504706 \nL 110.469376 184.453287 \nL 111.487315 184.881781 \nL 112.505253 186.390079 \nL 113.523192 186.338659 \nL 114.54113 185.738768 \nL 115.559069 186.064424 \nL 116.577008 187.367044 \nL 117.594946 188.206892 \nL 118.612885 187.452743 \nL 119.630823 188.309731 \nL 120.648762 187.315625 \nL 121.666701 188.309731 \nL 122.684639 188.841063 \nL 123.702578 190.503619 \nL 124.720516 189.972286 \nL 125.738455 188.086914 \nL 126.756393 189.423814 \nL 127.774332 192.44041 \nL 129.810209 191.977637 \nL 130.828148 193.588773 \nL 131.846086 194.000127 \nL 132.864025 194.771416 \nL 133.881964 195.954059 \nL 134.899902 196.194015 \nL 136.935779 198.233645 \nL 137.953718 198.027968 \nL 138.971656 198.850676 \nL 139.989595 199.519127 \nL 141.007534 199.124912 \nL 142.025472 200.050459 \nL 144.061349 198.867816 \nL 145.079288 200.033319 \nL 146.097227 200.290415 \nL 147.115165 200.358974 \nL 148.133104 200.598931 \nL 149.151042 201.593036 \nL 151.186919 201.078844 \nL 152.204858 200.564651 \nL 153.222797 200.718909 \nL 154.240735 201.284521 \nL 155.258674 202.295766 \nL 156.276612 202.364325 \nL 157.294551 201.935831 \nL 158.31249 201.781574 \nL 159.330428 201.747294 \nL 160.348367 202.090089 \nL 161.366305 201.164543 \nL 163.402182 201.713015 \nL 164.420121 202.68998 \nL 165.43806 202.450024 \nL 166.455998 203.289871 \nL 167.473937 202.809958 \nL 168.491875 200.513232 \nL 169.509814 203.118474 \nL 170.527753 203.289871 \nL 171.545691 201.473058 \nL 172.56363 202.947076 \nL 173.581568 201.713015 \nL 174.599507 199.330589 \nL 175.617445 201.627316 \nL 176.635384 199.519127 \nL 177.653323 202.175788 \nL 178.671261 201.130263 \nL 179.6892 201.627316 \nL 180.707138 202.964216 \nL 181.725077 203.238452 \nL 182.743016 202.364325 \nL 183.760954 202.141508 \nL 184.778893 202.861378 \nL 185.796831 202.68998 \nL 186.81477 202.775679 \nL 187.832708 204.301117 \nL 188.850647 203.187033 \nL 189.868586 203.135614 \nL 190.886524 202.278626 \nL 191.904463 202.072949 \nL 192.922401 199.879061 \nL 193.94034 202.415744 \nL 194.958279 199.244891 \nL 195.976217 201.113123 \nL 196.994156 199.741943 \nL 198.012094 198.919235 \nL 199.030033 201.867272 \nL 200.047971 199.861922 \nL 201.06591 201.713015 \nL 202.083849 200.736049 \nL 203.101787 202.67284 \nL 204.119726 203.495548 \nL 205.137664 202.741399 \nL 206.155603 202.947076 \nL 207.173542 203.444129 \nL 208.19148 203.512688 \nL 209.209419 203.067055 \nL 210.227357 203.752645 \nL 211.245296 203.906902 \nL 212.263234 203.272732 \nL 213.281173 204.232558 \nL 215.31705 203.821204 \nL 217.352927 204.523933 \nL 218.370866 203.478409 \nL 219.388805 203.752645 \nL 220.406743 204.335396 \nL 221.424682 202.72426 \nL 222.44262 204.04402 \nL 224.478497 203.924042 \nL 225.496436 204.489654 \nL 226.514375 204.146859 \nL 227.532313 201.678735 \nL 228.550252 202.775679 \nL 229.56819 202.107229 \nL 230.586129 202.655701 \nL 231.604068 199.330589 \nL 232.622006 203.084194 \nL 233.639945 202.775679 \nL 234.657883 201.301661 \nL 235.675822 202.552862 \nL 236.69376 204.592492 \nL 238.729638 203.169893 \nL 239.747576 204.04402 \nL 241.783453 204.266837 \nL 242.801392 204.232558 \nL 244.837269 204.592492 \nL 245.855208 205.089545 \nL 246.873146 204.506794 \nL 247.891085 204.335396 \nL 248.909023 204.678191 \nL 249.926962 204.712471 \nL 250.944901 205.329502 \nL 251.962839 205.483759 \nL 252.980778 205.055266 \nL 253.998716 205.278082 \nL 255.016655 204.74675 \nL 256.034594 203.889763 \nL 257.052532 204.626772 \nL 258.070471 204.335396 \nL 259.088409 204.592492 \nL 260.106348 204.558213 \nL 261.124286 203.632666 \nL 262.142225 203.684086 \nL 263.160164 204.72961 \nL 265.196041 205.123825 \nL 266.213979 204.918148 \nL 267.231918 203.992601 \nL 268.249857 204.301117 \nL 270.285734 203.924042 \nL 271.303672 203.906902 \nL 272.321611 205.312362 \nL 273.339549 205.552318 \nL 274.357488 203.855483 \nL 277.411304 205.380921 \nL 278.429242 204.866728 \nL 279.447181 202.844238 \nL 280.46512 199.604825 \nL 281.483058 202.758539 \nL 283.518935 203.307011 \nL 284.536874 203.786924 \nL 285.554812 204.901008 \nL 286.572751 204.78103 \nL 287.59069 204.009741 \nL 288.608628 205.363781 \nL 289.626567 204.146859 \nL 291.662444 203.889763 \nL 292.680383 205.158104 \nL 293.698321 206.066511 \nL 294.71626 205.329502 \nL 295.734198 203.958322 \nL 296.752137 203.067055 \nL 298.788014 204.695331 \nL 299.805953 205.569458 \nL 300.823891 204.592492 \nL 301.84183 203.461269 \nL 302.859768 204.09544 \nL 303.877707 204.318256 \nL 304.895646 204.935287 \nL 305.913584 205.072405 \nL 306.931523 205.346641 \nL 307.949461 204.163999 \nL 308.9674 204.0783 \nL 309.985338 203.084194 \nL 311.003277 202.947076 \nL 312.021216 204.74675 \nL 313.039154 205.946533 \nL 314.057093 205.552318 \nL 315.075031 202.844238 \nL 316.09297 201.935831 \nL 317.110909 203.564107 \nL 318.128847 204.09544 \nL 319.146786 204.918148 \nL 320.164724 203.632666 \nL 321.182663 204.489654 \nL 322.200601 204.866728 \nL 323.21854 203.426989 \nL 324.236479 203.015635 \nL 325.254417 202.261486 \nL 326.272356 202.844238 \nL 327.290294 204.301117 \nL 328.308233 199.536266 \nL 329.326172 201.095984 \nL 330.34411 203.804064 \nL 331.362049 202.295766 \nL 332.379987 204.918148 \nL 333.397926 203.666946 \nL 334.415864 203.426989 \nL 335.433803 203.546968 \nL 336.451742 204.163999 \nL 337.46968 203.101334 \nL 338.487619 203.426989 \nL 339.505557 203.084194 \nL 340.523496 204.918148 \nL 341.541435 205.895113 \nL 343.577312 204.112579 \nL 344.59525 203.769784 \nL 345.613189 203.049915 \nL 348.667005 204.541073 \nL 349.684943 204.026881 \nL 349.684943 204.026881 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_16\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p132245bb2a\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Plot train and validation losses history\n",
    "for metric in monitor_batchs.metrics_info:\n",
    "    print(f\"\\n{metric} plot (blue: train | orange: eval)\")\n",
    "    for set_i in monitor_batchs.sets_names:\n",
    "        plt.plot(monitor_epochs.metrics[set_i][metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nProbas predicted:\n [[0.02328846 0.03018999 0.1568941  0.78962743]\n [0.04976636 0.1483915  0.6850012  0.11684099]\n [0.00557394 0.1847722  0.31556246 0.49409148]\n ...\n [0.00783947 0.2418618  0.6241731  0.1261256 ]\n [0.00314532 0.06238999 0.29048744 0.6439772 ]\n [0.01725197 0.08706486 0.5012647  0.39441854]]\n\nQuantity of unique probas: 14557\n\n6 first uniques:\n[[1.2476766e-05 8.2676960e-03 9.8819017e-01 3.5296888e-03]\n [1.3699698e-05 8.7121949e-03 9.8820877e-01 3.0652569e-03]\n [1.3767986e-05 1.8768881e-02 9.7847635e-01 2.7410542e-03]\n [1.6655691e-05 4.2569377e-03 9.9101442e-01 4.7119106e-03]\n [1.8757002e-05 2.2172413e-03 9.9759310e-01 1.7085523e-04]\n [1.9595773e-05 1.0150178e-02 9.8638147e-01 3.4487392e-03]]\n\nvalues used for predictions: 0 1 2 3\n\nAccuracy model 14.4611%\n\n\nPredictions:\n2    34917\n3    12212\n0      345\n1      164\nName: y_pred, dtype: int64\n\nTARGET:\n0    23217\n1    16407\n2     7497\n3      517\nName: y, dtype: int64\n"
    }
   ],
   "source": [
    "# Transform logits into probabilities\n",
    "y_pred = F.softmax(predictions)\n",
    "\n",
    "# Transform tensors to numpy arrays\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y = labels.numpy()\n",
    "\n",
    "# Display probas predicted\n",
    "print('\\nProbas predicted:\\n', y_pred)\n",
    "\n",
    "# Display the number of uniques probas (see the diversity of predictions)\n",
    "print(\"\\nQuantity of unique probas:\", \\\n",
    "        len(np.unique(F.softmax(predictions).detach().numpy(), axis=0)))\n",
    "print(\"\\n6 first uniques:\\n\", \\\n",
    "        np.unique(F.softmax(predictions).detach().numpy(), axis=0)[:6])\n",
    "\n",
    "# Transform array of predicted probas into vector of ints\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# Values used\n",
    "print('\\nvalues used for predictions:', *np.unique(y_pred))\n",
    "\n",
    "# Transform arrays into dataframes\n",
    "df_results = pd.DataFrame({'y': y, 'y_pred': y_pred})\n",
    "\n",
    "# Compute accuracy ratio\n",
    "print(f'\\nAccuracy model {round(100 * sum(y_pred == y)/len(y), 4)}%')\n",
    "\n",
    "# Display value counts\n",
    "print('\\n\\nPredictions:')\n",
    "print(df_results['y_pred'].value_counts())\n",
    "print('\\nTARGET:')\n",
    "print(df_results['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "On the test set (and no longer validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 99 test: mod_loss 0.8449, comp_loss 0.8449, acc 14.5832\n"
    }
   ],
   "source": [
    "# Test set\n",
    "# --------\n",
    "with torch.no_grad():\n",
    "    # Reset batchs scores\n",
    "    monitor_batchs.reset()\n",
    "\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_test):\n",
    "        # Predict on the test set\n",
    "        predictions = model(x)\n",
    "        \n",
    "        # Evaluate model and store metrics\n",
    "        monitor_batchs.evaluate(predictions, labels, set_i='test')\n",
    "\n",
    "# Compute & store: train and eval losses for the epoch\n",
    "monitor_epochs.compute(monitor_batchs, ['test'])\n",
    "\n",
    "# Display scores\n",
    "monitor_epochs.print_scores(i_epoch=epoch, sets=['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "if EXPORT_DATA:\n",
    "    torch.save(model.state_dict(), 'weights/weights_new.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with benchmarks preds\n",
    "\n",
    "- Uniform random predictions\n",
    "\n",
    "- Dumb prediction of the best label on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'numpy'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-89621460f791>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create numpy copy of TARGET (from tensors)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/shortcuts/virtualenvs/pytorch/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5273\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5274\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5276\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "m_train = Y_train.shape[0]\n",
    "m_val = Y_val.shape[0]\n",
    "m_test = Y_test.shape[0]\n",
    "\n",
    "# Create numpy copy of TARGET (from tensors)\n",
    "y_train = Y_train.numpy().astype(np.int_)\n",
    "y_val = Y_val.numpy().astype(np.int_)\n",
    "y_test = Y_test.numpy().astype(np.int_)\n",
    "\n",
    "# Random uniform train/test\n",
    "random_preds_train = np.random.uniform(size=(Y_train.shape[0], 4))\n",
    "random_preds_val = np.random.uniform(size=(Y_val.shape[0], 4))\n",
    "random_preds_test = np.random.uniform(size=(Y_test.shape[0], 4))\n",
    "\n",
    "# Create empty benchmark dumb\n",
    "dumb_preds_train = np.zeros((m_train, 4)) + .49\n",
    "dumb_preds_val = np.zeros((m_val, 4)) + .49\n",
    "dumb_preds_test = np.zeros((m_test, 4)) + .49\n",
    "\n",
    "# Benchmark dumb predict always 0 nights (the most )\n",
    "dumb_preds_train[range(m_train), 0] = .5\n",
    "dumb_preds_val[range(m_val), 0] = .5\n",
    "dumb_preds_test[range(m_test), 0] = .5\n",
    "\n",
    "# Evaluate preds\n",
    "# Random\n",
    "random_loss_train = cobra.competition_scorer(random_preds_train, y_train)\n",
    "random_loss_val = cobra.competition_scorer(random_preds_val, y_val)\n",
    "random_loss_test = cobra.competition_scorer(random_preds_test, y_test)\n",
    "# Dumb\n",
    "dumb_loss_train = cobra.competition_scorer(dumb_preds_train, y_train)\n",
    "dumb_loss_val = cobra.competition_scorer(dumb_preds_val, y_val)\n",
    "dumb_loss_test = cobra.competition_scorer(dumb_preds_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Random preds\")\n",
    "print(round(random_loss_train, 4))\n",
    "print(round(random_loss_val, 4))\n",
    "print(round(random_loss_test, 4))\n",
    "\n",
    "print(\"\\nDumb preds\")\n",
    "print(round(dumb_loss_train, 4))\n",
    "print(round(dumb_loss_val, 4))\n",
    "print(round(dumb_loss_test, 4))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}