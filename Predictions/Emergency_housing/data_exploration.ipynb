{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "#### Goal: Predict the number of nights granted to a request (not to an individual)\n",
    "\n",
    "\n",
    "#### Caracteristics of the model:\n",
    "Accuracy:\n",
    "- if used as a clearing tool removing overburden upfront, and thus only to get rid of obvious cases, the accuracy of such a tool could be its most important caracteristic.\n",
    "\n",
    "Interpretability:\n",
    "- could help families understand the decision (although not as important as in diseases predictions).\n",
    "- can also highlight and thus control biases (racial, sex, age).\n",
    "- since the tool would probably be used in combination with human selection, it could help save time by highlighting the main factors for each decision\n",
    "\n",
    "#### Conclusion:\n",
    "- a model easily interpretable could be prefered (tree).\n",
    "- or a highly accurate model (less interpretable) could also be used upfront (NN).\n",
    "\n",
    "\n",
    "#### Future improvements\n",
    "\n",
    "Imputations:\n",
    "- Build more robust, generalisable imputations (eg. impute future test samples with missing gender based on all easily interpretable categories group_composition_label and group_composition_id)\n",
    "\n",
    "- Automate NaNs imputation for future test samples\n",
    "\n",
    "- Reconstruct some NaNs by training models to predict the feature\n",
    "\n",
    "\n",
    "Datasets handling\n",
    "- I made the choice to keep the train and test sets split. This is to prevent gaining insight from the test set while doing pre-processing, analysis and while training the model. To prevent duplicate code, I thus placed most of the inner workings in the class Analysis, which makes the reading less fluent. To improve, see how to better combine the visual aspect of Jupyter Notebooks, while maintaining code standards like DRY philosophy.\n",
    "\n",
    "\n",
    "Pre-processing\n",
    "- impact historical data with the known global crises (financial crisis, immigration waves)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "I. Initialization\n",
    "\n",
    "1. Import packages, classes, functions\n",
    "\n",
    "2. Load databases (no join)\n",
    "\n",
    "3. Instantiate object Analysis\n",
    "\n",
    "\n",
    "II. Analyze I\n",
    "\n",
    "1. Overview\n",
    "\n",
    "2. Features: corr, dist, impact\n",
    "\n",
    "\n",
    "III. Pre-process data\n",
    "\n",
    "1. Impute NaNs\n",
    "\n",
    "2. Impute never seen before test set NaNs\n",
    "\n",
    "3. Remove outliers\n",
    "\n",
    "4. Transform categorical features\n",
    "\n",
    "5. Feature engineer\n",
    "\n",
    "\n",
    "\n",
    "IV. Analyze II\n",
    "\n",
    "1. Impact engineered features\n",
    "\n",
    "\n",
    "V. Build Model\n",
    "\n",
    "1. Benchmakrs\n",
    "\n",
    "2. Rush pytorch NN\n",
    "\n",
    "3. Simple model using principal components\n",
    "\n",
    "4. Ensemble\n",
    "\n",
    "\n",
    "VI. Predictions\n",
    "\n",
    "1. Train and Predict\n",
    "\n",
    "2. Hyperparameter tunning (split train set)\n",
    "\n",
    "\n",
    "VII. Evaluate methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ML\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Linear\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "# Utils\n",
    "import cobratools as cobra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set False to only apply data transformations\n",
    "ANALYZE_ON = False\n",
    "\n",
    "# False for the competition, True if predicting > year 2019 requests\n",
    "FUTURE_PRED = False  #d:False\n",
    "\n",
    "# Takes Â±4min\n",
    "IMPUTE_NANS = True\n",
    "EXPORT_DATA = False  #d:False\n",
    "\n",
    "# Set to True to visualize\n",
    "PRINT_ON = False\n",
    "PLOT_ON = False\n",
    "\n",
    "# Debug\n",
    "RELOAD = False  #d:False\n",
    "\n",
    "# Project specificities\n",
    "TARGET_VAR = 'granted_number_of_nights'\n",
    "N_TARGET_CLASS = 4\n",
    "\n",
    "# Data format\n",
    "PRECISION = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug reload\n",
    "Without the need to re-perform data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RELOAD:\n",
    "    # Backup data\n",
    "    backup_train = obj_train.df.copy()\n",
    "    backup_test = obj_test.df.copy()\n",
    "    \n",
    "    # Reload updated class and functions\n",
    "    importlib.reload(cobra)\n",
    "\n",
    "    # Re-instanciate obj_train and obj_test\n",
    "    obj_train = cobra.Analysis(backup_train)\n",
    "    obj_test = cobra.Analysis(backup_test)\n",
    "    \n",
    "    # Re-set target variable\n",
    "    obj_train.target = TARGET_VAR\n",
    "    obj_test.target = TARGET_VAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_train = pd.read_csv(filepath_or_buffer='data/requests_train.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "requests_test = pd.read_csv(filepath_or_buffer='data/requests_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "individuals_train = pd.read_csv(filepath_or_buffer='data/individuals_train.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "individuals_test = pd.read_csv(filepath_or_buffer='data/individuals_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join datasets\n",
    "\n",
    "Since there are multiple requests by individuals and multiple individuals by request, the straightfoward approach would be to create columns for each individual' informations. This way, no information would be lost, but the curse of dimensionality is very near and the number of samples might be too low to extract useful information.\n",
    "\n",
    "The chosen approach is rather to only keep the request dataset' columns, and feature engineer additional columns based on the individuals data, eg.:\n",
    "- nb of past requests made by the same individual\n",
    "- nb nights granted in past requests of the same individual(s)/group\n",
    "- gender diversity of the group\n",
    "- etc.\n",
    "\n",
    "However, for analytics purpose, a dataframe with all the data is also created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Merge request and individuals datasets, for analytics purpose only\n",
    "    df_full_train = pd.merge(requests_train, individuals_train, on='request_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index col as request id\n",
    "# (not for individuals data set, since there is no pkey currently)\n",
    "# (hence not for obj_full_train either)\n",
    "requests_train.set_index('request_id', inplace=True)\n",
    "requests_test.set_index('request_id', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate object analysis\n",
    "\n",
    "obj_train and obj_test will be the main dataframes, used for training and testing the model\n",
    "\n",
    "They are primilary built with the request data sets, then features engineered from individuals' data sets are added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate analysis object with request data\n",
    "obj_train = cobra.Analysis(requests_train)\n",
    "obj_test = cobra.Analysis(requests_test)\n",
    "if ANALYZE_ON:\n",
    "    obj_full_train = cobra.Analysis(df_full_train)\n",
    "\n",
    "# Define properties\n",
    "\n",
    "# - set target (no copy)\n",
    "obj_train.target = TARGET_VAR\n",
    "obj_test.target = TARGET_VAR\n",
    "if ANALYZE_ON:\n",
    "    obj_full_train.target = TARGET_VAR\n",
    "\n",
    "# - set shape\n",
    "obj_train.m = obj_train.df.shape[0]\n",
    "obj_test.m = obj_test.df.shape[0]\n",
    "obj_train.n = obj_train.df.shape[1]\n",
    "obj_test.n = obj_test.df.shape[1]\n",
    "if ANALYZE_ON:\n",
    "    obj_full_train.m = obj_full_train.df.shape[0]\n",
    "    obj_full_train.n = obj_full_train.df.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "- Number of requests: 238191\n",
    "\n",
    "- Number of individuals: 384133\n",
    "\n",
    "- Number of features: 39\n",
    "\n",
    "- Requests are made for 1.6 pers on average.\n",
    "\n",
    "\n",
    "Principal components\n",
    "- housing_situation_label: with value \"emergency accomodation\". High probability to get 1 or two nights. Logical since the service treats emergency housing\n",
    "- housing_situation_2_label: with value \"emergency accomodation\". High probability to get 1 or two nights.\n",
    "\n",
    "--------------------\n",
    "\n",
    "\n",
    "Analysis by features\n",
    "\n",
    "\n",
    "A. housing_situation_id\n",
    "- correlation target-housing_situation_id: -0.458581. Strong negative impact. Although the linear numerical relation of the housing_situation_id categories is in my opinion flawed, the strong correlation is explainable as the category with the smallest value \"emergency accomodation\" might be correlated with higher granted_number_of_nights than the rest of the categories, which happen to have higher housing_situation_id values.\n",
    "\n",
    "- housing_situation_2_id: 0.283840. Strong positive impact. Same explanation as housing_situation_id.\n",
    "\n",
    "B. pregnancy\n",
    "- Pregnancy seems not to have a significant direct correlation with target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    obj_train.describe(investigation_level=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    obj_train.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis by features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### housing_situation_2_label\n",
    "\n",
    "- Â±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "\n",
    "- Â±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "\n",
    "- Â±75% (289,870) individuals are \"on the street\"\n",
    "\n",
    "- A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Â±42% (160,061) indiv with 'housing_situation_label' == 'street'\n",
    "    obj_full_train.df[obj_full_train.df['housing_situation_label'] == 'street']\n",
    "\n",
    "    # Â±41% (156,496) indiv with 'housing_situation_label' == 'street' and 'housing_situation_2_label' == 'on the street'\n",
    "    obj_full_train.df.query(\"housing_situation_label == 'street' and housing_situation_2_label == 'on the street'\")\n",
    "\n",
    "    # Â±75% (289,870) individuals are \"on the street\"\n",
    "    print(obj_full_train.df['housing_situation_2_label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Obs: A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights.\n",
    "\n",
    "    # Impact of feature on target\n",
    "    feature = 'housing_situation_2_label'\n",
    "    mask = obj_full_train.df[feature] == 'emergency accomodation'\n",
    "\n",
    "    # Hist: drop duplicate requests (due to multiple indivs by request)\n",
    "    obj_full_train.df[mask][['request_id', target]].drop_duplicates().hist()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### child_situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'child_situation'\n",
    "\n",
    "    # Display unique values\n",
    "    uniques = obj_train.get_col_uniques(feature)\n",
    "    uniques.sort()\n",
    "    print(\"child_situation possible values:\", *uniques)\n",
    "\n",
    "    # Display distribution\n",
    "    # Obs: Almost any request has child_situation == -1\n",
    "    # hyp: -1 means NaN\n",
    "    dist = obj_train.df[feature].value_counts()\n",
    "    \n",
    "    # Count all non NaNs values\n",
    "    dist_positive = sum(dist[dist.index != -1])\n",
    "    ratio_non_na = dist_positive / obj_train.m\n",
    "    \n",
    "    # Print distribution\n",
    "    print(\"\\nDistribution\\n\", dist)\n",
    "    \n",
    "    # Plot histogram\n",
    "    print(f\"\\n\\nChild_situation non NaN ratio: {round(ratio_non_na * 100, 2)}%\\n\\n\")\n",
    "\n",
    "    # Correlation with target (for non NaNs)\n",
    "    # The proportion of non NaNs is increasing with target values\n",
    "    # The probability of granting more nights is greater when non NaN\n",
    "    dist_grpby = obj_train.df[target].groupby(obj_train.df[feature])\n",
    "    if PLOT_ON:\n",
    "        dist_grpby.hist()\n",
    "        plt.show()\n",
    "\n",
    "    # Study only positive 'child_situation' samples\n",
    "    # TODO: produce a study\n",
    "    mask_pos = obj_train.df['child_situation'] != -1\n",
    "    dist_grpby_pos = obj_train.df[mask_pos][target].groupby(obj_train.df[feature])\n",
    "    if PLOT_ON:\n",
    "        dist_grpby_pos.hist()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### victime_of_violence_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'victim_of_violence_type'\n",
    "    feature_base = 'victim_of_violence'\n",
    "\n",
    "    # Inspect a specific group with violence type \"child\"\n",
    "    # ---------------------------------------------------\n",
    "    # TODO: go further this anecdotical impression\n",
    "    # Obs: \n",
    "    # - violence child can counter intuitively be applied on individuals without child, but awaiting a child.\n",
    "    # - requests seem more likely granted when multiple (non granted) requests have been made in the past\n",
    "    # - requests seem less likely granted when a recent request was granted\n",
    "    # => feature engineer measures to represent these observations\n",
    "\n",
    "    # Mask to filter on child violence only\n",
    "    mask_child_violence = obj_train.df[feature] == 'child'\n",
    "\n",
    "    # Mast to filter group1 entries only\n",
    "    mask_group1 = obj_train.df[mask_child_violence]['group_id'] == '8d79d2cd16e886a947158b5f6e2eff43'\n",
    "\n",
    "    # Sort entries by request_creation_date\n",
    "    grp1_sorted_rq_date = obj_train.df[mask_child][mask_group1].sort_values(by='request_creation_date')\n",
    "\n",
    "    # Get dates and housing values along with target\n",
    "    grp1_sorted_rq_date[[target, 'request_creation_date', 'answer_creation_date', 'housing_situation_label']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### animal_presence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    feature = 'animal_presence'\n",
    "    mask = df_train[feature] == 't'\n",
    "    df_train[mask][[feature, target]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### requester_type along with group_main_requester_id\n",
    "if it is an urgentist, used to bring individuals to the service, its groups might have higher granted rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### request_backoffice_creator_id\n",
    "this might impact since each people has its own biases (as for the predictions of court decisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data\n",
    "\n",
    "Methodology:\n",
    "\n",
    "- Clean-up obj_train.df (initially request dataset)\n",
    "\n",
    "- Feature engineer (using indiv dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute NaNs\n",
    "\n",
    "Methodology:\n",
    "- inspect NaNs on train set\n",
    "\n",
    "- if pattern detected, apply modifications on train and test sets\n",
    "\n",
    "Observations:\n",
    "- reverse engineering: the system seems to derive group_composition_id from group_composition_label, and both are then necessary linked/redondant => drop group_composition_label\n",
    "\n",
    "Further:\n",
    "- Impute 14 pregnancy NaNs from child_to_come (not useful for the current objective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaNs train summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get Na counts: by feature, by sample\n",
    "    na_ft_train, na_sp_train = obj_train.get_na_counts()\n",
    "    na_ft_test, na_sp_test = obj_test.get_na_counts()\n",
    "    if PRINT_ON:\n",
    "        print('Train: NaNs count by feature\\n\\n', na_ft_train[na_ft_train!=0])\n",
    "        #print('\\n\\nTest: NaNs count by feature\\n\\n', na_ft_test[na_ft_test!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_to_come NaNs\n",
    "\n",
    "Observation\n",
    "- There are 145947 NaNs for child_to_come on the train set (in request)\n",
    "\n",
    "- There are only 14 NaNs for pregnancy in train set (in individuals)\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: child_to_come is True if any indiv of the group is pregnant\n",
    "\n",
    "Conclusion\n",
    "- => Impute child_to_come from the pregnancy in the group of indiv of the request\n",
    "\n",
    "Control\n",
    "- Verify that the imputation is not only setting to 'f':\n",
    "- -> successful: from the 145947 requests, 5375 are set to 't'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Capture the indexes where NaNs\n",
    "    df_train_raw_nas = obj_train.df[obj_train.df['child_to_come'].isna()]\n",
    "    idx_nas = df_train_raw_nas['child_to_come'].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # TODO: refactor (this takes Â±3min)\n",
    "    # Impute train set\n",
    "    obj_train.impute_child_to_come(df_indiv=individuals_train)\n",
    "    # Impute test set\n",
    "    obj_test.impute_child_to_come(df_indiv=individuals_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get number of NaNs imputed as False and True\n",
    "    obj_train.df.loc[idx_nas]['child_to_come'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute housing_situation_label\n",
    "\n",
    "The following code cells are organized as follows for clarity:\n",
    "- Imputation steps\n",
    "\n",
    "- Analysis\n",
    "\n",
    "Observations\n",
    "\n",
    "A. Meta numbers\n",
    "- Â±7% (16,748) NaNs for housing_situation_label (request)\n",
    "\n",
    "- 0 NaN for housing_situation_id (request)\n",
    "\n",
    "- 0 NaN for housing_situation_label_2 (individuals)\n",
    "\n",
    "- 0 NaN for housing_situation_id_2 (individuals)\n",
    "\n",
    "- 21 housing_situation_label (request)\n",
    "\n",
    "- 22 housing_situation_id (request)\n",
    "\n",
    "B. Specific ratios\n",
    "- Â±10% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "\n",
    "- Â±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "\n",
    "C. Analysis 1\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n",
    "\n",
    "D. Analysis 2\n",
    "- housing_situation_2_label can be very diverse when housing_situation_label is NaN (17 over 21 cat)\n",
    "\n",
    "- => housing_situation_label NaNs are not produced in a specific housing_situation_2_label situation\n",
    "\n",
    "E. Analysis 3\n",
    "- all individuals of a same request share the same housing_situation_2_label\n",
    "\n",
    "- => NaNs do not come from a problem of aggregating indiv data\n",
    "\n",
    "Hypotheses\n",
    "- Hyp: the housing situation should logically have an impact on the result\n",
    "\n",
    "- Hyp: proba being on the street is significantly high to always impute NaN with 'street'\n",
    "\n",
    "- Hyp: housing_ids are not sorted in any specific order from which a logic could be derived. Thus, having numerical ids is dangereous and could lead to misinterpretations by the model.\n",
    "\n",
    "Conclusion\n",
    "- => Impute housing_situation_label NaNs as 'street'\n",
    "\n",
    "- => Drop housing_situation_id\n",
    "\n",
    "- => one-hot encode housing_situation_label\n",
    "\n",
    "\n",
    "Further improvements\n",
    "- derive more sub-groups: when a group is not housing_situation_label_2 'on the street', impute the request housing_situation_label with its most often matched value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Impute NaNs with the single value 'street'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # TODO: impute more properly \n",
    "    \n",
    "    # Impute housing_situation_label NaNs as 'street'\n",
    "    obj_train.df.loc[obj_train.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'\n",
    "    obj_test.df.loc[obj_test.df['housing_situation_label'].isna(), 'housing_situation_label'] = 'street'\n",
    "\n",
    "    # Drop housing_situation_id\n",
    "    obj_train.df.drop('housing_situation_id', axis=1, inplace=True)\n",
    "    obj_test.df.drop('housing_situation_id', axis=1, inplace=True)\n",
    "\n",
    "    # One-hot encoding is applied later-on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the mapping of housing_situation_id - housing_situation_label\n",
    "- housing_situation_id is derived from housing_situation_label\n",
    "\n",
    "- housing_sitaution_label NaNs have their specific id: 170\n",
    "\n",
    "- => there are actually 16748 NaNs for housing_situation_id (request)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_id - housing_situation_label\n",
    "    map_housing_id_label = obj_train.df.loc[:, ['housing_situation_id', 'housing_situation_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index for clarity\n",
    "    map_housing_id_label = map_housing_id_label.sort_values(by='housing_situation_id')\n",
    "    map_housing_id_label.reset_index(drop=True, inplace=True)\n",
    "    map_housing_id_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze relation between housing_situation_label (request) and housing_situation_2_label (indiv)\n",
    "\n",
    "Make a temporary dataframe with columns:\n",
    "\n",
    "| request_id | gr_nb_nights | hous_id | hous_lab | indiv_id | hous_2id | hous2_lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # request [gr_nb_nights, hous_id, hous_lab]\n",
    "    rq = obj_train.df.loc[:, ['granted_number_of_nights',\n",
    "                                'housing_situation_id',\n",
    "                                'housing_situation_label']]\n",
    "\n",
    "    # individuals [request_id, indiv_id, hous_2id, hous2_lab]\n",
    "    ind = individuals_train.loc[:, ['request_id',\n",
    "                                    'individual_id',\n",
    "                                    'housing_situation_2_id',\n",
    "                                    'housing_situation_2_label']]\n",
    "    ind.set_index('request_id', inplace=True)\n",
    "\n",
    "    # Merge request and individuals datasets\n",
    "    obj_full_train = pd.merge(rq, ind, on='request_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Nb of indivs (an indiv is considered a new indiv at each request)\n",
    "    nb_indivs = obj_full_train.shape[0]\n",
    "\n",
    "    # Â±6% (23,309) indiv with NaN at 'housing_situation_label'\n",
    "    obj_full_train[obj_full_train['housing_situation_label'].isna()]\n",
    "\n",
    "    # Â±90% (21,185) of missing housing_situation_label are housing_situation_2_label \"on the street\" \n",
    "    df_temp = obj_full_train[obj_full_train[\"housing_situation_label\"].isna()]\n",
    "    df_temp['housing_situation_2_label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect individuals with housing_situation_2_label \"on the street\":\n",
    "\n",
    "- they can have a very diverse housing_situation (17 categories over a total of 21)\n",
    "\n",
    "- => no pattern to derive from this point of view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    q = obj_full_train.query(\"housing_situation_label.isna() and housing_situation_2_label != 'on the street'\")\n",
    "\n",
    "    # Count number of categories for housing_situation_2_label\n",
    "    n_cat_2 = len(q.loc[:, 'housing_situation_2_label'].unique())\n",
    "\n",
    "    # Total categories for the feature\n",
    "    n_cat_1 = len(obj_train.get_col_uniques('housing_situation_label'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if housing_situation_label NA exist when indiv within a group have different housing_situation_2\n",
    "\n",
    "- no divergence\n",
    "\n",
    "- => when group, all indiv have the same housing_situation_2_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # takes Â±1min\n",
    "    if False:\n",
    "        # Get request_id along with its group size\n",
    "        rq_id = obj_full_train.index.value_counts()\n",
    "        for i in range(70000):\n",
    "            # Get ith rq_id\n",
    "            rq_id_i = rq_id.index[0]\n",
    "\n",
    "            # Observe if housing_situation_label same for all the group members\n",
    "            n_uni_grp = len(obj_full_train.loc[rq_id_i]['housing_situation_label'].unique())\n",
    "            n_uni_indiv = len(obj_full_train.loc[rq_id_i]['housing_situation_2_label'].unique())\n",
    "\n",
    "            if n_uni_grp > 1 or n_uni_indiv > 1:\n",
    "                print(i)\n",
    "                print(n_uni_grp, n_uni_indiv)\n",
    "                print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further improvements: derive the most probable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Get mapping housing_situation_label - housing_situation_2_label\n",
    "    obj_full_train_no_na = obj_full_train[~obj_full_train.housing_situation_label.isna()]\n",
    "    map_housing_labels = obj_full_train_no_na.loc[:, ['housing_situation_label', 'housing_situation_2_label']].drop_duplicates()\n",
    "\n",
    "    # Sort and drop index\n",
    "    map_housing_labels = map_housing_labels.sort_values(by='housing_situation_label')\n",
    "    map_housing_labels.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute long_term_housing_request NaNs\n",
    "\n",
    "Nb NaNs: 165556\n",
    "\n",
    "Type: bool\n",
    "\n",
    "It seems to have no direct impact on target\n",
    "\n",
    "=> drop feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    ft = 'long_term_housing_request'\n",
    "    ma_na = obj_train.df[ft].isna()\n",
    "    ma_true = obj_train.df[ft] == 't'\n",
    "\n",
    "    # Is long_term_housing_request true when 'street' only?\n",
    "    # - No\n",
    "    obj_train.df[ma_true]['housing_situation_id'].value_counts()\n",
    "\n",
    "    # Does ft impact target?\n",
    "    # - Not directly\n",
    "    ct_true   = obj_train.df[ma_true][target].value_counts()\n",
    "    ct_false  = obj_train.df[~ma_true][target].value_counts()\n",
    "    ct_na     = obj_train.df[ma_na][target].value_counts()\n",
    "    ct_non_na = obj_train.df[~ma_na][target].value_counts()\n",
    "\n",
    "    if PRINT_ON:\n",
    "        print(\"ratios target when lt_housing true\")\n",
    "        for elem in ct_true:\n",
    "            print(f\"{round(elem/sum(ct_true)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing false\")\n",
    "        for elem in ct_false:\n",
    "            print(f\"{round(elem/sum(ct_false)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing NaN\")\n",
    "        for elem in ct_na:\n",
    "            print(f\"{round(elem/sum(ct_na)*100)}%\")\n",
    "\n",
    "        print(\"ratios target when lt_housing not NaN\")\n",
    "        for elem in ct_non_na:\n",
    "            print(f\"{round(elem/sum(ct_non_na)*100)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    obj_train.df.drop('long_term_housing_request', axis=1, inplace=True)\n",
    "    obj_test.df.drop('long_term_housing_request', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute town NaNs\n",
    "\n",
    "Nb NaNs: 159959\n",
    "\n",
    "categorical: cat_many\n",
    "\n",
    "Obs: The distribution is very uneven\n",
    "\n",
    "hyps:\n",
    "- very probable to live in a town, and ask housing in the district of our town\n",
    "\n",
    "- request_backoffice_creator_id: lives and makes requests in the same town, if the missing town is found in another request, all other NaNs with this backoffice_creator can be imputed properly\n",
    "\n",
    "- individual_id: might have missed town info in a request, but not in another (if requests are close, the probability to live in the same town is high)\n",
    "\n",
    "=> attribute the most probable town based on request district\n",
    "\n",
    "- 1 => build mapping of town-district pairs\n",
    "\n",
    "- 2 => attribute the corresponding pair for each NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Check that all values are available for district\n",
    "    # - Yes\n",
    "    sum(obj_full_train.df[ma_na]['district'].isna()) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # Build mapping town-distric\n",
    "    mapping_town_district_train = obj_train.get_features_mapping('district', 'town')\n",
    "\n",
    "    # Fill 'town' NaNs with the most frequent occurence\n",
    "    # in the pair feature 'district'. Use the mapping\n",
    "    obj_train.fill_na_most_freq_pair('town', 'district', \n",
    "                                    mapping = mapping_town_district_train,\n",
    "                                    inplace = True)\n",
    "    obj_test.fill_na_most_freq_pair('town', 'district',\n",
    "                                    mapping = mapping_town_district_train,\n",
    "                                    inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute victim_of_violence_type NaNs\n",
    "\n",
    "Nb NaNs: 234175\n",
    "\n",
    "Hyp: is NaN if victim_of_violence is 'f'\n",
    "\n",
    "=> Set a specific value to NaNs where victim_of_violence is 'f', which will later be transformed into a boolean\n",
    "\n",
    "=> Set another specific value to NaNs where victim_of_violence is 't', IDEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    # Obs: the grand majority of victim_of_violence_type NaNs comes\n",
    "    # from the absence of violence (trivial)\n",
    "    print(\"victim bool distribution\\n\",\n",
    "            obj_train.df['victim_of_violence'].value_counts())\n",
    "    print(\"\\nvictim type NaNs\\n\",\n",
    "            obj_train.df['victim_of_violence_type'].isna().value_counts())\n",
    "\n",
    "    # For the remaining victim_of_violence_type NaNs\n",
    "    # only  half requests are not granted when victim_of_violence 't',\n",
    "    remaining_nans = obj_train.df[obj_train.df['victim_of_violence'] == 't']\\\n",
    "                                [obj_train.df['victim_of_violence_type'].isna()]\n",
    "    \n",
    "    print(\"\\nRemaining Nans\\n\", remaining_nans[target].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    feature = 'victim_of_violence_type'\n",
    "    feature_base = 'victim_of_violence'\n",
    "\n",
    "    # Impute NaNs corresponding to no violence signaled by 'no violence'\n",
    "    idx_na_no_violence_train = obj_train.df[obj_train.df[feature_base] == 'f'][obj_train.df[feature].isna()].index\n",
    "    idx_na_no_violence_test = obj_test.df[obj_test.df[feature_base] == 'f'][obj_test.df[feature].isna()].index\n",
    "    obj_train.df.loc[idx_na_no_violence_train, feature] = 'no violence'\n",
    "    obj_test.df.loc[idx_na_no_violence_test, feature] = 'no violence'\n",
    "\n",
    "    # Impute NaNs corresponding to a lack of specification, but with violence signaled by 'no detail'\n",
    "    idx_na_no_detail_train = obj_train.df[obj_train.df[feature_base] == 't'][obj_train.df[feature].isna()].index\n",
    "    idx_na_no_detail_test = obj_test.df[obj_test.df[feature_base] == 't'][obj_test.df[feature].isna()].index\n",
    "    obj_train.df.loc[idx_na_no_detail_train, feature] = 'no detail'\n",
    "    obj_test.df.loc[idx_na_no_detail_test, feature] = 'no detail'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute child_situation \n",
    "(hyp: -1 values are NaNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ANALYZE_ON:\n",
    "    ft_child = 'child_situation'\n",
    "    ft_violence = 'victim_of_violence_type'\n",
    "\n",
    "    # child_situation might be linked with:\n",
    "    # - group_composition_id: 58 combinations with ft\n",
    "    # - social_situation_id: no, it is redondant with group_id\n",
    "    # - victim_of_violence_type (if child): 34 combinations with ft (better)\n",
    "    obj_train.df[ft_child].value_counts()\n",
    "\n",
    "    # Get combinations for child_situation and victim_of_violence_type\n",
    "    df_temp = obj_train.df[[ft_child, ft_violence]]\\\n",
    "                            .sort_values(by = ft_violence)\n",
    "    df_temp.drop_duplicates(ignore_index=True)\\\n",
    "                            .sort_values(by = ft_violence)\n",
    "\n",
    "    # victim_of_violence_type\n",
    "    # Obs: only child_situation -1 and 10 (ie. only 10)\n",
    "    ma_child = df_temp[ft_violence] == 'child'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    ft_child = 'child_situation'\n",
    "    ft_violence = 'victim_of_violence_type'\n",
    "\n",
    "    # Hyp: -1 (NaNs) for child_situation should be 10 when victim_of_violence_type 'child'\n",
    "    # => replace child_situation by 10 when victim_of_violence_type 'child'\n",
    "    idx_child_train = obj_train.df[obj_train.df[ft_violence] == 'child'].index\n",
    "    idx_child_test = obj_test.df[obj_test.df[ft_violence] == 'child'].index\n",
    "    obj_train.df.loc[idx_child_train, ft_child] = 10\n",
    "    obj_test.df.loc[idx_child_test, ft_child] = 10\n",
    "\n",
    "    # Idem for 'family'\n",
    "    idx_family_train = obj_train.df[obj_train.df[ft_violence] == 'family'].index\n",
    "    idx_family_test = obj_test.df[obj_test.df[ft_violence] == 'family'].index\n",
    "    obj_train.df.loc[idx_family_train, ft_child] = 10\n",
    "    obj_test.df.loc[idx_family_test, ft_child] = 10\n",
    "\n",
    "    # TODO: impute the rest (majority :( )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Impute remaining test set NaNs\n",
    "(that have no equivalent in train set, and thus can't be studied to build a clever imputation method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMPUTE_NANS:\n",
    "    # TODO: implement method based on train set logic for any feature\n",
    "    obj_train.set_default_na_vals()\n",
    "\n",
    "    # Transfer default NaNs to test object (no need to copy)\n",
    "    obj_test.default_na_vals = obj_train.default_na_vals\n",
    "\n",
    "    # Impute any remaining NaN based on its default value\n",
    "    obj_test.impute_nans()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop answer creation date\n",
    "hyp: the variable is not available at prediction time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the purpose of the competition, is it expected to be used?\n",
    "if FUTURE_PRED:\n",
    "    obj_train.df.drop('answer_creation_date', axis=1, inplace=True)\n",
    "    obj_test.df.drop('answer_creation_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete old samples\n",
    "(if it was to predict future requests (> 2020))\n",
    "- Train/test split being done randomly (â  historically), it is important for this competition to train the model on the whole train set (don't remove old samples)\n",
    "- Delete samples with group_creation_date < 2015, since it is very unlikely that current demands are treated like +5 years ago (social services evolve)\n",
    "- Threshold date: see if later is better, potential gains from domain knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if FUTURE_PRED:\n",
    "    # Drop samples with year < 2015\n",
    "    old_samples = obj_train.df[obj_train.df.group_creation_date.dt.year < 2015]\n",
    "    obj_train.df.drop(old_samples.index, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender\n",
    "\n",
    "- => Only females are possibly pregnant, thus 30 males have made a mistake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Retrieve the individual ids, and correct for male -> pregnancy = 0\n",
    "#obj_train.df['gender'].groupby(obj_train.df['pregnancy']).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clusterize large categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: make clusters then transform using one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform dates\n",
    "- into linear numerical features (year, month)\n",
    "\n",
    "- and into categorical features (hot_season, col_season:T/F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features: Dates to year, month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns of date type\n",
    "list_date_cols = [\n",
    "    'request_creation_date',\n",
    "    'group_creation_date'\n",
    "]\n",
    "\n",
    "# Don't use the feature if trying to build robust in-production model\n",
    "if not FUTURE_PRED:\n",
    "    list_date_cols.append('answer_creation_date')\n",
    "\n",
    "# Transform date type: string to timestamp\n",
    "for col in list_date_cols:\n",
    "    obj_train.df[col] = pd.to_datetime(obj_train.df[col])\n",
    "    obj_test.df[col] = pd.to_datetime(obj_test.df[col])\n",
    "\n",
    "# Create feature: 'year'\n",
    "for col in list_date_cols:\n",
    "    obj_train.df[col[:-4]+'year'] = obj_train.df[col].dt.year\n",
    "    obj_test.df[col[:-4]+'year'] = obj_test.df[col].dt.year\n",
    "\n",
    "# Create feature: 'month'\n",
    "for col in list_date_cols:\n",
    "    obj_train.df[col[:-4]+'month'] = obj_train.df[col].dt.month\n",
    "    obj_test.df[col[:-4]+'month'] = obj_test.df[col].dt.month\n",
    "\n",
    "# Drop raw features of type date\n",
    "for col in list_date_cols:\n",
    "    obj_train.df.drop(col, axis=1, inplace=True)\n",
    "    obj_test.df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New Feats: hot_season, cold_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create district_grant_ratio and town_grant_ratio\n",
    "\n",
    "Type:\n",
    "- num (float), can be linearly separable\n",
    "\n",
    "Obs:\n",
    "- district_grant_ratio: has a large impact, with districts granting more nights than there are requests and some refusing way more often\n",
    "\n",
    "- town_grant_ratio: has a large impact, with nights granted more for individuals from a specific towns (eg. Amiens is 4x)\n",
    "\n",
    "Hyp:\n",
    "- it is a sort of district emergency housing capacity measurement against the emergency housing demand\n",
    "\n",
    "- it should be very close, redondant? Yes in part, the correlation is very high (88%), but the discrepancies might come from valuable information\n",
    "\n",
    "- => create ratio of the distance between town and district of a request\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new feature district_grant_ratio\n",
    "obj_train.create_ft_grant_ratio('district')\n",
    "obj_test.create_ft_grant_ratio('district')\n",
    "\n",
    "# Create new feature town_grant_ratio\n",
    "obj_train.create_ft_grant_ratio('town')\n",
    "obj_test.create_ft_grant_ratio('town')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: distance between town and district\n",
    "or a simpler version: if town is from this district or another\n",
    "\n",
    "- if town in district: 0\n",
    "- else: 1\n",
    "\n",
    "Since there are 1116 towns, doing the mapping would take 3h if 10s by town\n",
    "\n",
    "=> another time, or say, let the model firgure it out <3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create town_capacity_left\n",
    "This can be computed on the month or the year. It provides a guess of the number of nights that can be granted at time of request (using past request then)\n",
    "\n",
    "Hyp: it might be the most impactful feature, since the selectivity based on personal criteria is lowered or inexistant when there is a large emergency housing capacity left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform Town and District to regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: group_age_max, group_age_min\n",
    "\n",
    "Based on individuals information birth_month, birth_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of indivs in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past requests by indivs forming the group of the request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "\n",
    "# Single individual\n",
    "\n",
    "# Get number of ALL requests of indiv with max n_requests\n",
    "#ind_id = obj_full_train['individual_id'].value_counts().index[0]\n",
    "\n",
    "# Watch request made by the same indiv\n",
    "#obj_full_train[obj_full_train['individual_id'] == ind_id]\n",
    "\n",
    "# TODO: Past requests only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Feat: nb of past granted request by indivs forming the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop numerical columns\n",
    "(that can't be used properly, or untill transformation methods are implemented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: transform before drop: request_backoffice_creator_id\n",
    "list_drop = [\n",
    "    'district',  # replaced by district_grant_ratio\n",
    "    'town',      # replace by town_grant_ratio\n",
    "    'group_id',\n",
    "    'group_main_requester_id',\n",
    "    'request_backoffice_creator_id',\n",
    "    'social_situation_id'\n",
    "]\n",
    "\n",
    "for feature in list_drop:\n",
    "    obj_train.df.drop(feature, axis=1, inplace=True)\n",
    "    obj_test.df.drop(feature, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform categorical features\n",
    "Prepare data to feed models\n",
    "\n",
    "- booleans: replace by (1, 0)\n",
    "\n",
    "- 2 < cats < 11: one-hot encoding\n",
    "\n",
    "- No transform on features with more than 11 categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show standard data type: True\n",
    "# Show personalized (provide insight on information level)\n",
    "STANDARD = False\n",
    "\n",
    "if ANALYZE_ON:\n",
    "    if STANDARD:\n",
    "        # Display standard data types\n",
    "        print(obj_train.df.dtypes)\n",
    "    else:\n",
    "        # Display col name along its type (bool, cat, num, empty)\n",
    "        for col, col_type in zip(obj_train.df.columns, obj_train.get_cols_type()):\n",
    "            print(col_type, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform all categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traform categorical features:\n",
    "# - booleans: ('t', 't') into (1, 0)\n",
    "# - categorical with few/med classes: one-hot encoding\n",
    "bools_train, failed_train = obj_train.transform_categories(\n",
    "                                        target=obj_train.target)\n",
    "bools_test, failed_test = obj_test.transform_categories(\n",
    "                                        target=obj_test.target)\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "obj_train.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Preprocess specific cat columns\n",
    "obj_test.convert_to_bool(col='group_type',\n",
    "                            true_val='group',\n",
    "                            false_val='individual')\n",
    "\n",
    "# Export data\n",
    "if EXPORT_DATA:\n",
    "    obj_train.export_data('data/data_train_preprocessed.csv')\n",
    "    obj_test.export_data('data/data_test_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict\n",
    "\n",
    "If training directly with the criterion weights, the model is rapidly stuck in a bad local optimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data, tools, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose between selecting or dropping columns\n",
    "SELECT = False\n",
    "\n",
    "# Drop only the following features, keep the others\n",
    "# -------------------------------------------------\n",
    "if not SELECT:\n",
    "    drop_features = [\n",
    "        'request_creation_year',\n",
    "        'group_creation_year',\n",
    "        'answer_creation_year'\n",
    "    ]\n",
    "    df_train = obj_train.df.drop(*[drop_features], axis=1, inplace=False)\n",
    "    df_test  = obj_train.df.drop(*[drop_features], axis=1, inplace=False)\n",
    "\n",
    "else:\n",
    "    # Select and keep only the following features\n",
    "    # -------------------------------------------\n",
    "    use_features = [\n",
    "        'district_grant_ratio'\n",
    "    ]\n",
    "    # Append target col to the list of columns to keep\n",
    "    use_cols = use_features + [obj_train.target]\n",
    "    \n",
    "    # Create df with selected cols only\n",
    "    df_train = obj_train.df[use_cols]\n",
    "    df_test  = obj_test.df[use_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split and tensorize data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train/cross-validation split:\n",
    "# .8 means 80% of samples in the train set,\n",
    "# and the remaining, 20%, in validation set\n",
    "TRAIN_VAL_SPLIT = .8\n",
    "\n",
    "# Reset the target feature\n",
    "# (in case it has been changed during debugging)\n",
    "target = obj_train.target\n",
    "\n",
    "# Mask - select all features columns but the target\n",
    "ma_ft = df_train.columns != target\n",
    "\n",
    "# Separate target and features\n",
    "X_train_full = df_train.loc[:,ma_ft]\n",
    "X_test       = df_test.loc[:,ma_ft]\n",
    "Y_train_full = df_train.loc[:,target]\n",
    "Y_test       = df_test.loc[:,target]\n",
    "\n",
    "# Split train into: train / cross-val sets\n",
    "n_train = round(X_train_full.shape[0] * TRAIN_VAL_SPLIT)\n",
    "X_train = X_train_full[:n_train]\n",
    "X_val   = X_train_full[n_train:]\n",
    "Y_train = Y_train_full[:n_train]\n",
    "Y_val   = Y_train_full[n_train:]\n",
    "\n",
    "# Transform pandas dataframes into torch tensors\n",
    "X_train = torch.from_numpy(X_train.values)\n",
    "X_val   = torch.from_numpy(X_val.values)\n",
    "X_test  = torch.from_numpy(X_test.values)\n",
    "Y_train = torch.from_numpy(Y_train.values)\n",
    "Y_val   = torch.from_numpy(Y_val.values)\n",
    "Y_test  = torch.from_numpy(Y_test.values)\n",
    "\n",
    "# Cast all to float type\n",
    "X_train = X_train.float()\n",
    "X_val   = X_val.float()\n",
    "X_test  = X_test.float()\n",
    "Y_train = Y_train.float()\n",
    "Y_val   = Y_val.float()\n",
    "Y_test  = Y_test.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate datasets\n",
    "dataset_train = cobra.Dataset(X=X_train, Y=Y_train)\n",
    "dataset_val   = cobra.Dataset(X=X_val,   Y=Y_val)\n",
    "dataset_test  = cobra.Dataset(X=X_test,  Y=Y_test)\n",
    "\n",
    "# Instantiate data loaders\n",
    "dataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size = dataset_train.len)\n",
    "dataloader_val   = torch.utils.data.DataLoader(dataset_val,   batch_size = dataset_val.len)\n",
    "dataloader_test  = torch.utils.data.DataLoader(dataset_test,  batch_size = dataset_test.len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model properties\n",
    "MODEL_LAYERS = [X_train.shape[1], 80, 60, N_TARGET_CLASS]  # [hidden1, ...]\n",
    "CLASS_WEIGHTS = [1, 10, 100, 1000]  # compet standard\n",
    "LEARNING_RATE= .08\n",
    "MOMENTUM= .8\n",
    "WEIGHT_DECAY = 0\n",
    "DROPOUT_RATIO = .3\n",
    "\n",
    "# Cast weights to tensor format\n",
    "class_weights = torch.FloatTensor(CLASS_WEIGHTS)\n",
    "CRITERION = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "# Set monitoring properties\n",
    "SETS = ['train', 'eval', 'test']\n",
    "METRICS = {'accuracy': cobra.compute_accuracy,\n",
    "           'loss_model': CRITERION,\n",
    "           'loss_compet': cobra.competition_scorer} \n",
    "\n",
    "\n",
    "# Calculate the number of weights\n",
    "n_weights = cobra.calculate_n_weights(MODEL_LAYERS)\n",
    "if PRINT_ON:\n",
    "    print('Number of model weights', n_weights)\n",
    "\n",
    "# Reimport module\n",
    "importlib.reload(cobra)\n",
    "\n",
    "# Initialize model and weights\n",
    "model = cobra.NN(MODEL_LAYERS, p=DROPOUT_RATIO)\n",
    "\n",
    "# Set optimizer\n",
    "optimizer = optim.SGD(model.parameters(),\n",
    "                        lr=LEARNING_RATE,\n",
    "                        momentum=MOMENTUM,\n",
    "                        weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Reset performances history\n",
    "monitor_epochs = cobra.Monitoring(sets=SETS,\n",
    "                                  metrics=METRICS)\n",
    "monitor_batchs = cobra.Monitoring(sets=SETS,\n",
    "                                  metrics=METRICS)\n",
    "\n",
    "# Show storing format\n",
    "if PRINT_ON:\n",
    "    monitor_epochs.metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 0 train/val: mod_loss 0.9637, 0.97, comp_loss 0.9638, 0.97, acc 13.7841, 14.5808\nEpoch 1 train/val: mod_loss 0.9656, 0.9776, comp_loss 0.9657, 0.9775, acc 14.8216, 13.4074\nEpoch 2 train/val: mod_loss 0.9731, 0.9757, comp_loss 0.9731, 0.9757, acc 13.423, 13.548\nEpoch 3 train/val: mod_loss 0.9712, 0.9749, comp_loss 0.9712, 0.9748, acc 13.5227, 13.7453\nEpoch 4 train/val: mod_loss 0.9696, 0.9716, comp_loss 0.9695, 0.9716, acc 13.7636, 14.5976\nEpoch 5 train/val: mod_loss 0.9667, 0.9725, comp_loss 0.9667, 0.9725, acc 14.6689, 14.8537\nEpoch 6 train/val: mod_loss 0.969, 0.9697, comp_loss 0.9689, 0.9696, acc 14.8242, 14.5262\nEpoch 7 train/val: mod_loss 0.9665, 0.9693, comp_loss 0.9663, 0.9693, acc 14.5839, 14.2176\nEpoch 8 train/val: mod_loss 0.9662, 0.9668, comp_loss 0.9662, 0.9668, acc 14.3073, 13.8839\nEpoch 9 train/val: mod_loss 0.9651, 0.9645, comp_loss 0.9651, 0.9645, acc 14.0334, 13.9636\nEpoch 10 train/val: mod_loss 0.9643, 0.9644, comp_loss 0.9641, 0.9644, acc 14.0171, 14.0287\nEpoch 11 train/val: mod_loss 0.9633, 0.9642, comp_loss 0.9632, 0.9642, acc 14.0937, 14.0644\nEpoch 12 train/val: mod_loss 0.962, 0.9632, comp_loss 0.9622, 0.9632, acc 14.238, 14.2071\nEpoch 13 train/val: mod_loss 0.9611, 0.9626, comp_loss 0.9612, 0.9626, acc 14.3398, 14.2785\nEpoch 14 train/val: mod_loss 0.9602, 0.9625, comp_loss 0.9602, 0.9626, acc 14.4086, 14.2554\nEpoch 15 train/val: mod_loss 0.9588, 0.962, comp_loss 0.9589, 0.962, acc 14.3556, 14.2449\nEpoch 16 train/val: mod_loss 0.9572, 0.9588, comp_loss 0.9574, 0.9589, acc 14.3897, 14.1589\nEpoch 17 train/val: mod_loss 0.9556, 0.9688, comp_loss 0.9559, 0.9689, acc 14.2816, 13.7852\nEpoch 18 train/val: mod_loss 0.9625, 0.9654, comp_loss 0.9627, 0.9654, acc 13.7526, 14.8201\nEpoch 19 train/val: mod_loss 0.9623, 0.9756, comp_loss 0.9622, 0.9756, acc 14.9003, 14.2197\nEpoch 20 train/val: mod_loss 0.9669, 0.9654, comp_loss 0.967, 0.9653, acc 14.4212, 13.9762\nEpoch 21 train/val: mod_loss 0.958, 0.9642, comp_loss 0.9582, 0.9641, acc 14.354, 13.5018\nEpoch 22 train/val: mod_loss 0.9575, 0.9621, comp_loss 0.9577, 0.9622, acc 13.7248, 13.4955\nEpoch 23 train/val: mod_loss 0.9548, 0.9791, comp_loss 0.9551, 0.9791, acc 13.6812, 13.9301\nEpoch 24 train/val: mod_loss 0.9705, 0.9702, comp_loss 0.9704, 0.9702, acc 14.2191, 14.1379\nEpoch 25 train/val: mod_loss 0.9639, 0.9694, comp_loss 0.9639, 0.9694, acc 14.3514, 14.1526\nEpoch 26 train/val: mod_loss 0.9617, 0.9851, comp_loss 0.9617, 0.985, acc 14.6127, 13.1072\nEpoch 27 train/val: mod_loss 0.9729, 0.9575, comp_loss 0.9729, 0.9575, acc 13.1559, 14.0224\nEpoch 28 train/val: mod_loss 0.9571, 0.9657, comp_loss 0.9571, 0.9658, acc 14.1929, 14.5409\nEpoch 29 train/val: mod_loss 0.9672, 0.9664, comp_loss 0.9672, 0.9664, acc 14.8819, 14.5031\nEpoch 30 train/val: mod_loss 0.9635, 0.9708, comp_loss 0.9636, 0.9708, acc 14.7912, 14.4485\nEpoch 31 train/val: mod_loss 0.9635, 0.9646, comp_loss 0.9638, 0.9646, acc 14.7387, 14.1715\nEpoch 32 train/val: mod_loss 0.9572, 0.9653, comp_loss 0.9573, 0.9653, acc 14.1677, 14.1337\nEpoch 33 train/val: mod_loss 0.9583, 0.9617, comp_loss 0.9584, 0.9617, acc 14.1373, 14.6627\nEpoch 34 train/val: mod_loss 0.9555, 0.9568, comp_loss 0.9556, 0.9569, acc 14.6621, 14.5073\nEpoch 35 train/val: mod_loss 0.9528, 0.9714, comp_loss 0.9529, 0.9714, acc 14.5403, 14.5325\nEpoch 36 train/val: mod_loss 0.9682, 0.9871, comp_loss 0.9683, 0.9871, acc 14.724, 12.8112\nEpoch 37 train/val: mod_loss 0.9772, 0.9579, comp_loss 0.9772, 0.9579, acc 12.8437, 13.9133\nEpoch 38 train/val: mod_loss 0.9557, 0.9635, comp_loss 0.9559, 0.9635, acc 14.1761, 14.3058\nEpoch 39 train/val: mod_loss 0.9583, 0.9668, comp_loss 0.9587, 0.9668, acc 14.3482, 14.5913\nEpoch 40 train/val: mod_loss 0.9592, 0.9698, comp_loss 0.9594, 0.9698, acc 14.6783, 14.6081\nEpoch 41 train/val: mod_loss 0.9587, 0.9687, comp_loss 0.959, 0.9687, acc 14.6626, 14.3499\nEpoch 42 train/val: mod_loss 0.9566, 0.966, comp_loss 0.9568, 0.966, acc 14.3362, 14.1232\nEpoch 43 train/val: mod_loss 0.9552, 0.9634, comp_loss 0.9554, 0.9634, acc 14.0465, 13.9972\nEpoch 44 train/val: mod_loss 0.9549, 0.9631, comp_loss 0.9553, 0.9631, acc 14.0439, 13.6551\nEpoch 45 train/val: mod_loss 0.9541, 0.9634, comp_loss 0.9541, 0.9634, acc 13.7914, 13.7159\nEpoch 46 train/val: mod_loss 0.9541, 0.9856, comp_loss 0.9542, 0.9856, acc 13.9137, 13.0547\nEpoch 47 train/val: mod_loss 0.9745, 0.963, comp_loss 0.9745, 0.963, acc 12.978, 14.6627\nEpoch 48 train/val: mod_loss 0.9543, 0.9705, comp_loss 0.9544, 0.9705, acc 14.6542, 14.8873\nEpoch 49 train/val: mod_loss 0.963, 0.9618, comp_loss 0.9631, 0.9617, acc 15.1758, 14.6354\n"
    }
   ],
   "source": [
    "# Train model (3x)\n",
    "n_epochs = 50\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # Reset batchs scores\n",
    "    monitor_batchs.reset()\n",
    "\n",
    "    # Training\n",
    "    # --------\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_train):\n",
    "\n",
    "        # Predict\n",
    "        predictions = model(x)\n",
    "\n",
    "        # Evaluate model and store metrics\n",
    "\n",
    "        loss = monitor_batchs.evaluate(predictions, labels, 'train')\n",
    "\n",
    "        # Reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Backpropagate\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    # ----------\n",
    "    with torch.no_grad():\n",
    "        for n_batch, (x, labels) in enumerate(dataloader_val):\n",
    "            \n",
    "            # Predict on the eval set\n",
    "            predictions = model(x)\n",
    "\n",
    "            # Evaluate model and store metrics\n",
    "            monitor_batchs.evaluate(predictions, labels, set_i='eval')\n",
    "\n",
    "\n",
    "    # Compute & store: train and eval losses for the epoch\n",
    "    monitor_epochs.compute(monitor_batchs, ['train', 'eval'])\n",
    "    \n",
    "    # Display scores\n",
    "    monitor_epochs.print_scores(i_epoch=epoch, ['train', 'eval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitor training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\naccuracy plot (blue: train | orange: eval)\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 378.465625 248.518125\" width=\"378.465625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 378.465625 248.518125 \nL 378.465625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \nL 371.265625 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m375adb4fcc\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"51.683807\" xlink:href=\"#m375adb4fcc\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(48.502557 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"92.537986\" xlink:href=\"#m375adb4fcc\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(86.175486 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"133.392166\" xlink:href=\"#m375adb4fcc\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(127.029666 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"174.246345\" xlink:href=\"#m375adb4fcc\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(167.883845 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"215.100524\" xlink:href=\"#m375adb4fcc\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(208.738024 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"255.954704\" xlink:href=\"#m375adb4fcc\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(246.410954 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"296.808883\" xlink:href=\"#m375adb4fcc\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g transform=\"translate(287.265133 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"337.663062\" xlink:href=\"#m375adb4fcc\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 140 -->\n      <g transform=\"translate(328.119312 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m772190c752\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m772190c752\" y=\"203.861135\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 12.5 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 207.660353)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m772190c752\" y=\"177.081002\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15.0 -->\n      <g transform=\"translate(7.2 180.880221)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m772190c752\" y=\"150.30087\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 17.5 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(7.2 154.100088)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m772190c752\" y=\"123.520737\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 20.0 -->\n      <g transform=\"translate(7.2 127.319956)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m772190c752\" y=\"96.740605\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 22.5 -->\n      <g transform=\"translate(7.2 100.539823)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m772190c752\" y=\"69.960472\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 25.0 -->\n      <g transform=\"translate(7.2 73.759691)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m772190c752\" y=\"43.18034\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 27.5 -->\n      <g transform=\"translate(7.2 46.979559)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"36.465625\" xlink:href=\"#m772190c752\" y=\"16.400207\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 30.0 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(7.2 20.199426)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"159.033203\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#p4c6ee56629)\" d=\"M 51.683807 214.756364 \nL 53.726516 27.92959 \nL 55.769225 122.691624 \nL 57.811934 94.831717 \nL 59.854643 98.232794 \nL 61.897352 162.891817 \nL 63.940061 188.442205 \nL 65.98277 192.994828 \nL 68.025479 194.985127 \nL 70.068188 195.159734 \nL 72.110897 195.918147 \nL 74.153605 196.54266 \nL 76.196314 196.385193 \nL 78.239023 193.664331 \nL 80.281732 188.458274 \nL 82.324441 188.852477 \nL 84.36715 185.974148 \nL 86.409859 184.113465 \nL 88.452568 186.417627 \nL 90.495277 186.32229 \nL 92.537986 184.826888 \nL 94.580695 184.501241 \nL 96.623404 184.956503 \nL 98.666113 183.017622 \nL 100.708822 183.511448 \nL 102.751531 185.529598 \nL 104.79424 185.079692 \nL 106.836949 183.495379 \nL 108.879658 183.658203 \nL 112.965076 186.311578 \nL 115.007785 185.524242 \nL 117.050494 182.54522 \nL 119.093203 183.247931 \nL 121.135912 181.757884 \nL 123.178621 185.186813 \nL 125.22133 178.699593 \nL 127.264039 179.272688 \nL 129.306748 182.173512 \nL 131.349457 183.545726 \nL 133.392166 181.988194 \nL 135.434875 183.398971 \nL 137.477584 181.791092 \nL 139.520292 184.906157 \nL 141.563001 185.597084 \nL 143.60571 181.527575 \nL 145.648419 181.155867 \nL 147.691128 191.460862 \nL 149.733837 190.032945 \nL 151.776546 184.534449 \nL 153.819255 178.27861 \nL 155.861964 184.866522 \nL 157.904673 175.883395 \nL 159.947382 183.528587 \nL 161.990091 189.67302 \nL 164.0328 186.485113 \nL 166.075509 188.532187 \nL 168.118218 189.852983 \nL 170.160927 188.182974 \nL 172.203636 187.924813 \nL 174.246345 184.180951 \nL 176.289054 180.7231 \nL 178.331763 179.447295 \nL 180.374472 179.351957 \nL 182.417181 180.515286 \nL 184.45989 185.063624 \nL 186.502599 193.844294 \nL 188.545308 188.95317 \nL 190.588017 182.353475 \nL 192.630726 177.238469 \nL 194.673435 178.463928 \nL 196.716144 181.375464 \nL 198.758853 189.706228 \nL 200.801562 182.786242 \nL 204.886979 190.955253 \nL 206.929688 190.808498 \nL 208.972397 181.290839 \nL 211.015106 188.587889 \nL 213.057815 186.732562 \nL 215.100524 177.373441 \nL 217.143233 177.861911 \nL 219.185942 187.452412 \nL 221.228651 189.538049 \nL 223.27136 183.607856 \nL 225.314069 183.43325 \nL 227.356778 185.186813 \nL 229.399487 173.965937 \nL 231.442196 193.051602 \nL 233.484905 180.678109 \nL 235.527614 192.444228 \nL 237.570323 189.875478 \nL 239.613032 180.015033 \nL 241.655741 182.134949 \nL 243.69845 187.25531 \nL 245.741159 184.894374 \nL 247.783868 180.319256 \nL 249.826577 180.650258 \nL 251.869286 185.636719 \nL 253.911995 185.029345 \nL 255.954704 190.105787 \nL 257.997413 178.992032 \nL 260.040122 193.97391 \nL 262.082831 192.905918 \nL 264.12554 190.325384 \nL 266.168249 180.627763 \nL 268.210958 178.964181 \nL 270.253666 181.538287 \nL 274.339084 187.435273 \nL 276.381793 187.609879 \nL 278.424502 186.789336 \nL 280.467211 185.243586 \nL 282.50992 184.153099 \nL 284.552629 183.41611 \nL 286.595338 183.983849 \nL 288.638047 183.618568 \nL 290.680756 184.776541 \nL 292.723465 190.443217 \nL 294.766174 178.148994 \nL 296.808883 183.281138 \nL 298.851592 184.000988 \nL 300.894301 190.741012 \nL 302.93701 191.208058 \nL 304.979719 185.446044 \nL 307.022428 184.02884 \nL 309.065137 181.22978 \nL 311.107846 196.835099 \nL 313.150555 185.7267 \nL 315.193264 178.346096 \nL 317.235973 179.317679 \nL 319.278682 179.880062 \nL 321.321391 185.996644 \nL 323.3641 186.32229 \nL 325.406809 180.700605 \nL 327.449518 182.005333 \nL 329.492227 180.037529 \nL 331.534936 200.179402 \nL 333.577645 185.906663 \nL 335.620353 184.063118 \nL 337.663062 180.52707 \nL 339.705771 180.695249 \nL 341.74848 184.191663 \nL 343.791189 187.294945 \nL 345.833898 187.322796 \nL 347.876607 190.027589 \nL 349.919316 188.717505 \nL 351.962025 198.740773 \nL 354.004734 180.78523 \nL 356.047443 175.197823 \nL 356.047443 175.197823 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path clip-path=\"url(#p4c6ee56629)\" d=\"M 51.683807 17.083636 \nL 53.726516 125.130759 \nL 55.769225 89.534607 \nL 57.811934 97.449743 \nL 59.854643 154.767796 \nL 61.897352 186.315863 \nL 63.940061 193.692183 \nL 65.98277 195.198297 \nL 68.025479 195.693194 \nL 70.068188 196.413044 \nL 72.110897 196.839384 \nL 74.153605 196.09811 \nL 76.196314 194.051036 \nL 78.239023 188.003011 \nL 80.281732 188.586818 \nL 82.324441 185.70849 \nL 84.36715 185.462112 \nL 86.409859 186.81076 \nL 88.452568 186.81076 \nL 90.495277 185.304645 \nL 92.537986 185.079692 \nL 94.580695 185.439617 \nL 96.623404 184.764758 \nL 98.666113 184.247366 \nL 100.708822 185.820966 \nL 102.751531 185.75348 \nL 104.79424 184.989711 \nL 108.879658 185.61958 \nL 110.922367 186.42834 \nL 112.965076 186.09091 \nL 115.007785 183.977422 \nL 117.050494 184.607291 \nL 119.093203 183.325058 \nL 121.135912 186.045919 \nL 123.178621 180.761664 \nL 125.22133 180.964121 \nL 127.264039 184.17988 \nL 129.306748 185.507103 \nL 133.392166 185.102187 \nL 135.434875 182.943709 \nL 137.477584 187.080704 \nL 139.520292 185.910947 \nL 141.563001 182.988699 \nL 143.60571 182.988699 \nL 145.648419 191.645109 \nL 147.691128 190.746368 \nL 149.733837 185.192169 \nL 151.776546 180.761664 \nL 153.819255 184.112394 \nL 155.861964 175.859828 \nL 157.904673 185.955938 \nL 159.947382 190.408938 \nL 161.990091 188.317946 \nL 164.0328 193.17479 \nL 166.075509 192.769875 \nL 168.118218 188.901753 \nL 170.160927 187.463124 \nL 172.203636 184.877234 \nL 174.246345 180.941626 \nL 176.289054 179.997894 \nL 178.331763 179.952904 \nL 180.374472 181.009112 \nL 182.417181 185.484608 \nL 184.45989 193.46723 \nL 186.502599 189.801565 \nL 188.545308 183.077609 \nL 190.588017 177.367014 \nL 192.630726 179.34553 \nL 194.673435 182.223859 \nL 196.716144 189.801565 \nL 198.758853 184.719767 \nL 200.801562 190.723873 \nL 202.844271 194.635915 \nL 204.886979 194.478447 \nL 206.929688 184.022412 \nL 208.972397 189.036724 \nL 211.015106 187.643086 \nL 213.057815 179.143072 \nL 215.100524 180.042885 \nL 217.143233 189.351659 \nL 219.185942 192.319969 \nL 221.228651 187.260666 \nL 223.27136 188.474342 \nL 225.314069 190.723873 \nL 227.356778 175.904819 \nL 229.399487 194.613419 \nL 231.442196 182.808737 \nL 233.484905 192.544922 \nL 235.527614 191.577623 \nL 237.570323 183.437534 \nL 239.613032 184.202375 \nL 241.655741 188.519332 \nL 243.69845 187.013218 \nL 245.741159 182.201363 \nL 247.783868 183.212581 \nL 249.826577 189.801565 \nL 251.869286 190.183985 \nL 253.911995 192.319969 \nL 255.954704 181.571495 \nL 257.997413 194.141018 \nL 260.040122 192.634903 \nL 262.082831 190.521415 \nL 264.12554 181.391532 \nL 266.168249 178.648175 \nL 272.296375 189.036724 \nL 274.339084 188.182974 \nL 276.381793 187.485619 \nL 278.424502 187.103199 \nL 280.467211 185.574589 \nL 282.50992 184.809748 \nL 284.552629 185.057197 \nL 286.595338 185.169673 \nL 288.638047 186.09091 \nL 290.680756 190.094004 \nL 292.723465 179.0081 \nL 294.766174 185.439617 \nL 296.808883 188.048002 \nL 298.851592 193.1298 \nL 300.894301 193.197286 \nL 302.93701 188.541828 \nL 304.979719 186.315863 \nL 307.022428 186.158396 \nL 309.065137 197.356776 \nL 311.107846 187.553105 \nL 313.150555 181.998906 \nL 315.193264 182.403821 \nL 317.235973 182.988699 \nL 319.278682 185.955938 \nL 321.321391 186.360854 \nL 323.3641 180.694178 \nL 325.406809 182.358831 \nL 327.449518 182.088887 \nL 329.492227 200.527544 \nL 331.534936 188.72179 \nL 333.577645 184.517309 \nL 335.620353 181.459018 \nL 337.663062 181.279056 \nL 339.705771 184.044908 \nL 341.74848 186.47333 \nL 343.791189 187.823049 \nL 345.833898 191.487642 \nL 347.876607 190.836349 \nL 349.919316 197.919159 \nL 351.962025 180.694178 \nL 354.004734 178.28825 \nL 356.047443 180.986617 \nL 356.047443 180.986617 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_19\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 36.465625 224.64 \nL 36.465625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 371.265625 224.64 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.465625 224.64 \nL 371.265625 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.465625 7.2 \nL 371.265625 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p4c6ee56629\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"36.465625\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nloss_model plot (blue: train | orange: eval)\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m56b316363f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m56b316363f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"86.175486\" xlink:href=\"#m56b316363f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(79.812986 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"127.029666\" xlink:href=\"#m56b316363f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(120.667166 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.883845\" xlink:href=\"#m56b316363f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(161.521345 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"208.738024\" xlink:href=\"#m56b316363f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(202.375524 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"249.592204\" xlink:href=\"#m56b316363f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(240.048454 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"290.446383\" xlink:href=\"#m56b316363f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g transform=\"translate(280.902633 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"331.300562\" xlink:href=\"#m56b316363f\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 140 -->\n      <g transform=\"translate(321.756812 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m2578da510f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2578da510f\" y=\"201.583763\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 205.382982)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2578da510f\" y=\"173.675712\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.1 -->\n      <g transform=\"translate(7.2 177.474931)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2578da510f\" y=\"145.767661\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.2 -->\n      <g transform=\"translate(7.2 149.56688)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2578da510f\" y=\"117.85961\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(7.2 121.658828)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2578da510f\" y=\"89.951558\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.4 -->\n      <g transform=\"translate(7.2 93.750777)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2578da510f\" y=\"62.043507\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 65.842726)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m2578da510f\" y=\"34.135456\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.6 -->\n      <g transform=\"translate(7.2 37.934674)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#p51d19dd4aa)\" d=\"M 45.321307 17.083636 \nL 47.364016 66.201807 \nL 49.406725 92.602823 \nL 51.449434 111.998919 \nL 53.492143 122.324898 \nL 55.534852 133.32067 \nL 57.577561 142.000074 \nL 59.62027 151.767892 \nL 61.662979 159.637962 \nL 63.705688 165.97309 \nL 65.748397 171.889597 \nL 67.791105 176.633966 \nL 69.833814 180.848081 \nL 71.876523 184.44822 \nL 73.919232 187.266933 \nL 75.961941 189.555393 \nL 78.00465 191.648497 \nL 80.047359 192.960176 \nL 82.090068 194.439302 \nL 88.218195 197.202199 \nL 92.303613 198.792958 \nL 98.43174 200.495349 \nL 100.474449 200.830246 \nL 102.517158 201.416315 \nL 104.559867 201.862844 \nL 108.645285 202.421005 \nL 110.687994 202.867534 \nL 114.773412 203.537327 \nL 116.816121 203.844316 \nL 118.85883 203.872224 \nL 120.901539 204.20712 \nL 122.944248 204.235028 \nL 124.986957 204.625741 \nL 127.029666 204.709465 \nL 133.157792 205.462983 \nL 137.24321 205.769971 \nL 139.285919 205.742063 \nL 141.328628 204.569925 \nL 143.371337 205.379258 \nL 145.414046 206.328132 \nL 147.456755 205.686247 \nL 149.499464 205.937419 \nL 151.542173 203.258247 \nL 153.584882 204.235028 \nL 155.627591 205.044362 \nL 157.6703 205.714155 \nL 159.713009 206.188592 \nL 161.755718 205.686247 \nL 163.798427 206.35604 \nL 165.841136 206.049052 \nL 167.883845 206.300224 \nL 169.926554 206.774661 \nL 174.011972 207.249098 \nL 178.09739 208.197972 \nL 180.140099 206.970017 \nL 182.182808 206.997925 \nL 184.225517 208.923581 \nL 186.268226 208.22588 \nL 188.310935 208.337512 \nL 190.353644 208.616592 \nL 192.396353 208.532868 \nL 194.439062 206.663029 \nL 196.481771 206.718845 \nL 198.524479 207.556086 \nL 200.567188 208.114247 \nL 202.609897 207.918891 \nL 204.652606 208.253788 \nL 206.695315 208.36542 \nL 208.738024 208.784041 \nL 214.866151 209.37011 \nL 218.951569 210.179443 \nL 220.994278 210.51434 \nL 223.036987 207.332822 \nL 225.079696 209.732914 \nL 227.122405 208.756133 \nL 229.165114 208.979397 \nL 231.207823 209.565466 \nL 233.250532 209.732914 \nL 235.293241 210.207351 \nL 243.464077 211.184133 \nL 247.549495 211.881834 \nL 249.592204 211.714386 \nL 251.634913 211.184133 \nL 253.677622 209.091029 \nL 257.76304 210.067811 \nL 259.805749 210.877145 \nL 261.848458 210.235259 \nL 263.891166 210.932961 \nL 265.933875 211.016685 \nL 276.14742 212.439995 \nL 278.190129 212.691168 \nL 284.318256 213.974938 \nL 286.360965 212.049283 \nL 288.403674 212.105099 \nL 290.446383 210.821328 \nL 292.489092 213.305145 \nL 294.531801 213.444685 \nL 296.57451 214.198203 \nL 298.617219 209.816639 \nL 300.659928 211.65857 \nL 302.702637 212.272547 \nL 304.745346 209.146845 \nL 306.788055 213.556317 \nL 308.830764 210.737604 \nL 310.873473 211.770202 \nL 312.916182 211.770202 \nL 314.958891 213.528409 \nL 317.0016 213.221421 \nL 321.087018 214.756364 \nL 323.129727 210.458524 \nL 325.172436 207.946799 \nL 327.215145 213.94703 \nL 329.257853 213.221421 \nL 331.300562 212.970248 \nL 333.343271 213.109789 \nL 335.38598 213.695858 \nL 337.428689 214.08657 \nL 339.471398 214.170295 \nL 341.514107 214.393559 \nL 343.556816 214.393559 \nL 345.599525 208.700317 \nL 347.642234 214.337743 \nL 349.684943 211.909742 \nL 349.684943 211.909742 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#p51d19dd4aa)\" d=\"M 45.321307 65.839002 \nL 47.364016 81.941948 \nL 49.406725 106.24986 \nL 53.492143 130.613589 \nL 57.577561 151.432995 \nL 59.62027 159.38679 \nL 61.662979 165.83355 \nL 65.748397 175.824632 \nL 67.791105 180.234104 \nL 69.833814 183.917967 \nL 71.876523 187.127393 \nL 73.919232 189.667026 \nL 75.961941 191.732221 \nL 78.00465 193.518337 \nL 80.047359 194.913739 \nL 82.090068 196.030061 \nL 86.175486 197.648728 \nL 88.218195 198.541786 \nL 90.260904 199.183671 \nL 92.303613 199.49066 \nL 96.389031 200.830246 \nL 98.43174 201.081419 \nL 100.474449 201.63958 \nL 108.645285 202.979166 \nL 112.730703 203.760591 \nL 114.773412 204.318752 \nL 116.816121 204.262936 \nL 118.85883 204.597833 \nL 120.901539 204.709465 \nL 122.944248 205.128086 \nL 124.986957 205.155994 \nL 127.029666 205.518799 \nL 131.115084 205.658339 \nL 135.200501 206.188592 \nL 137.24321 206.244408 \nL 139.285919 205.267626 \nL 141.328628 206.104868 \nL 143.371337 207.109558 \nL 145.414046 206.188592 \nL 147.456755 206.439764 \nL 149.499464 202.365189 \nL 151.542173 204.039672 \nL 155.627591 205.937419 \nL 157.6703 206.551397 \nL 159.713009 206.104868 \nL 161.755718 206.886293 \nL 163.798427 206.244408 \nL 165.841136 206.328132 \nL 171.969263 207.556086 \nL 174.011972 208.281696 \nL 176.054681 208.560776 \nL 178.09739 207.556086 \nL 180.140099 207.667719 \nL 182.182808 209.091029 \nL 184.225517 208.197972 \nL 186.268226 207.835167 \nL 190.353644 208.393328 \nL 192.396353 206.718845 \nL 194.439062 207.109558 \nL 196.481771 207.863075 \nL 198.524479 208.086339 \nL 200.567188 207.835167 \nL 204.652606 208.532868 \nL 206.695315 208.979397 \nL 212.823442 209.146845 \nL 214.866151 209.788731 \nL 218.951569 211.463214 \nL 220.994278 205.630431 \nL 223.036987 209.760822 \nL 225.079696 207.695627 \nL 227.122405 208.923581 \nL 229.165114 209.732914 \nL 233.250532 210.346892 \nL 235.293241 210.179443 \nL 237.33595 210.3748 \nL 241.421368 211.65857 \nL 243.464077 211.546938 \nL 245.506786 212.300455 \nL 249.592204 209.956179 \nL 251.634913 207.835167 \nL 253.677622 208.36542 \nL 255.720331 208.588684 \nL 257.76304 209.50965 \nL 259.805749 209.258478 \nL 261.848458 210.039903 \nL 263.891166 210.151535 \nL 267.976584 211.491122 \nL 272.062002 211.574846 \nL 276.14742 212.021375 \nL 278.190129 212.049283 \nL 280.232838 212.188823 \nL 282.275547 213.081881 \nL 284.318256 210.291075 \nL 286.360965 211.239949 \nL 288.403674 208.393328 \nL 290.446383 211.239949 \nL 292.489092 211.574846 \nL 294.531801 212.160915 \nL 296.57451 207.416546 \nL 298.617219 209.900363 \nL 300.659928 210.123627 \nL 302.702637 205.742063 \nL 304.745346 213.444685 \nL 306.788055 211.156225 \nL 308.830764 210.960869 \nL 310.873473 209.732914 \nL 312.916182 211.463214 \nL 314.958891 211.267857 \nL 317.0016 212.272547 \nL 319.044309 213.640042 \nL 321.087018 209.565466 \nL 323.129727 205.183902 \nL 325.172436 213.333053 \nL 327.215145 211.770202 \nL 331.300562 210.011995 \nL 333.343271 210.318983 \nL 337.428689 211.79811 \nL 339.471398 211.881834 \nL 341.514107 211.79811 \nL 343.556816 205.602523 \nL 345.599525 211.909742 \nL 347.642234 209.816639 \nL 349.684943 212.244639 \nL 349.684943 212.244639 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p51d19dd4aa\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nloss_compet plot (blue: train | orange: eval)\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 372.103125 248.518125\" width=\"372.103125pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 372.103125 248.518125 \nL 372.103125 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \nL 364.903125 7.2 \nL 30.103125 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m2e7e4c1a51\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"45.321307\" xlink:href=\"#m2e7e4c1a51\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(42.140057 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"86.175486\" xlink:href=\"#m2e7e4c1a51\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(79.812986 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"127.029666\" xlink:href=\"#m2e7e4c1a51\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(120.667166 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"167.883845\" xlink:href=\"#m2e7e4c1a51\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(161.521345 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"208.738024\" xlink:href=\"#m2e7e4c1a51\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(202.375524 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"249.592204\" xlink:href=\"#m2e7e4c1a51\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 100 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(240.048454 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"290.446383\" xlink:href=\"#m2e7e4c1a51\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 120 -->\n      <g transform=\"translate(280.902633 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"331.300562\" xlink:href=\"#m2e7e4c1a51\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 140 -->\n      <g transform=\"translate(321.756812 239.238438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_9\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m38dcf33179\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m38dcf33179\" y=\"201.602386\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 205.401605)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m38dcf33179\" y=\"173.67462\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.1 -->\n      <g transform=\"translate(7.2 177.473839)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m38dcf33179\" y=\"145.746854\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 1.2 -->\n      <g transform=\"translate(7.2 149.546073)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m38dcf33179\" y=\"117.819088\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 1.3 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(7.2 121.618307)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m38dcf33179\" y=\"89.891322\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 1.4 -->\n      <g transform=\"translate(7.2 93.690541)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m38dcf33179\" y=\"61.963556\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 1.5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(7.2 65.762775)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.103125\" xlink:href=\"#m38dcf33179\" y=\"34.03579\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 1.6 -->\n      <g transform=\"translate(7.2 37.835009)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path clip-path=\"url(#pee8c1c906e)\" d=\"M 45.321307 17.083636 \nL 47.364016 69.113064 \nL 49.406725 92.935449 \nL 51.449434 112.177679 \nL 53.492143 122.17582 \nL 55.534852 133.151432 \nL 57.577561 141.92075 \nL 59.62027 151.66754 \nL 61.662979 159.571098 \nL 63.705688 166.162051 \nL 65.748397 171.859315 \nL 67.791105 176.718746 \nL 69.833814 180.879984 \nL 71.876523 184.370954 \nL 73.919232 187.275442 \nL 75.961941 189.593447 \nL 78.00465 191.54839 \nL 80.047359 193.112345 \nL 82.090068 194.369095 \nL 86.175486 196.463677 \nL 90.260904 198.139343 \nL 92.303613 198.809609 \nL 94.346322 199.312309 \nL 98.43174 200.513203 \nL 100.474449 200.820408 \nL 104.559867 201.742025 \nL 114.773412 203.473546 \nL 116.816121 203.892463 \nL 118.85883 203.892463 \nL 120.901539 204.17174 \nL 122.944248 204.311379 \nL 124.986957 204.646512 \nL 127.029666 204.786151 \nL 129.072375 205.093357 \nL 133.157792 205.42849 \nL 135.200501 205.735695 \nL 139.285919 205.93119 \nL 141.328628 204.618585 \nL 145.414046 206.378034 \nL 147.456755 205.707767 \nL 149.499464 205.987045 \nL 151.542173 203.333907 \nL 153.584882 204.367235 \nL 157.6703 205.791551 \nL 159.713009 206.154612 \nL 161.755718 205.735695 \nL 163.798427 206.405962 \nL 165.841136 206.126684 \nL 167.883845 206.322178 \nL 169.926554 206.713167 \nL 174.011972 207.132084 \nL 176.054681 207.690639 \nL 178.09739 208.109555 \nL 180.140099 206.936589 \nL 182.182808 206.964517 \nL 184.225517 208.863605 \nL 186.268226 208.137483 \nL 188.310935 208.193339 \nL 190.353644 208.528472 \nL 192.396353 208.584327 \nL 194.439062 206.685239 \nL 196.481771 206.685239 \nL 198.524479 207.578928 \nL 200.567188 208.109555 \nL 202.609897 207.914061 \nL 204.652606 208.221266 \nL 206.695315 208.360905 \nL 208.738024 208.723966 \nL 210.780733 208.891533 \nL 216.90886 209.785221 \nL 220.994278 210.455488 \nL 223.036987 207.243795 \nL 225.079696 209.729366 \nL 227.122405 208.723966 \nL 229.165114 208.947388 \nL 231.207823 209.589727 \nL 233.250532 209.729366 \nL 235.293241 210.17621 \nL 247.549495 211.879804 \nL 249.592204 211.712237 \nL 251.634913 211.18161 \nL 253.677622 209.114955 \nL 257.76304 210.120354 \nL 259.805749 210.902332 \nL 261.848458 210.287921 \nL 263.891166 211.014043 \nL 265.933875 211.041971 \nL 274.104711 212.159081 \nL 280.232838 213.080698 \nL 284.318256 213.918531 \nL 286.360965 212.019443 \nL 288.403674 212.159081 \nL 290.446383 210.818549 \nL 292.489092 213.276192 \nL 294.531801 213.415831 \nL 296.57451 214.141953 \nL 298.617219 209.869005 \nL 300.659928 211.684309 \nL 302.702637 212.29872 \nL 304.745346 209.17081 \nL 306.788055 213.583397 \nL 308.830764 210.762693 \nL 310.873473 211.768093 \nL 312.916182 211.712237 \nL 314.958891 213.527542 \nL 317.0016 213.220337 \nL 321.087018 214.756364 \nL 323.129727 210.455488 \nL 325.172436 207.969917 \nL 327.215145 213.918531 \nL 329.257853 213.136553 \nL 331.300562 212.941059 \nL 333.343271 213.05277 \nL 335.38598 213.667181 \nL 337.428689 214.058169 \nL 339.471398 214.086097 \nL 341.514107 214.42123 \nL 343.556816 214.393303 \nL 345.599525 208.723966 \nL 347.642234 214.337447 \nL 349.684943 211.907732 \nL 349.684943 211.907732 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path clip-path=\"url(#pee8c1c906e)\" d=\"M 45.321307 65.733805 \nL 47.364016 81.903981 \nL 49.406725 106.145282 \nL 53.492143 130.582077 \nL 57.577561 151.416191 \nL 59.62027 159.347676 \nL 61.662979 165.79899 \nL 65.748397 175.852986 \nL 67.791105 180.237645 \nL 69.833814 183.952038 \nL 71.876523 187.107875 \nL 73.919232 189.705158 \nL 75.961941 191.743885 \nL 78.00465 193.503334 \nL 80.047359 194.955578 \nL 82.090068 196.072688 \nL 86.175486 197.636643 \nL 88.218195 198.586187 \nL 90.260904 199.17267 \nL 92.303613 199.479876 \nL 96.389031 200.848336 \nL 98.43174 201.099686 \nL 100.474449 201.630314 \nL 110.687994 203.389763 \nL 114.773412 204.283451 \nL 116.816121 204.283451 \nL 118.85883 204.646512 \nL 120.901539 204.730296 \nL 122.944248 205.149212 \nL 124.986957 205.17714 \nL 127.029666 205.512273 \nL 131.115084 205.67984 \nL 135.200501 206.210467 \nL 137.24321 206.266323 \nL 139.285919 205.288851 \nL 143.371337 207.104156 \nL 145.414046 206.182539 \nL 147.456755 206.489745 \nL 149.499464 202.356436 \nL 151.542173 204.087957 \nL 155.627591 205.93119 \nL 157.6703 206.5456 \nL 159.713009 206.126684 \nL 161.755718 206.908661 \nL 163.798427 206.266323 \nL 165.841136 206.322178 \nL 171.969263 207.551 \nL 174.011972 208.277122 \nL 176.054681 208.584327 \nL 178.09739 207.606856 \nL 180.140099 207.634783 \nL 182.182808 209.087027 \nL 184.225517 208.221266 \nL 186.268226 207.830278 \nL 190.353644 208.388833 \nL 192.396353 206.769023 \nL 194.439062 207.104156 \nL 196.481771 207.858205 \nL 198.524479 208.109555 \nL 200.567188 207.858205 \nL 204.652606 208.5564 \nL 206.695315 209.031172 \nL 212.823442 209.17081 \nL 214.866151 209.813149 \nL 218.951569 211.488815 \nL 220.994278 205.651912 \nL 223.036987 209.785221 \nL 225.079696 207.746494 \nL 227.122405 208.947388 \nL 229.165114 209.757294 \nL 233.250532 210.399632 \nL 235.293241 210.204138 \nL 237.33595 210.399632 \nL 241.421368 211.684309 \nL 243.464077 211.544671 \nL 245.506786 212.326648 \nL 249.592204 209.980716 \nL 251.634913 207.886133 \nL 253.677622 208.388833 \nL 255.720331 208.640183 \nL 257.76304 209.533871 \nL 259.805749 209.282522 \nL 261.848458 210.092427 \nL 263.891166 210.17621 \nL 267.976584 211.516743 \nL 272.062002 211.600526 \nL 276.14742 212.04737 \nL 278.190129 212.04737 \nL 280.232838 212.214937 \nL 282.275547 213.080698 \nL 284.318256 210.287921 \nL 286.360965 211.265393 \nL 288.403674 208.416761 \nL 290.446383 211.293321 \nL 292.489092 211.628454 \nL 294.531801 212.159081 \nL 296.57451 207.439289 \nL 298.617219 209.92486 \nL 300.659928 210.148282 \nL 302.702637 205.791551 \nL 304.745346 213.471686 \nL 306.788055 211.153682 \nL 308.830764 210.986115 \nL 310.873473 209.757294 \nL 312.916182 211.488815 \nL 314.958891 211.293321 \nL 317.0016 212.29872 \nL 319.044309 213.639253 \nL 321.087018 209.589727 \nL 323.129727 205.205068 \nL 325.172436 213.359975 \nL 327.215145 211.79602 \nL 331.300562 210.036571 \nL 333.343271 210.343777 \nL 337.428689 211.823948 \nL 339.471398 211.907732 \nL 341.514107 211.823948 \nL 343.556816 205.623984 \nL 345.599525 211.935659 \nL 347.642234 209.841077 \nL 349.684943 212.29872 \nL 349.684943 212.29872 \n\" style=\"fill:none;stroke:#ff7f0e;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"line2d_18\"/>\n   <g id=\"patch_3\">\n    <path d=\"M 30.103125 224.64 \nL 30.103125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 364.903125 224.64 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 30.103125 224.64 \nL 364.903125 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 30.103125 7.2 \nL 364.903125 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pee8c1c906e\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"30.103125\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# Plot train and validation losses history\n",
    "for metric in monitor_batchs.metrics_info:\n",
    "    print(f\"\\n{metric} plot (blue: train | orange: eval)\")\n",
    "    for set_i in monitor_batchs.sets_names:\n",
    "        plt.plot(monitor_epochs.metrics[set_i][metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspect predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nProbas predicted:\n [[0.07117087 0.11733746 0.6008368  0.2106549 ]\n [0.01440324 0.19275396 0.5239699  0.26887286]\n [0.01603005 0.08618136 0.58315116 0.31463745]\n ...\n [0.01406228 0.2407567  0.5016608  0.24352019]\n [0.04616858 0.11326624 0.509383   0.33118224]\n [0.01560723 0.12527496 0.5677694  0.2913484 ]]\n\nQuantity of unique probas: 47217\n\n6 first uniques:\n [[2.7658923e-25 0.0000000e+00 1.0592421e-20 1.0000000e+00]\n [1.6664196e-15 3.7042680e-39 1.0555843e-11 1.0000000e+00]\n [3.0580836e-11 4.2367913e-29 3.4248555e-09 1.0000000e+00]\n [2.0889759e-07 2.3528230e-03 5.1473126e-02 9.4617385e-01]\n [1.0551531e-06 1.0203214e-03 6.9876760e-02 9.2910188e-01]\n [1.4974285e-06 1.0632515e-03 6.1655551e-02 9.3727964e-01]]\n\nvalues used for predictions: 0 2 3\n\nAccuracy model 14.608%\n\n\nPredictions:\n2    224310\n3     13880\n0         1\nName: y_pred, dtype: int64\n\ntarget:\n0    116542\n1     81723\n2     37340\n3      2586\nName: y, dtype: int64\n"
    }
   ],
   "source": [
    "# Transform logits into probabilities\n",
    "y_pred = F.softmax(predictions)\n",
    "\n",
    "# Transform tensors to numpy arrays\n",
    "y_pred = y_pred.detach().numpy()\n",
    "y = labels.numpy()\n",
    "\n",
    "# Display probas predicted\n",
    "print('\\nProbas predicted:\\n', y_pred)\n",
    "\n",
    "# Display the number of uniques probas (see the diversity of predictions)\n",
    "print(\"\\nQuantity of unique probas:\", \\\n",
    "        len(np.unique(F.softmax(predictions).detach().numpy(), axis=0)))\n",
    "print(\"\\n6 first uniques:\\n\", \\\n",
    "        np.unique(F.softmax(predictions).detach().numpy(), axis=0)[:6])\n",
    "\n",
    "# Transform array of predicted probas into vector of ints\n",
    "y_pred = y_pred.argmax(axis=1)\n",
    "\n",
    "# Values used\n",
    "print('\\nvalues used for predictions:', *np.unique(y_pred))\n",
    "\n",
    "# Transform arrays into dataframes\n",
    "df_results = pd.DataFrame({'y': y, 'y_pred': y_pred})\n",
    "\n",
    "# Compute accuracy ratio\n",
    "print(f'\\nAccuracy model {round(100 * sum(y_pred == y)/len(y), 4)}%')\n",
    "\n",
    "# Display value counts\n",
    "print('\\n\\nPredictions:')\n",
    "print(df_results['y_pred'].value_counts())\n",
    "print('\\ntarget:')\n",
    "print(df_results['y'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model\n",
    "\n",
    "On the test set (and no longer validation set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (<ipython-input-103-702f5d7c007c>, line 18)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-103-702f5d7c007c>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    monitor_epochs.print_scores(i_epoch=epoch, ['test'])\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "# --------\n",
    "with torch.no_grad():\n",
    "    # Reset batchs scores\n",
    "    monitor_batchs.reset()\n",
    "\n",
    "    for n_batch, (x, labels) in enumerate(dataloader_test):\n",
    "        # Predict on the test set\n",
    "        predictions = model(x)\n",
    "        \n",
    "        # Evaluate model and store metrics\n",
    "        monitor_batchs.evaluate(predictions, labels, set_i='test')\n",
    "\n",
    "# Compute & store: train and eval losses for the epoch\n",
    "monitor_epochs.compute(monitor_batchs, ['test'])\n",
    "\n",
    "# Display scores\n",
    "monitor_epochs.print_scores(i_epoch=epoch, ['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[0.956]"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "monitor_epochs.metrics['test']['loss_compet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model's weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'weights/weights_new.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with benchmarks preds\n",
    "\n",
    "- Uniform random predictions\n",
    "\n",
    "- Dumb prediction of the best label on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Random preds\n1.6357\n1.6626\n1.6485\n\nDumb preds\n1.3911\n1.3911\n1.3911\n"
    }
   ],
   "source": [
    "m_train = Y_train.shape[0]\n",
    "m_val = Y_val.shape[0]\n",
    "m_test = Y_test.shape[0]\n",
    "\n",
    "# Create numpy copy of target (from tensors)\n",
    "y_train = Y_train.numpy().astype(np.int_)\n",
    "y_val = Y_val.numpy().astype(np.int_)\n",
    "y_test = Y_test.numpy().astype(np.int_)\n",
    "\n",
    "# Random uniform train/test\n",
    "random_preds_train = np.random.uniform(size=(Y_train.shape[0], 4))\n",
    "random_preds_val = np.random.uniform(size=(Y_val.shape[0], 4))\n",
    "random_preds_test = np.random.uniform(size=(Y_test.shape[0], 4))\n",
    "\n",
    "# Create empty benchmark dumb\n",
    "dumb_preds_train = np.zeros((m_train, 4)) + .49\n",
    "dumb_preds_val = np.zeros((m_val, 4)) + .49\n",
    "dumb_preds_test = np.zeros((m_test, 4)) + .49\n",
    "\n",
    "# Benchmark dumb predict always 0 nights (the most )\n",
    "dumb_preds_train[range(m_train), 0] = .5\n",
    "dumb_preds_val[range(m_val), 0] = .5\n",
    "dumb_preds_test[range(m_test), 0] = .5\n",
    "\n",
    "# Evaluate preds\n",
    "# Random\n",
    "random_loss_train = cobra.competition_scorer(random_preds_train, y_train)\n",
    "random_loss_val = cobra.competition_scorer(random_preds_val, y_val)\n",
    "random_loss_test = cobra.competition_scorer(random_preds_test, y_test)\n",
    "# Dumb\n",
    "dumb_loss_train = cobra.competition_scorer(dumb_preds_train, y_train)\n",
    "dumb_loss_val = cobra.competition_scorer(dumb_preds_val, y_val)\n",
    "dumb_loss_test = cobra.competition_scorer(dumb_preds_test, y_test)\n",
    "\n",
    "# Display results\n",
    "print(\"Random preds\")\n",
    "print(round(random_loss_train, 4))\n",
    "print(round(random_loss_val, 4))\n",
    "print(round(random_loss_test, 4))\n",
    "\n",
    "print(\"\\nDumb preds\")\n",
    "print(round(dumb_loss_train, 4))\n",
    "print(round(dumb_loss_val, 4))\n",
    "print(round(dumb_loss_test, 4))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}