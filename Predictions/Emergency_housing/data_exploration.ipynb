{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation\n",
    "\n",
    "#### Goal: Enhance emergency housing allocation.\n",
    "\n",
    "\n",
    "#### Caracteristics of the model:\n",
    "Accuracy:\n",
    "- if used as a clearing tool removing overburden upfront, and thus only to get rid of obvious cases, the accuracy of such a tool could be its most important caracteristic.\n",
    "\n",
    "Interpretability:\n",
    "- could help families understand the decision (although not as important as in diseases predictions).\n",
    "- can also highlight and thus control biases (racial, sex, age).\n",
    "- since the tool would probably be used in combination with human selection, it could help save time by highlighting the main factors for each decision\n",
    "\n",
    "#### Conclusion:\n",
    "- a model easily interpretable could be prefered (tree).\n",
    "- or a highly accurate model (less interpretable) could also be used upfront (NN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classes, Functions & imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn import tree\n",
    "\n",
    "from cobratools import Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform methods\n",
    "def num_to_onehot(arr):\n",
    "    \"\"\" Transform a numeric categorical vector into a one-hot matrix \"\"\"\n",
    "    arr_onehot = np.zeros((arr.size, arr.max()+1))\n",
    "    arr_onehot[np.arange(arr.size), arr] = 1\n",
    "    return arr_onehot\n",
    "\n",
    "def onehot_to_num(arr):\n",
    "    \"\"\" Transform a one-hot encoded matrix into a numeric categorical vector \"\"\"\n",
    "    arr_num = arr.dot(np.arange(arr.shape[1]))\n",
    "    return arr_num\n",
    "\n",
    "# Analytics\n",
    "def count_pred_errors(arr_preds, arr_truth):\n",
    "    \"\"\" Counts the number of wrong predictions \"\"\"\n",
    "    return sum(arr_preds != arr_truth)\n",
    "\n",
    "# Define the test scorer\n",
    "def competition_scorer(y_true, y_pred):\n",
    "    return log_loss(y_true, y_pred, sample_weight=10**y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "requests_train = pd.read_csv(filepath_or_buffer='data/requests_train.csv',\n",
    "                             sep=',',\n",
    "                             low_memory=False,\n",
    "                             error_bad_lines=False)\n",
    "\n",
    "requests_test = pd.read_csv(filepath_or_buffer='data/requests_test.csv',\n",
    "                            sep=',',\n",
    "                            low_memory=False,\n",
    "                            error_bad_lines=False)\n",
    "\n",
    "individuals_train = pd.read_csv(filepath_or_buffer='data/individuals_train.csv',\n",
    "                                sep=',',\n",
    "                                low_memory=False,\n",
    "                                error_bad_lines=False)\n",
    "\n",
    "individuals_test = pd.read_csv(filepath_or_buffer='data/individuals_test.csv',\n",
    "                               sep=',',\n",
    "                               low_memory=False,\n",
    "                               error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(requests_train, individuals_train, on='request_id', how='outer')\n",
    "df_test = pd.merge(requests_test, individuals_test, on='request_id', how='outer')\n",
    "del requests_train, requests_test\n",
    "del individuals_train, individuals_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyze_df_train = Analysis(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process columns\n",
    "# booleans: 't', 't' => True, False\n",
    "# few categories => one-hot encoding\n",
    "# number of cols gone from 39 cols to 66 (still ok)\n",
    "Analyze_df_train.preprocess_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis (df_train)\n",
    "### General:\n",
    "- Number of requests: 238191\n",
    "- Number of individuals: 384133\n",
    "- Number of features: 39\n",
    "\n",
    "Requests are made for 1.6 pers on average.\n",
    "\n",
    "\n",
    "### Correlations with granted_number_of_nights\n",
    "- housing_situation_id: -0.458581. Strong negative impact. A high value must represent the good quality of the current housing situation.\n",
    "- housing_situation_2_id: 0.283840. Strong positive impact. A higher value must conversely represent a degraded quality.\n",
    "\n",
    "### Principal components\n",
    "- housing_situation_2_label: with value \"emergency accomodation\". High probability to get 1 or two nights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Analyze_df_train = Analysis(df_train)\n",
    "#Analyze_df_train.describe(investigation_level=3)\n",
    "#Analyze.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'granted_number_of_nights'\n",
    "feature = 'animal_presence'\n",
    "mask = df_train[feature] == 't'\n",
    "df_train[mask][[feature, target]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set of values\n",
    "set(df_train['animal_presence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NA, inf\n",
    "columns_selected = ['animal_presence']\n",
    "df_train[columns_selected].isnull().sum()\n",
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display unique values for main features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(df_train['housing_situation_2_label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "feature: housing_situation_2_label\n",
    "- A majority of requests with the label \"emergency accomodation\" obtains 1 or 2 nights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact of feature on target\n",
    "join_key = 'request_id'\n",
    "target = 'granted_number_of_nights'\n",
    "feature = 'housing_situation_2_label'\n",
    "mask = df_train[feature] == 'emergency accomodation'\n",
    "\n",
    "# Hist: drop duplicate requests (due to indiv data merged)\n",
    "df_train[mask][[join_key, target]].drop_duplicates().hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random uniform train/test\n",
    "random_preds_train = np.random.uniform(size=(requests_train.shape[0], 4))\n",
    "random_preds_test = np.random.uniform(size=(requests_test.shape[0], 4))\n",
    "\n",
    "# Dumb (always pred 3)\n",
    "dumb_preds_train = np.zeros((requests_train.shape[0], 4))\n",
    "dumb_preds_test = np.zeros((requests_test.shape[0], 4))\n",
    "# Set 10% pred everywhere (if not, log penalyzes hardly)\n",
    "dumb_preds_train[:,:] = .01\n",
    "dumb_preds_test[:,:] = .01\n",
    "# Set 20% pred on class 3\n",
    "dumb_preds_train[:,2] = .02\n",
    "dumb_preds_test[:,2] = .02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observed a significant (negative) correlation of housing_situation_id with granted_number_of_nights, let's train a univariate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model' parameters\n",
    "clf = tree.DecisionTreeClassifier(\n",
    "    criterion='gini',\n",
    "    splitter='best',\n",
    "    max_depth=2,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    max_leaf_nodes=None,\n",
    "    class_weight=None)\n",
    "\n",
    "# Build train/test datasets with housing_situation_id only\n",
    "X_train = np.array(requests_train['housing_situation_id']).reshape(-1, 1)\n",
    "X_test = np.array(requests_test['housing_situation_id'].values).reshape(-1, 1)\n",
    "Y_train = requests_train.granted_number_of_nights.values\n",
    "Y_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Transform categorical target into a one-hot vector\n",
    "Y_train_onehot = to_onehot(Y_train)\n",
    "Y_test_onehot = to_onehot(Y_test)\n",
    "\n",
    "# Train the model\n",
    "clf = clf.fit(X_train, Y_train_onehot)\n",
    "\n",
    "# Yield train/test predictions\n",
    "preds_train_tree_univar = clf.predict(X_train)\n",
    "preds_test_tree_univar = clf.predict(X_test)\n",
    "\n",
    "# Fill predictions to .2 elsewhere\n",
    "preds_train_tree_univar[preds_train_tree_univar == 0] = .2\n",
    "preds_test_tree_univar[preds_test_tree_univar == 0] = .2\n",
    "\n",
    "# Evaluate train/test\n",
    "score_train = competition_scorer(Y_train, preds_train_tree_univar)\n",
    "score_test = competition_scorer(Y_test, preds_test_tree_univar)\n",
    "\n",
    "# Display results\n",
    "print(f'train score: {score_train:.2f}')\n",
    "print(f'test score: {score_test:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = clf.predict_proba(X_train)\n",
    "v0 = probas[0].max(1)\n",
    "v1 = probas[1].max(1)\n",
    "v2 = probas[2].max(1)\n",
    "v3 = probas[3].max(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_test = requests_test.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_test = competition_scorer(y_true_test, random_preds_test)\n",
    "dumb_score_test = competition_scorer(y_true_test, dumb_preds_test)\n",
    "\n",
    "# Display results\n",
    "print(f'test score random: {random_score_test:.2f}')\n",
    "print(f'test score dumb: {dumb_score_test:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_train = requests_train.granted_number_of_nights.values\n",
    "\n",
    "# Evaluate benchmarks\n",
    "random_score_train = competition_scorer(y_true_train, random_preds_train)\n",
    "dumb_score_train = competition_scorer(y_true_train, dumb_preds_train)\n",
    "\n",
    "# Display results\n",
    "print(f'train score random: {random_score_train:.2f}')\n",
    "print(f'train score dumb: {dumb_score_train:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree\n",
    "fn = ['housing_situation_id']\n",
    "cn = ['0', '1', '2', '3']\n",
    "\n",
    "tree.plot_tree(clf,\n",
    "               feature_names = fn, \n",
    "               class_names=cn,\n",
    "               filled = True)\n",
    "\n",
    "requests_train['housing_situation_id'].hist()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36264bitpytorchvirtualenvb2c3f00e98dc48dba8e2131dc30ce6c5",
   "display_name": "Python 3.6.2 64-bit ('pytorch': virtualenv)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}